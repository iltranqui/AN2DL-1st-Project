{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('tensorflow_gpuenv': conda)",
   "metadata": {
    "interpreter": {
     "hash": "b4475d159700ac7f63d83dbd0a06e80f15c08c0a62544dac6ddf2e61acd99b97"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "VAL = 0.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{0, 1, 2}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "SEED = 1234\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "cwd = os.getcwd()\n",
    "\n",
    "import json\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# Defining the datasets directory\n",
    "dataset_dir = os.path.join(cwd, 'MaskDataset')\n",
    "training_dir = os.path.join(dataset_dir, 'training')\n",
    "validation_dir = os.path.join(dataset_dir, 'validation')\n",
    "test_dir = os.path.join(dataset_dir, 'test')\n",
    "\n",
    "# Create validation directory if it doesn't exist\n",
    "if not os.path.exists(validation_dir):\n",
    "    os.makedirs(validation_dir)\n",
    "\n",
    "# Loading the classes of each image into the memory\n",
    "train_classes_json_file_name = 'train_gt.json'\n",
    "train_classes_json_directory = os.path.join(dataset_dir, train_classes_json_file_name)\n",
    "\n",
    "data = {}\n",
    "\n",
    "with open(train_classes_json_directory) as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "\n",
    "# Creating folder for each class of image for training and validation datasets\n",
    "classes = set(data.values())\n",
    "print(classes)\n",
    "\n",
    "for class_label in classes:\n",
    "    class_training_dir = os.path.join(training_dir, str(class_label))\n",
    "    class_validation_dir = os.path.join(validation_dir, str(class_label))\n",
    "    if not os.path.exists(class_training_dir):\n",
    "        os.makedirs(class_training_dir)\n",
    "    if not os.path.exists(class_validation_dir):\n",
    "        os.makedirs(class_validation_dir)\n",
    "\n",
    "# Assigning images to each training folder/class, avoiding to have the same image two times in the same folder\n",
    "for entry in os.scandir(training_dir):\n",
    "    if(entry.is_file()):\n",
    "        file_destination = os.path.join(training_dir, str(data[entry.name]), entry.name)\n",
    "        if not os.path.isfile(file_destination):\n",
    "            shutil.copy(entry.path, file_destination)\n",
    "    \n",
    "# Choosing random images to be into the validation folders, being able to repeat without cloning images\n",
    "validation_rate = VAL\n",
    "\n",
    "for class_label in classes:\n",
    "    class_training_dir = os.path.join(training_dir, str(class_label))\n",
    "    class_validation_dir = os.path.join(validation_dir, str(class_label))\n",
    "    \n",
    "    for old_entry in os.scandir(class_validation_dir):\n",
    "        os.remove(old_entry.path)\n",
    "    \n",
    "    training_entries = list(os.scandir(class_training_dir))\n",
    "    validation_size = round(len(training_entries)*validation_rate)\n",
    "    \n",
    "    for validation_entry in random.sample(training_entries, validation_size):\n",
    "        destination = os.path.join(class_validation_dir, validation_entry.name)\n",
    "        os.rename(validation_entry.path, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 4492 images belonging to 3 classes.\nFound 1122 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "apply_data_augmentation = True\n",
    "\n",
    "if apply_data_augmentation:\n",
    "    train_data_gen = ImageDataGenerator(\n",
    "        rotation_range=10,\n",
    "        width_shift_range=10,\n",
    "        height_shift_range=10,\n",
    "        zoom_range=0.3,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        fill_mode='constant',\n",
    "        cval=0,\n",
    "        rescale=1/255.\n",
    "    )\n",
    "else:\n",
    "    train_data_gen = ImageDataGenerator(rescale=1/255.)\n",
    "\n",
    "valid_data_gen = ImageDataGenerator(rescale=1/255.)\n",
    "# test_data_gen = ImageDataGenerator(rescale=1/255.)\n",
    "\n",
    "bs = 8\n",
    "\n",
    "train_gen = train_data_gen.flow_from_directory(\n",
    "    training_dir,\n",
    "    batch_size=bs,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "valid_gen = valid_data_gen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    batch_size=bs,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "# test_gen = test_data_gen.flow_from_directory(\n",
    "#     test_dir,\n",
    "#     batch_size=bs,\n",
    "#     class_mode='categorical',\n",
    "#     shuffle=True,\n",
    "#     seed=SEED\n",
    "# )\n",
    "\n",
    "img_h = 256\n",
    "img_w = 256\n",
    "\n",
    "num_classes = len(classes)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: train_gen,\n",
    "    output_types=(tf.float32, tf.float32),\n",
    "    output_shapes=([None, 256, 256, 3], [None, num_classes])\n",
    ")\n",
    "\n",
    "train_dataset = train_dataset.repeat()\n",
    "\n",
    "valid_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: valid_gen,\n",
    "    output_types=(tf.float32, tf.float32),\n",
    "    output_shapes=([None, 256, 256, 3], [None, num_classes])\n",
    ")\n",
    "\n",
    "valid_dataset = valid_dataset.repeat()\n",
    "\n",
    "# test_dataset = tf.data.Dataset.from_generator(\n",
    "#     lambda: test_gen,\n",
    "#     output_types=(tf.float32, tf.float32),\n",
    "#     output_shapes=([None, 256, 256, 3], [None, num_classes])\n",
    "# )\n",
    "\n",
    "# test_dataset = test_dataset.repeat()"
   ]
  },
  {
   "source": [
    "# Building the Network"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load VGG16 Model\n",
    "\n",
    "vgg = tf.keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=(img_h, img_w, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"vgg16\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 256, 256, 3)]     0         \n_________________________________________________________________\nblock1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      \n_________________________________________________________________\nblock1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     \n_________________________________________________________________\nblock1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         \n_________________________________________________________________\nblock2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     \n_________________________________________________________________\nblock2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    \n_________________________________________________________________\nblock2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         \n_________________________________________________________________\nblock3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    \n_________________________________________________________________\nblock3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    \n_________________________________________________________________\nblock3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    \n_________________________________________________________________\nblock3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         \n_________________________________________________________________\nblock4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   \n_________________________________________________________________\nblock4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   \n_________________________________________________________________\nblock4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   \n_________________________________________________________________\nblock4_pool (MaxPooling2D)   (None, 16, 16, 512)       0         \n_________________________________________________________________\nblock5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   \n_________________________________________________________________\nblock5_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n_________________________________________________________________\nblock5_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n_________________________________________________________________\nblock5_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n=================================================================\nTotal params: 14,714,688\nTrainable params: 14,714,688\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nvgg16 (Model)                (None, 8, 8, 512)         14714688  \n_________________________________________________________________\nflatten (Flatten)            (None, 32768)             0         \n_________________________________________________________________\ndense (Dense)                (None, 512)               16777728  \n_________________________________________________________________\ndense_1 (Dense)              (None, 3)                 1539      \n=================================================================\nTotal params: 31,493,955\nTrainable params: 23,858,691\nNon-trainable params: 7,635,264\n_________________________________________________________________\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0e-04, -3.09621776e-03, -3.01808352e-03],\n",
       "          [-2.62522907e-03,  3.51887429e-03, -2.58309790e-03, ...,\n",
       "           -6.02027494e-03, -8.85035843e-03,  9.85825085e-04]],\n",
       " \n",
       "         [[ 3.02846078e-04,  2.64736195e-03, -1.37099335e-02, ...,\n",
       "            1.49135189e-02, -4.65666235e-04, -6.84898719e-03],\n",
       "          [-9.60117579e-03,  5.01031429e-03, -1.13053191e-02, ...,\n",
       "            8.86707660e-03,  6.21224102e-03,  2.48882570e-03],\n",
       "          [-1.13499342e-02, -4.72285505e-03, -8.57903156e-03, ...,\n",
       "           -3.04920389e-03,  9.67197306e-03,  1.90250184e-02],\n",
       "          ...,\n",
       "          [-4.48127137e-03,  5.53716440e-03,  4.68912302e-03, ...,\n",
       "           -4.91005788e-03,  6.40070112e-03, -8.28019064e-03],\n",
       "          [-6.00830279e-03, -7.51605199e-04,  8.29616503e-04, ...,\n",
       "            2.07461347e-03,  3.22994636e-03, -1.69727230e-03],\n",
       "          [-2.81035155e-03,  1.36994272e-02, -2.04460253e-03, ...,\n",
       "           -5.17683988e-03, -9.04289633e-03, -1.79657899e-03]],\n",
       " \n",
       "         [[ 3.09069827e-03, -7.85107608e-04, -1.12262042e-02, ...,\n",
       "            1.38624888e-02, -1.50248851e-03, -2.83075101e-03],\n",
       "          [-1.78263709e-02, -4.06336552e-03, -1.11764381e-02, ...,\n",
       "            1.76884588e-02, -1.14172359e-03,  1.50952139e-03],\n",
       "          [-1.26420632e-02, -1.19902752e-03, -1.03873471e-02, ...,\n",
       "           -1.54873531e-03,  3.21487361e-03,  1.84067711e-02],\n",
       "          ...,\n",
       "          [ 4.99952445e-03,  8.96072667e-03,  2.35912274e-03, ...,\n",
       "           -6.95799524e-03,  9.11425054e-03, -1.76598097e-03],\n",
       "          [-3.11188446e-03, -4.81695170e-03,  2.14671413e-03, ...,\n",
       "            8.69878661e-03,  4.66441829e-03,  3.96351190e-03],\n",
       "          [-1.56560540e-03,  1.01758400e-02, -1.81451999e-03, ...,\n",
       "           -7.93038029e-03, -7.92690739e-03,  9.85421613e-03]]],\n",
       " \n",
       " \n",
       "        [[[ 2.21009902e-03,  5.53841889e-03, -1.51329748e-02, ...,\n",
       "            1.92244705e-02, -2.94085429e-03, -2.05214042e-03],\n",
       "          [ 4.31180233e-03, -4.67703957e-03, -9.83539224e-03, ...,\n",
       "           -1.16664264e-03, -7.47026131e-03,  8.98758229e-03],\n",
       "          [-1.00150378e-02, -3.31197702e-03, -4.38165246e-03, ...,\n",
       "            1.28704909e-04,  6.90069282e-05,  5.32614533e-03],\n",
       "          ...,\n",
       "          [-1.65325180e-02,  5.79520175e-03, -1.08136714e-03, ...,\n",
       "           -3.87264206e-03,  3.87065555e-03, -8.52444116e-03],\n",
       "          [-1.10835498e-02,  6.04208373e-03,  6.12878706e-03, ...,\n",
       "           -4.66409931e-03, -1.65367487e-03, -4.93706390e-03],\n",
       "          [-5.82469627e-03,  2.77068373e-03,  2.59765168e-03, ...,\n",
       "           -9.57501866e-03, -3.32338479e-03,  3.07677989e-03]],\n",
       " \n",
       "         [[ 3.59932799e-03,  1.19693214e-02, -1.60994809e-02, ...,\n",
       "            1.80910621e-02,  3.29896147e-06, -6.10836258e-04],\n",
       "          [-7.41903298e-03, -5.61146066e-03, -1.38216335e-02, ...,\n",
       "            2.96197180e-03,  2.69207382e-03,  7.01817824e-03],\n",
       "          [-8.48251395e-03,  9.95878596e-04,  6.25522574e-04, ...,\n",
       "           -3.68017773e-03,  1.27349654e-02,  4.87677474e-03],\n",
       "          ...,\n",
       "          [-8.20725970e-03,  1.95525214e-03,  2.69707199e-03, ...,\n",
       "           -4.49266564e-03,  6.45229314e-03, -1.28380703e-02],\n",
       "          [-5.50353806e-03,  1.61080994e-03,  1.39699667e-03, ...,\n",
       "           -2.52319360e-03, -4.11227718e-03, -5.21757640e-03],\n",
       "          [-2.69698747e-03,  2.70054420e-03,  3.79564380e-03, ...,\n",
       "           -7.66708190e-03, -9.20492224e-03, -4.52092383e-03]],\n",
       " \n",
       "         [[ 2.48262100e-03,  6.13112841e-03, -1.47995697e-02, ...,\n",
       "            1.69335436e-02,  1.16662926e-03,  1.17623655e-03],\n",
       "          [-1.69411730e-02, -8.71018134e-03, -1.29530905e-02, ...,\n",
       "            1.87354535e-03, -6.88433880e-04, -1.68701622e-03],\n",
       "          [-6.59902534e-03,  3.46401357e-03, -3.11806914e-03, ...,\n",
       "           -4.05590283e-03,  7.37769250e-03,  5.51742781e-03],\n",
       "          ...,\n",
       "          [ 9.51702707e-04,  1.64372730e-03,  1.49127271e-03, ...,\n",
       "           -7.65326899e-03,  1.19846454e-02, -9.10102390e-03],\n",
       "          [ 2.88849953e-03, -5.35335718e-03, -3.08376068e-04, ...,\n",
       "            3.87483276e-04, -4.36716061e-03, -2.73425644e-03],\n",
       "          [-1.54271268e-03,  4.30263951e-03, -4.31923472e-05, ...,\n",
       "           -5.21167647e-03, -8.79874174e-03, -2.11346560e-04]]],\n",
       " \n",
       " \n",
       "        [[[-2.93453527e-03,  4.62880917e-03, -9.69677325e-03, ...,\n",
       "            1.48544796e-02,  3.87839018e-03,  1.85810984e-03],\n",
       "          [ 5.63784037e-03, -6.04889123e-03, -5.59245935e-03, ...,\n",
       "           -4.98529337e-03, -1.92062720e-03,  4.07473044e-03],\n",
       "          [-4.84194839e-03,  2.70295335e-04, -3.02166585e-03, ...,\n",
       "           -1.49492722e-03, -1.31164724e-02,  2.69274553e-03],\n",
       "          ...,\n",
       "          [-1.79702230e-02, -3.29879066e-03, -6.12194091e-03, ...,\n",
       "           -7.89267663e-03, -1.74841529e-03, -2.64002383e-03],\n",
       "          [-1.11466460e-02,  5.13884844e-03,  1.51880039e-02, ...,\n",
       "           -4.87166690e-03,  2.45198980e-03, -3.42866592e-03],\n",
       "          [-6.12380216e-03,  8.87359586e-03, -3.45014478e-03, ...,\n",
       "           -1.09723555e-02,  2.66773975e-03, -4.79325093e-03]],\n",
       " \n",
       "         [[-6.14633691e-03,  1.40388934e-02, -9.19489283e-03, ...,\n",
       "            1.60656814e-02,  8.88941437e-03,  6.56510517e-03],\n",
       "          [-5.72578516e-03, -3.33702704e-03, -8.64025764e-03, ...,\n",
       "            1.98416272e-03,  7.86264334e-03,  2.50778953e-03],\n",
       "          [-3.77366156e-03,  9.24240507e-04,  7.29091058e-04, ...,\n",
       "           -4.96890210e-03,  3.85057204e-03, -7.15580711e-04],\n",
       "          ...,\n",
       "          [-1.22111076e-02, -2.42003356e-03, -4.81141545e-03, ...,\n",
       "           -4.22020489e-03, -1.01946108e-02, -5.80721162e-03],\n",
       "          [-9.04400460e-03,  1.94370467e-03,  7.34009594e-03, ...,\n",
       "           -5.14973374e-03,  3.66879918e-04, -5.37241250e-03],\n",
       "          [-3.53684562e-04,  1.53788179e-02, -8.76262202e-04, ...,\n",
       "           -7.13666994e-03, -4.27656015e-03, -1.42133404e-02]],\n",
       " \n",
       "         [[-6.67408668e-03,  9.11168288e-03, -9.18486901e-03, ...,\n",
       "            1.21346870e-02,  8.51947255e-03,  7.15135690e-03],\n",
       "          [-1.64910071e-02, -2.04550894e-03, -7.30760070e-03, ...,\n",
       "           -2.89353775e-03,  1.16095145e-03, -6.60440046e-03],\n",
       "          [-7.68517129e-05,  4.32093628e-03, -6.93119306e-04, ...,\n",
       "           -3.48316878e-03, -1.47545757e-03, -2.85687298e-03],\n",
       "          ...,\n",
       "          [-4.66702832e-03, -1.39780261e-03,  3.67210196e-05, ...,\n",
       "           -4.95146902e-04,  7.23151665e-04, -6.29519764e-03],\n",
       "          [ 3.63699184e-03, -4.63909749e-03,  5.31478412e-03, ...,\n",
       "           -1.50180201e-03, -7.48660788e-03, -1.94359326e-03],\n",
       "          [-1.03440508e-03,  1.57131702e-02, -1.98940560e-03, ...,\n",
       "           -5.38550608e-04, -5.37431426e-03, -9.20103770e-03]]]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'block5_conv3/bias:0' shape=(512,) dtype=float32, numpy=\n",
       " array([ 1.88378572e-01, -5.00367463e-01,  5.42223394e-01,  2.46460959e-01,\n",
       "         1.54070303e-01, -2.36067176e-01, -1.17649809e-02,  3.57512347e-02,\n",
       "         7.58338273e-02,  1.63476378e-01, -1.34778112e-01, -8.40371996e-02,\n",
       "         2.50966042e-01, -1.67475253e-01, -2.82782689e-02,  4.04935628e-01,\n",
       "         4.92739901e-02,  3.43014568e-01, -2.48226017e-01, -8.52851495e-02,\n",
       "         1.14871934e-01, -8.34204536e-03, -7.97333941e-02,  2.08946794e-01,\n",
       "         2.29255453e-01, -3.57115209e-01,  3.54569256e-01,  4.94823381e-02,\n",
       "         2.67764390e-01,  1.16772160e-01,  2.48077109e-01,  1.90769851e-01,\n",
       "         2.27198079e-01,  2.07326874e-01,  4.33389664e-01, -2.14167282e-01,\n",
       "         4.27582026e-01,  2.85164490e-02, -1.01103269e-01, -1.16591506e-01,\n",
       "         1.57484300e-02, -1.92446187e-01,  5.09383738e-01, -1.01140939e-01,\n",
       "        -1.70503020e-01,  1.82109758e-01,  6.56641722e-02,  1.48948044e-01,\n",
       "        -3.34800705e-02,  2.34267697e-01,  1.17521681e-01, -1.11647561e-01,\n",
       "         1.67274535e-01, -2.18229502e-01, -1.26343705e-02,  6.51194036e-01,\n",
       "         4.33828384e-01,  5.46606928e-02,  2.51551688e-01,  2.21985489e-01,\n",
       "         2.07218826e-02, -2.58966297e-01,  1.32507131e-01,  1.47451892e-01,\n",
       "        -1.49491996e-01, -2.45121513e-02, -1.93051482e-03,  3.55903581e-02,\n",
       "        -2.87072897e-01,  2.04153866e-01,  5.73086739e-02,  1.29463181e-01,\n",
       "         1.23248003e-01, -1.90378204e-01, -5.25708608e-02, -8.20820853e-02,\n",
       "         7.67999232e-01,  2.17065111e-01,  4.36754115e-02, -6.61685169e-02,\n",
       "         1.55227348e-01,  6.22618794e-01,  1.98174551e-01,  1.35126531e-01,\n",
       "         1.28762200e-01, -4.85090315e-02,  4.69657898e-01,  4.86439429e-02,\n",
       "         3.53257835e-01,  5.42547941e-01, -2.09446177e-01,  1.35347247e-01,\n",
       "         1.24633104e-01,  2.24511325e-01, -1.93987757e-01, -1.69384852e-02,\n",
       "         6.01346325e-03,  2.04649493e-01, -3.49047594e-02,  3.08254182e-01,\n",
       "         2.74999171e-01,  6.06408417e-01,  1.30885825e-01, -7.84191936e-02,\n",
       "         2.30702013e-01,  6.21092655e-02,  1.07052080e-01, -2.47026488e-01,\n",
       "         3.11956823e-01,  2.79106498e-01,  2.18370885e-01,  1.03057109e-01,\n",
       "         5.74263111e-02,  1.94899786e+00, -9.07675177e-02,  7.99698196e-03,\n",
       "         1.57724932e-01,  6.45613790e-01,  1.95434928e-01,  6.70031726e-01,\n",
       "        -1.17897667e-01,  2.08516628e-01,  1.35548666e-01,  5.05479157e-01,\n",
       "         2.27726430e-01, -2.85992660e-02,  7.31752664e-02,  2.16317698e-01,\n",
       "         1.04756050e-01,  7.34472694e-03, -9.85700116e-02, -2.09823661e-02,\n",
       "        -1.19556062e-01,  4.82213408e-01,  2.29107309e-02,  7.89495856e-02,\n",
       "         1.66905075e-01,  2.03251719e-01,  2.19120562e-01,  3.17676008e-01,\n",
       "         2.38415692e-03,  4.65317338e-04,  5.53632751e-02,  2.63843596e-01,\n",
       "        -2.68867999e-01, -6.39354065e-02,  3.14108700e-01, -1.04466088e-01,\n",
       "         2.15531588e-01,  2.69292265e-01,  6.31085504e-03,  2.11812276e-02,\n",
       "         3.03376783e-02,  1.34254768e-01,  1.78778559e-01,  9.43155289e+00,\n",
       "         2.75686860e-01,  1.31738886e-01,  1.86976731e-01,  8.58496577e-02,\n",
       "         1.49559855e-01, -2.00136185e-01, -3.02753776e-01,  6.99055195e-01,\n",
       "         1.03292175e-01,  5.93839027e-02,  6.86080813e-01, -1.75999016e-01,\n",
       "         1.97002128e-01,  2.17421085e-01,  1.00237295e-01,  2.00453222e-01,\n",
       "         5.19402325e-01,  3.03252012e-01,  1.08759388e-01,  2.52096474e-01,\n",
       "         9.80204344e-02,  6.79299794e-03,  4.11590002e-02,  3.55982512e-01,\n",
       "         9.82239395e-02, -1.27133965e-01,  5.89193106e-02, -2.11274922e-02,\n",
       "        -9.46500301e-02,  3.23439181e-01,  5.33190012e-01,  2.81205267e-01,\n",
       "        -7.00195059e-02,  4.50011939e-02,  5.85235953e-02, -2.72989403e-02,\n",
       "         1.23330429e-01,  1.57047048e-01,  6.30159453e-02, -1.79739177e-01,\n",
       "         1.68211743e-01, -2.27243900e-02,  1.42132714e-01,  2.76279449e-01,\n",
       "         4.04965654e-02, -1.99054778e-01,  3.65843683e-01,  2.73112729e-02,\n",
       "        -1.31376877e-01,  9.32270288e-02, -7.60697424e-02,  1.93399116e-02,\n",
       "         1.85015425e-03,  4.15253565e-02,  2.56592147e-02, -6.57611638e-02,\n",
       "         3.76626439e-02,  2.72211343e-01,  1.40291587e-01,  3.34124207e-01,\n",
       "        -4.18526232e-02, -9.58744287e-02,  2.74706990e-01, -1.55596823e-01,\n",
       "         3.64604779e-02, -1.32014111e-01,  1.34014981e-02, -4.87616658e-02,\n",
       "         1.06156722e-01,  5.36326528e-01,  3.72983187e-01,  3.38566378e-02,\n",
       "        -8.60288590e-02,  7.98788011e-01, -1.82336777e-01,  1.64008543e-01,\n",
       "         1.88149005e-01,  1.57651126e-01,  8.60020444e-02,  5.53895067e-03,\n",
       "         2.04019845e-02,  3.66550952e-01,  1.50018111e-01,  6.82196319e-02,\n",
       "         1.26301348e-01,  2.67437845e-01,  1.32230207e-01,  6.47044480e-02,\n",
       "         2.42651135e-01,  7.22966492e-02,  1.25669807e-01, -6.93451017e-02,\n",
       "         4.69704807e-01,  1.46840796e-01,  1.52075395e-01,  1.08058611e-02,\n",
       "         7.89734907e-03, -1.83315612e-02,  1.02967513e+00,  2.86464036e-01,\n",
       "         2.72089839e-01,  2.99726725e-02,  1.12274528e-01,  3.48836958e-01,\n",
       "        -6.20776117e-02,  2.17991203e-01,  4.28738832e-01, -4.16037142e-02,\n",
       "         3.66377145e-01,  1.08046882e-01, -2.55869627e-02, -4.00224268e-01,\n",
       "        -2.40779221e-01,  7.19139993e-01, -5.15835034e-03,  4.65480566e-01,\n",
       "         1.19287916e-01, -1.20954335e-01,  2.40479499e-01,  4.27416801e-01,\n",
       "         5.59932351e-01,  1.26139030e-01, -1.14825912e-01,  1.22176088e-01,\n",
       "         2.95618027e-02, -7.13887066e-02,  2.86794007e-01,  2.46085122e-01,\n",
       "         1.81327894e-01,  3.12949091e-01, -9.33331028e-02,  1.16926350e-03,\n",
       "        -2.63316602e-01,  3.58326316e-01,  1.62727624e-01,  3.76439899e-01,\n",
       "         3.91090691e-01,  1.10005677e-01,  1.11292467e-01,  2.07414851e-02,\n",
       "         1.14994623e-01,  6.28707856e-02,  5.34125865e-01, -2.11611167e-01,\n",
       "         5.91500774e-02, -1.58647493e-01, -3.78553174e-03,  3.52953747e-02,\n",
       "        -2.05919351e-02,  1.53826475e-01,  1.20451070e-01,  1.26241818e-01,\n",
       "        -6.20619431e-02, -1.44232456e-02, -1.47647366e-01, -1.82920575e-01,\n",
       "         2.08717108e-01,  3.31947088e-01, -8.80439430e-02,  1.55856574e+00,\n",
       "         2.22004980e-01,  2.32446954e-01,  5.67621551e-02,  3.97473991e-01,\n",
       "         5.03389001e-01, -1.44024760e-01,  1.91921026e-01, -1.38310969e-01,\n",
       "        -6.44080155e-03,  3.39745015e-01,  4.69098449e-01,  2.28332952e-02,\n",
       "         6.56073332e-01,  2.45110661e-01, -1.68141842e-01,  7.19269738e-02,\n",
       "        -1.22520126e-01, -2.34832615e-01,  1.96609661e-01,  8.65012854e-02,\n",
       "         1.28099874e-01, -9.01192203e-02,  4.89099592e-01, -1.34810328e-01,\n",
       "         1.06568784e-01,  1.27098143e-01,  4.38580155e-01,  4.55901057e-01,\n",
       "         4.61729169e-02,  1.65377498e-01,  3.57421547e-01,  9.74082127e-02,\n",
       "        -2.31282339e-01,  8.46065506e-02,  2.89760232e-01, -9.88961682e-02,\n",
       "         9.01378930e-01,  2.52402127e-01, -2.15688810e-01, -5.59736192e-02,\n",
       "        -1.13818742e-01, -6.13411656e-03, -1.34001493e-01,  1.61142886e-01,\n",
       "        -4.80620004e-02,  1.38647243e-01, -3.01776342e-02,  1.83977813e-01,\n",
       "        -1.18016593e-01,  3.89179081e-01,  6.13915585e-02,  1.58884943e-01,\n",
       "         5.89057468e-02,  5.19612193e-01,  1.23953849e-01,  5.55581629e-01,\n",
       "         5.01390219e-01, -3.79978642e-02, -1.41257286e-01,  7.03621209e-02,\n",
       "        -1.73130766e-01,  3.50397527e-01, -1.34628639e-01, -2.30107084e-02,\n",
       "         5.94515465e-02,  3.11439663e-01,  4.39245671e-01, -8.34068432e-02,\n",
       "         8.05468298e-03,  8.24325830e-02, -6.42216429e-02,  1.73451111e-01,\n",
       "         9.77575108e-02, -9.48499516e-02,  6.00330293e-01, -2.85697937e-01,\n",
       "         6.63027644e-01,  2.28900835e-01, -5.50854504e-02,  1.96810931e-01,\n",
       "         1.31078482e-01,  1.16677739e-01,  2.73458511e-01, -1.60894319e-01,\n",
       "         1.54009443e-02,  1.65677398e-01,  4.01737362e-01,  1.94677606e-01,\n",
       "        -3.40434372e-01,  4.65704620e-01, -2.72638332e-02,  9.78857726e-02,\n",
       "         3.00865740e-01,  8.31336603e-02,  6.52762055e-02,  1.93404332e-01,\n",
       "         4.39618938e-02,  1.97853178e-01,  6.20303333e-01, -2.47850232e-02,\n",
       "         3.16133723e-02,  4.27223206e-01, -1.78643763e-01,  2.27603521e-02,\n",
       "         1.01879463e-01, -1.77166402e-01, -9.12419409e-02,  6.85135424e-02,\n",
       "         2.09163412e-01,  2.12687582e-01,  2.60186791e-01, -1.92657262e-02,\n",
       "         1.86271384e-01,  8.68155286e-02, -1.64935917e-01, -6.73513263e-02,\n",
       "         3.51010323e-01,  7.94189423e-02,  3.47567499e-01, -3.27353388e-01,\n",
       "         2.28438899e-01,  1.91672705e-02,  4.34933186e-01,  2.34846137e-02,\n",
       "         5.02053857e-01,  2.87198114e+00,  3.45609011e-03, -3.42143588e-02,\n",
       "         3.52340311e-01,  4.58314866e-01, -1.96509138e-01, -1.23567872e-01,\n",
       "         1.77132830e-01,  6.33585453e-02, -2.15546321e-03,  3.33019942e-01,\n",
       "        -5.46362288e-02,  1.94658935e-01,  2.31957555e-01, -1.94247887e-01,\n",
       "         7.14528114e-02,  4.19912785e-02,  3.27715337e-01, -1.10557206e-01,\n",
       "        -1.07955880e-01,  1.31638125e-01,  2.46899307e-01,  7.21076829e-03,\n",
       "         2.77655154e-01, -1.57194927e-01,  6.24649376e-02, -1.32860814e-03,\n",
       "        -1.57012362e-02,  2.07436994e-01, -9.61607322e-03, -4.07151505e-02,\n",
       "         3.30549240e-01, -5.71658760e-02,  5.70487320e-01, -1.03581101e-01,\n",
       "        -1.79280698e-01,  3.29045117e-01,  5.74648529e-02, -8.48884210e-02,\n",
       "         1.71312660e-01, -5.71665429e-02,  3.82779270e-01,  2.49197200e-01,\n",
       "        -1.67588264e-01, -5.42712435e-02,  4.65058923e-01, -3.14851582e-01,\n",
       "         3.38773549e-01, -1.19772919e-01,  7.56180510e-02,  2.71076292e-01,\n",
       "         1.29012525e-01,  1.41996786e-01,  3.30376983e-01,  2.09672466e-01,\n",
       "         2.74694502e-01,  1.87327504e-01,  2.14084148e-01,  1.21977694e-01,\n",
       "         5.93084395e-01,  2.13688929e-02,  8.09027970e-01,  3.09404194e-01,\n",
       "         3.44152540e-01,  1.66218415e-01,  1.36155128e-01,  2.33373582e-01,\n",
       "         8.00405815e-03,  1.03328384e-01,  6.38187110e-01, -2.65396535e-02],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense/kernel:0' shape=(32768, 512) dtype=float32, numpy=\n",
       " array([[-0.00343867,  0.00970074,  0.00761419, ...,  0.00472174,\n",
       "          0.01278673, -0.00838173],\n",
       "        [ 0.00674719, -0.0037171 , -0.01276275, ..., -0.00701244,\n",
       "         -0.00815223, -0.00045384],\n",
       "        [-0.00096254,  0.00420359, -0.00218798, ..., -0.00727353,\n",
       "         -0.0122852 , -0.00809226],\n",
       "        ...,\n",
       "        [ 0.00648587,  0.00230318, -0.00578238, ...,  0.00268827,\n",
       "          0.00555896,  0.00891508],\n",
       "        [-0.01293176,  0.01324635,  0.00151865, ..., -0.00696855,\n",
       "         -0.00798706,  0.00062717],\n",
       "        [-0.00239865, -0.00298386,  0.01139854, ...,  0.00129829,\n",
       "          0.00589423, -0.00914223]], dtype=float32)>,\n",
       " <tf.Variable 'dense/bias:0' shape=(512,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'dense_1/kernel:0' shape=(512, 3) dtype=float32, numpy=\n",
       " array([[-0.00888144,  0.01210425, -0.0667401 ],\n",
       "        [ 0.05661795,  0.09621903,  0.06116671],\n",
       "        [ 0.08479334, -0.07124434, -0.06974751],\n",
       "        ...,\n",
       "        [ 0.02017195, -0.09863566, -0.03432756],\n",
       "        [-0.09172217, -0.06379514,  0.05645891],\n",
       "        [ 0.06042523, -0.10636619, -0.04233239]], dtype=float32)>,\n",
       " <tf.Variable 'dense_1/bias:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>]"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# Create Model\n",
    "# ------------\n",
    "\n",
    "finetuning = True\n",
    "\n",
    "if finetuning:\n",
    "    freeze_until = 15 # layer from which we want to fine-tune\n",
    "    \n",
    "    for layer in vgg.layers[:freeze_until]:\n",
    "        layer.trainable = False\n",
    "else:\n",
    "    vgg.trainable = False\n",
    "    \n",
    "model = tf.keras.Sequential()\n",
    "model.add(vgg)\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(units=512, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(units=num_classes, activation='softmax'))\n",
    "\n",
    "# Visualize created model as a table\n",
    "model.summary()\n",
    "\n",
    "# Visualize initialized weights\n",
    "model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization params\n",
    "# -------------------\n",
    "\n",
    "# Loss\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "# learning rate\n",
    "lr = 1e-4\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "# -------------------\n",
    "\n",
    "# Validation metrics\n",
    "# ------------------\n",
    "\n",
    "metrics = ['accuracy']\n",
    "# ------------------\n",
    "\n",
    "# Compile Model\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "source": [
    "## Training with callbacks\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# from tensorflow.compat.v1 import ConfigProto\n",
    "# from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "# config = ConfigProto()\n",
    "# config.gpu_options.allow_growth = True\n",
    "# session = InteractiveSession(config=config)\n",
    "\n",
    "cwd = '/content/drive/My Drive/Keras3'\n",
    "\n",
    "exps_dir = os.path.join(cwd, 'transfer_learning_experiments')\n",
    "if not os.path.exists(exps_dir):\n",
    "    os.makedirs(exps_dir)\n",
    "\n",
    "now = datetime.now().strftime('%b%d_%H-%M-%S')\n",
    "\n",
    "model_name = 'CNN'\n",
    "\n",
    "exp_dir = os.path.join(exps_dir, model_name + '_' + str(now))\n",
    "if not os.path.exists(exp_dir):\n",
    "    os.makedirs(exp_dir)\n",
    "    \n",
    "callbacks = []\n",
    "\n",
    "# Model checkpoint\n",
    "# ----------------\n",
    "ckpt_dir = os.path.join(exp_dir, 'ckpts')\n",
    "if not os.path.exists(ckpt_dir):\n",
    "    os.makedirs(ckpt_dir)\n",
    "\n",
    "ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(ckpt_dir, 'cp.ckpt'), \n",
    "                                                   save_weights_only=True)  # False to save the model directly\n",
    "callbacks.append(ckpt_callback)\n",
    "\n",
    "# Visualize Learning on Tensorboard\n",
    "# ---------------------------------\n",
    "tb_dir = os.path.join(exp_dir, 'tb_logs')\n",
    "if not os.path.exists(tb_dir):\n",
    "    os.makedirs(tb_dir)\n",
    "    \n",
    "# By default shows losses and metrics for both training and validation\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_dir,\n",
    "                                             profile_batch=0,\n",
    "                                             histogram_freq=1)  # if 1 shows weights histograms\n",
    "callbacks.append(tb_callback)\n",
    "\n",
    "# Early Stopping\n",
    "# --------------\n",
    "early_stop = False\n",
    "if early_stop:\n",
    "    es_callback = tf.keras.callback.EarlyStopping(monitor='val_loss', patience=10)\n",
    "    callbacks.append(es_callback)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train for 562 steps, validate for 141 steps\n",
      "Epoch 1/30\n",
      "562/562 [==============================] - 344s 612ms/step - loss: 0.9268 - accuracy: 0.5252 - val_loss: 0.7592 - val_accuracy: 0.6194\n",
      "Epoch 2/30\n",
      "562/562 [==============================] - 337s 600ms/step - loss: 0.7117 - accuracy: 0.6618 - val_loss: 0.6235 - val_accuracy: 0.6845\n",
      "Epoch 3/30\n",
      "562/562 [==============================] - 337s 600ms/step - loss: 0.6525 - accuracy: 0.6950 - val_loss: 0.6237 - val_accuracy: 0.6952\n",
      "Epoch 4/30\n",
      "562/562 [==============================] - 336s 598ms/step - loss: 0.6056 - accuracy: 0.7193 - val_loss: 0.5982 - val_accuracy: 0.7157\n",
      "Epoch 5/30\n",
      "562/562 [==============================] - 337s 600ms/step - loss: 0.5600 - accuracy: 0.7378 - val_loss: 0.5879 - val_accuracy: 0.7531\n",
      "Epoch 6/30\n",
      "562/562 [==============================] - 340s 604ms/step - loss: 0.5339 - accuracy: 0.7533 - val_loss: 0.4974 - val_accuracy: 0.7594\n",
      "Epoch 7/30\n",
      "562/562 [==============================] - 336s 597ms/step - loss: 0.4976 - accuracy: 0.7774 - val_loss: 0.4644 - val_accuracy: 0.7959\n",
      "Epoch 8/30\n",
      "562/562 [==============================] - 338s 601ms/step - loss: 0.4657 - accuracy: 0.7901 - val_loss: 0.5219 - val_accuracy: 0.7683\n",
      "Epoch 9/30\n",
      "562/562 [==============================] - 338s 601ms/step - loss: 0.4300 - accuracy: 0.8070 - val_loss: 0.4097 - val_accuracy: 0.8173\n",
      "Epoch 10/30\n",
      "562/562 [==============================] - 336s 598ms/step - loss: 0.4207 - accuracy: 0.8166 - val_loss: 0.4858 - val_accuracy: 0.8012\n",
      "Epoch 11/30\n",
      "562/562 [==============================] - 337s 599ms/step - loss: 0.4057 - accuracy: 0.8210 - val_loss: 0.4574 - val_accuracy: 0.7959\n",
      "Epoch 12/30\n",
      "562/562 [==============================] - 345s 613ms/step - loss: 0.3746 - accuracy: 0.8350 - val_loss: 0.4057 - val_accuracy: 0.8280\n",
      "Epoch 13/30\n",
      "562/562 [==============================] - 342s 608ms/step - loss: 0.3455 - accuracy: 0.8535 - val_loss: 0.4418 - val_accuracy: 0.8298\n",
      "Epoch 14/30\n",
      "562/562 [==============================] - 339s 604ms/step - loss: 0.3483 - accuracy: 0.8506 - val_loss: 0.4194 - val_accuracy: 0.8387\n",
      "Epoch 15/30\n",
      "562/562 [==============================] - 339s 603ms/step - loss: 0.3216 - accuracy: 0.8671 - val_loss: 0.5717 - val_accuracy: 0.7701\n",
      "Epoch 16/30\n",
      "562/562 [==============================] - 337s 600ms/step - loss: 0.3132 - accuracy: 0.8718 - val_loss: 0.4459 - val_accuracy: 0.8173\n",
      "Epoch 17/30\n",
      "562/562 [==============================] - 340s 605ms/step - loss: 0.2994 - accuracy: 0.8787 - val_loss: 0.4335 - val_accuracy: 0.8298\n",
      "Epoch 18/30\n",
      "562/562 [==============================] - 337s 599ms/step - loss: 0.2770 - accuracy: 0.8902 - val_loss: 0.4524 - val_accuracy: 0.8271\n",
      "Epoch 19/30\n",
      "562/562 [==============================] - 336s 598ms/step - loss: 0.2689 - accuracy: 0.8887 - val_loss: 0.4051 - val_accuracy: 0.8449\n",
      "Epoch 20/30\n",
      "562/562 [==============================] - 337s 600ms/step - loss: 0.2712 - accuracy: 0.8920 - val_loss: 0.4051 - val_accuracy: 0.8503\n",
      "Epoch 21/30\n",
      "562/562 [==============================] - 337s 600ms/step - loss: 0.2521 - accuracy: 0.8989 - val_loss: 0.3963 - val_accuracy: 0.8431\n",
      "Epoch 22/30\n",
      "562/562 [==============================] - 336s 599ms/step - loss: 0.2440 - accuracy: 0.8992 - val_loss: 0.5216 - val_accuracy: 0.8111\n",
      "Epoch 23/30\n",
      "562/562 [==============================] - 337s 599ms/step - loss: 0.2307 - accuracy: 0.9074 - val_loss: 0.5508 - val_accuracy: 0.8137\n",
      "Epoch 24/30\n",
      "562/562 [==============================] - 337s 600ms/step - loss: 0.2215 - accuracy: 0.9123 - val_loss: 0.4594 - val_accuracy: 0.8449\n",
      "Epoch 25/30\n",
      "562/562 [==============================] - 338s 601ms/step - loss: 0.2170 - accuracy: 0.9127 - val_loss: 0.5015 - val_accuracy: 0.8280\n",
      "Epoch 26/30\n",
      "562/562 [==============================] - 342s 609ms/step - loss: 0.1990 - accuracy: 0.9203 - val_loss: 0.5338 - val_accuracy: 0.8289\n",
      "Epoch 27/30\n",
      "562/562 [==============================] - 339s 603ms/step - loss: 0.2024 - accuracy: 0.9150 - val_loss: 0.5040 - val_accuracy: 0.8414\n",
      "Epoch 28/30\n",
      "562/562 [==============================] - 338s 601ms/step - loss: 0.1900 - accuracy: 0.9243 - val_loss: 0.5361 - val_accuracy: 0.8182\n",
      "Epoch 29/30\n",
      "562/562 [==============================] - 338s 602ms/step - loss: 0.1869 - accuracy: 0.9308 - val_loss: 0.5672 - val_accuracy: 0.8226\n",
      "Epoch 30/30\n",
      "562/562 [==============================] - 338s 601ms/step - loss: 0.1813 - accuracy: 0.9334 - val_loss: 0.5566 - val_accuracy: 0.8253\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ec88ac0388>"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "model.fit(x=train_dataset,\n",
    "          epochs=30,  #### set repeat in training dataset\n",
    "          steps_per_epoch=len(train_gen),\n",
    "          validation_data=valid_dataset,\n",
    "          validation_steps=len(valid_gen), \n",
    "          callbacks=callbacks)\n",
    "\n",
    "# How to visualize Tensorboard\n",
    "\n",
    "# 1. tensorboard --logdir EXPERIMENTS_DIR --port PORT     <- from terminal\n",
    "# 2. localhost:PORT   <- in your browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 450 validated image filenames belonging to 1 classes.\n",
      "WARNING:tensorflow:From <ipython-input-10-ff6b512ee0fe>:33: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.predict, which supports generators.\n",
      "57/57 [==============================] - 23s 397ms/step\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def create_csv(results, results_dir='./'):\n",
    "\n",
    "    csv_fname = 'results_'\n",
    "    csv_fname += datetime.now().strftime('%b%d_%H-%M-%S') + '.csv'\n",
    "\n",
    "    with open(os.path.join(results_dir, csv_fname), 'w') as f:\n",
    "\n",
    "        f.write('Id,Category\\n')\n",
    "\n",
    "        for key, value in results.items():\n",
    "            f.write(key + ',' + str(value) + '\\n')\n",
    "\n",
    "\n",
    "test_dir = os.path.join(dataset_dir, 'test')\n",
    "\n",
    "images = [f for f in os.listdir(test_dir)]\n",
    "images = pd.DataFrame(images)\n",
    "images.rename(columns = {0:'filename'}, inplace = True)\n",
    "images[\"class\"] = 'test'\n",
    "\n",
    "test_gen = train_data_gen.flow_from_dataframe(images,\n",
    "                                               test_dir,\n",
    "                                               batch_size=bs,\n",
    "                                               target_size=(img_h, img_w),\n",
    "                                               class_mode='categorical',\n",
    "                                               shuffle=False,\n",
    "                                               seed=SEED)\n",
    "\n",
    "\n",
    "test_gen.reset()\n",
    "\n",
    "predictions = model.predict_generator(test_gen, len(test_gen), verbose=1)\n",
    "\n",
    "results = {}\n",
    "images = test_gen.filenames\n",
    "i = 0\n",
    "\n",
    "for p in predictions:\n",
    "  prediction = np.argmax(p)\n",
    "  import ntpath\n",
    "  image_name = ntpath.basename(images[i])\n",
    "  results[image_name] = str(prediction)\n",
    "  i = i + 1\n",
    "\n",
    "create_csv(results,dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train for 562 steps, validate for 141 steps\n",
      "Epoch 1/15\n",
      "562/562 [==============================] - 338s 601ms/step - loss: 0.1724 - accuracy: 0.9328 - val_loss: 0.6044 - val_accuracy: 0.8200\n",
      "Epoch 2/15\n",
      "562/562 [==============================] - 339s 603ms/step - loss: 0.1623 - accuracy: 0.9352 - val_loss: 0.5681 - val_accuracy: 0.8137\n",
      "Epoch 3/15\n",
      "562/562 [==============================] - 361s 642ms/step - loss: 0.1530 - accuracy: 0.9426 - val_loss: 0.5235 - val_accuracy: 0.8333\n",
      "Epoch 4/15\n",
      "562/562 [==============================] - 337s 600ms/step - loss: 0.1520 - accuracy: 0.9459 - val_loss: 0.5073 - val_accuracy: 0.8494\n",
      "Epoch 5/15\n",
      "562/562 [==============================] - 337s 600ms/step - loss: 0.1679 - accuracy: 0.9386 - val_loss: 0.5371 - val_accuracy: 0.8414\n",
      "Epoch 6/15\n",
      "562/562 [==============================] - 337s 601ms/step - loss: 0.1471 - accuracy: 0.9441 - val_loss: 0.4575 - val_accuracy: 0.8512\n",
      "Epoch 7/15\n",
      "562/562 [==============================] - 338s 601ms/step - loss: 0.1379 - accuracy: 0.9477 - val_loss: 0.4668 - val_accuracy: 0.8494\n",
      "Epoch 8/15\n",
      "562/562 [==============================] - 338s 601ms/step - loss: 0.1356 - accuracy: 0.9517 - val_loss: 0.5784 - val_accuracy: 0.8458\n",
      "Epoch 9/15\n",
      "562/562 [==============================] - 850s 2s/step - loss: 0.1254 - accuracy: 0.9524 - val_loss: 0.5133 - val_accuracy: 0.8476\n",
      "Epoch 10/15\n",
      "562/562 [==============================] - 338s 601ms/step - loss: 0.1336 - accuracy: 0.9481 - val_loss: 0.5439 - val_accuracy: 0.8200\n",
      "Epoch 11/15\n",
      "562/562 [==============================] - 337s 600ms/step - loss: 0.1178 - accuracy: 0.9559 - val_loss: 0.7291 - val_accuracy: 0.8173\n",
      "Epoch 12/15\n",
      "562/562 [==============================] - 338s 602ms/step - loss: 0.1027 - accuracy: 0.9613 - val_loss: 0.6222 - val_accuracy: 0.8271\n",
      "Epoch 13/15\n",
      "562/562 [==============================] - 338s 601ms/step - loss: 0.1261 - accuracy: 0.9564 - val_loss: 0.5306 - val_accuracy: 0.8529\n",
      "Epoch 14/15\n",
      "562/562 [==============================] - 340s 605ms/step - loss: 0.1192 - accuracy: 0.9541 - val_loss: 0.7954 - val_accuracy: 0.7897\n",
      "Epoch 15/15\n",
      "562/562 [==============================] - 340s 604ms/step - loss: 0.1300 - accuracy: 0.9524 - val_loss: 0.4678 - val_accuracy: 0.8619\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ec88a9ca88>"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "model.fit(x=train_dataset,\n",
    "          epochs=15,  #### set repeat in training dataset\n",
    "          steps_per_epoch=len(train_gen),\n",
    "          validation_data=valid_dataset,\n",
    "          validation_steps=len(valid_gen), \n",
    "          callbacks=callbacks)\n",
    "\n",
    "# How to visualize Tensorboard\n",
    "\n",
    "# 1. tensorboard --logdir EXPERIMENTS_DIR --port PORT     <- from terminal\n",
    "# 2. localhost:PORT   <- in your browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 450 validated image filenames belonging to 1 classes.\n",
      "57/57 [==============================] - 24s 416ms/step\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def create_csv(results, results_dir='./'):\n",
    "\n",
    "    csv_fname = 'results_'\n",
    "    csv_fname += datetime.now().strftime('%b%d_%H-%M-%S') + '.csv'\n",
    "\n",
    "    with open(os.path.join(results_dir, csv_fname), 'w') as f:\n",
    "\n",
    "        f.write('Id,Category\\n')\n",
    "\n",
    "        for key, value in results.items():\n",
    "            f.write(key + ',' + str(value) + '\\n')\n",
    "\n",
    "\n",
    "test_dir = os.path.join(dataset_dir, 'test')\n",
    "\n",
    "images = [f for f in os.listdir(test_dir)]\n",
    "images = pd.DataFrame(images)\n",
    "images.rename(columns = {0:'filename'}, inplace = True)\n",
    "images[\"class\"] = 'test'\n",
    "\n",
    "test_gen = train_data_gen.flow_from_dataframe(images,\n",
    "                                               test_dir,\n",
    "                                               batch_size=bs,\n",
    "                                               target_size=(img_h, img_w),\n",
    "                                               class_mode='categorical',\n",
    "                                               shuffle=False,\n",
    "                                               seed=SEED)\n",
    "\n",
    "\n",
    "test_gen.reset()\n",
    "\n",
    "predictions = model.predict_generator(test_gen, len(test_gen), verbose=1)\n",
    "\n",
    "results = {}\n",
    "images = test_gen.filenames\n",
    "i = 0\n",
    "\n",
    "for p in predictions:\n",
    "  prediction = np.argmax(p)\n",
    "  import ntpath\n",
    "  image_name = ntpath.basename(images[i])\n",
    "  results[image_name] = str(prediction)\n",
    "  i = i + 1\n",
    "\n",
    "create_csv(results,dataset_dir)"
   ]
  },
  {
   "source": [
    "## Desnet model\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 4492 images belonging to 3 classes.\nFound 1122 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "apply_data_augmentation = True\n",
    "\n",
    "if apply_data_augmentation:\n",
    "    train_data_gen = ImageDataGenerator(\n",
    "        rotation_range=10,\n",
    "        width_shift_range=10,\n",
    "        height_shift_range=10,\n",
    "        zoom_range=0.3,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        fill_mode='constant',\n",
    "        cval=0,\n",
    "        rescale=1/255.\n",
    "    )\n",
    "else:\n",
    "    train_data_gen = ImageDataGenerator(rescale=1/255.)\n",
    "\n",
    "valid_data_gen = ImageDataGenerator(rescale=1/255.)\n",
    "# test_data_gen = ImageDataGenerator(rescale=1/255.)\n",
    "\n",
    "bs = 8\n",
    "\n",
    "train_gen = train_data_gen.flow_from_directory(\n",
    "    training_dir,\n",
    "    batch_size=bs,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "valid_gen = valid_data_gen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    batch_size=bs,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "# test_gen = test_data_gen.flow_from_directory(\n",
    "#     test_dir,\n",
    "#     batch_size=bs,\n",
    "#     class_mode='categorical',\n",
    "#     shuffle=True,\n",
    "#     seed=SEED\n",
    "# )\n",
    "\n",
    "img_h = 256\n",
    "img_w = 256\n",
    "\n",
    "num_classes = len(classes)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: train_gen,\n",
    "    output_types=(tf.float32, tf.float32),\n",
    "    output_shapes=([None, 224, 224, 3], [None, num_classes])\n",
    ")\n",
    "\n",
    "train_dataset = train_dataset.repeat()\n",
    "\n",
    "valid_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: valid_gen,\n",
    "    output_types=(tf.float32, tf.float32),\n",
    "    output_shapes=([None, 224, 224, 3], [None, num_classes])\n",
    ")\n",
    "\n",
    "valid_dataset = valid_dataset.repeat()\n",
    "\n",
    "# test_dataset = tf.data.Dataset.from_generator(\n",
    "#     lambda: test_gen,\n",
    "#     output_types=(tf.float32, tf.float32),\n",
    "#     output_shapes=([None, 256, 256, 3], [None, num_classes])\n",
    "# )\n",
    "\n",
    "# test_dataset = test_dataset.repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using TensorFlow backend.\n",
      "Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet152_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "234700800/234698864 [==============================] - 175s 1us/step\n",
      "Capa input_1 freeze...\n",
      "Capa conv1_pad freeze...\n",
      "Capa conv1_conv freeze...\n",
      "Capa conv1_bn freeze...\n",
      "Capa conv1_relu freeze...\n",
      "Capa pool1_pad freeze...\n",
      "Capa pool1_pool freeze...\n",
      "Capa conv2_block1_1_conv freeze...\n",
      "Capa conv2_block1_1_bn freeze...\n",
      "Capa conv2_block1_1_relu freeze...\n",
      "Capa conv2_block1_2_conv freeze...\n",
      "Capa conv2_block1_2_bn freeze...\n",
      "Capa conv2_block1_2_relu freeze...\n",
      "Capa conv2_block1_0_conv freeze...\n",
      "Capa conv2_block1_3_conv freeze...\n",
      "Capa conv2_block1_0_bn freeze...\n",
      "Capa conv2_block1_3_bn freeze...\n",
      "Capa conv2_block1_add freeze...\n",
      "Capa conv2_block1_out freeze...\n",
      "Capa conv2_block2_1_conv freeze...\n",
      "Capa conv2_block2_1_bn freeze...\n",
      "Capa conv2_block2_1_relu freeze...\n",
      "Capa conv2_block2_2_conv freeze...\n",
      "Capa conv2_block2_2_bn freeze...\n",
      "Capa conv2_block2_2_relu freeze...\n",
      "Capa conv2_block2_3_conv freeze...\n",
      "Capa conv2_block2_3_bn freeze...\n",
      "Capa conv2_block2_add freeze...\n",
      "Capa conv2_block2_out freeze...\n",
      "Capa conv2_block3_1_conv freeze...\n",
      "Capa conv2_block3_1_bn freeze...\n",
      "Capa conv2_block3_1_relu freeze...\n",
      "Capa conv2_block3_2_conv freeze...\n",
      "Capa conv2_block3_2_bn freeze...\n",
      "Capa conv2_block3_2_relu freeze...\n",
      "Capa conv2_block3_3_conv freeze...\n",
      "Capa conv2_block3_3_bn freeze...\n",
      "Capa conv2_block3_add freeze...\n",
      "Capa conv2_block3_out freeze...\n",
      "Capa conv3_block1_1_conv freeze...\n",
      "Capa conv3_block1_1_bn freeze...\n",
      "Capa conv3_block1_1_relu freeze...\n",
      "Capa conv3_block1_2_conv freeze...\n",
      "Capa conv3_block1_2_bn freeze...\n",
      "Capa conv3_block1_2_relu freeze...\n",
      "Capa conv3_block1_0_conv freeze...\n",
      "Capa conv3_block1_3_conv freeze...\n",
      "Capa conv3_block1_0_bn freeze...\n",
      "Capa conv3_block1_3_bn freeze...\n",
      "Capa conv3_block1_add freeze...\n",
      "Capa conv3_block1_out freeze...\n",
      "Capa conv3_block2_1_conv freeze...\n",
      "Capa conv3_block2_1_bn freeze...\n",
      "Capa conv3_block2_1_relu freeze...\n",
      "Capa conv3_block2_2_conv freeze...\n",
      "Capa conv3_block2_2_bn freeze...\n",
      "Capa conv3_block2_2_relu freeze...\n",
      "Capa conv3_block2_3_conv freeze...\n",
      "Capa conv3_block2_3_bn freeze...\n",
      "Capa conv3_block2_add freeze...\n",
      "Capa conv3_block2_out freeze...\n",
      "Capa conv3_block3_1_conv freeze...\n",
      "Capa conv3_block3_1_bn freeze...\n",
      "Capa conv3_block3_1_relu freeze...\n",
      "Capa conv3_block3_2_conv freeze...\n",
      "Capa conv3_block3_2_bn freeze...\n",
      "Capa conv3_block3_2_relu freeze...\n",
      "Capa conv3_block3_3_conv freeze...\n",
      "Capa conv3_block3_3_bn freeze...\n",
      "Capa conv3_block3_add freeze...\n",
      "Capa conv3_block3_out freeze...\n",
      "Capa conv3_block4_1_conv freeze...\n",
      "Capa conv3_block4_1_bn freeze...\n",
      "Capa conv3_block4_1_relu freeze...\n",
      "Capa conv3_block4_2_conv freeze...\n",
      "Capa conv3_block4_2_bn freeze...\n",
      "Capa conv3_block4_2_relu freeze...\n",
      "Capa conv3_block4_3_conv freeze...\n",
      "Capa conv3_block4_3_bn freeze...\n",
      "Capa conv3_block4_add freeze...\n",
      "Capa conv3_block4_out freeze...\n",
      "Capa conv3_block5_1_conv freeze...\n",
      "Capa conv3_block5_1_bn freeze...\n",
      "Capa conv3_block5_1_relu freeze...\n",
      "Capa conv3_block5_2_conv freeze...\n",
      "Capa conv3_block5_2_bn freeze...\n",
      "Capa conv3_block5_2_relu freeze...\n",
      "Capa conv3_block5_3_conv freeze...\n",
      "Capa conv3_block5_3_bn freeze...\n",
      "Capa conv3_block5_add freeze...\n",
      "Capa conv3_block5_out freeze...\n",
      "Capa conv3_block6_1_conv freeze...\n",
      "Capa conv3_block6_1_bn freeze...\n",
      "Capa conv3_block6_1_relu freeze...\n",
      "Capa conv3_block6_2_conv freeze...\n",
      "Capa conv3_block6_2_bn freeze...\n",
      "Capa conv3_block6_2_relu freeze...\n",
      "Capa conv3_block6_3_conv freeze...\n",
      "Capa conv3_block6_3_bn freeze...\n",
      "Capa conv3_block6_add freeze...\n",
      "Capa conv3_block6_out freeze...\n",
      "Capa conv3_block7_1_conv freeze...\n",
      "Capa conv3_block7_1_bn freeze...\n",
      "Capa conv3_block7_1_relu freeze...\n",
      "Capa conv3_block7_2_conv freeze...\n",
      "Capa conv3_block7_2_bn freeze...\n",
      "Capa conv3_block7_2_relu freeze...\n",
      "Capa conv3_block7_3_conv freeze...\n",
      "Capa conv3_block7_3_bn freeze...\n",
      "Capa conv3_block7_add freeze...\n",
      "Capa conv3_block7_out freeze...\n",
      "Capa conv3_block8_1_conv freeze...\n",
      "Capa conv3_block8_1_bn freeze...\n",
      "Capa conv3_block8_1_relu freeze...\n",
      "Capa conv3_block8_2_conv freeze...\n",
      "Capa conv3_block8_2_bn freeze...\n",
      "Capa conv3_block8_2_relu freeze...\n",
      "Capa conv3_block8_3_conv freeze...\n",
      "Capa conv3_block8_3_bn freeze...\n",
      "Capa conv3_block8_add freeze...\n",
      "Capa conv3_block8_out freeze...\n",
      "Capa conv4_block1_1_conv freeze...\n",
      "Capa conv4_block1_1_bn freeze...\n",
      "Capa conv4_block1_1_relu freeze...\n",
      "Capa conv4_block1_2_conv freeze...\n",
      "Capa conv4_block1_2_bn freeze...\n",
      "Capa conv4_block1_2_relu freeze...\n",
      "Capa conv4_block1_0_conv freeze...\n",
      "Capa conv4_block1_3_conv freeze...\n",
      "Capa conv4_block1_0_bn freeze...\n",
      "Capa conv4_block1_3_bn freeze...\n",
      "Capa conv4_block1_add freeze...\n",
      "Capa conv4_block1_out freeze...\n",
      "Capa conv4_block2_1_conv freeze...\n",
      "Capa conv4_block2_1_bn freeze...\n",
      "Capa conv4_block2_1_relu freeze...\n",
      "Capa conv4_block2_2_conv freeze...\n",
      "Capa conv4_block2_2_bn freeze...\n",
      "Capa conv4_block2_2_relu freeze...\n",
      "Capa conv4_block2_3_conv freeze...\n",
      "Capa conv4_block2_3_bn freeze...\n",
      "Capa conv4_block2_add freeze...\n",
      "Capa conv4_block2_out freeze...\n",
      "Capa conv4_block3_1_conv freeze...\n",
      "Capa conv4_block3_1_bn freeze...\n",
      "Capa conv4_block3_1_relu freeze...\n",
      "Capa conv4_block3_2_conv freeze...\n",
      "Capa conv4_block3_2_bn freeze...\n",
      "Capa conv4_block3_2_relu freeze...\n",
      "Capa conv4_block3_3_conv freeze...\n",
      "Capa conv4_block3_3_bn freeze...\n",
      "Capa conv4_block3_add freeze...\n",
      "Capa conv4_block3_out freeze...\n",
      "Capa conv4_block4_1_conv freeze...\n",
      "Capa conv4_block4_1_bn freeze...\n",
      "Capa conv4_block4_1_relu freeze...\n",
      "Capa conv4_block4_2_conv freeze...\n",
      "Capa conv4_block4_2_bn freeze...\n",
      "Capa conv4_block4_2_relu freeze...\n",
      "Capa conv4_block4_3_conv freeze...\n",
      "Capa conv4_block4_3_bn freeze...\n",
      "Capa conv4_block4_add freeze...\n",
      "Capa conv4_block4_out freeze...\n",
      "Capa conv4_block5_1_conv freeze...\n",
      "Capa conv4_block5_1_bn freeze...\n",
      "Capa conv4_block5_1_relu freeze...\n",
      "Capa conv4_block5_2_conv freeze...\n",
      "Capa conv4_block5_2_bn freeze...\n",
      "Capa conv4_block5_2_relu freeze...\n",
      "Capa conv4_block5_3_conv freeze...\n",
      "Capa conv4_block5_3_bn freeze...\n",
      "Capa conv4_block5_add freeze...\n",
      "Capa conv4_block5_out freeze...\n",
      "Capa conv4_block6_1_conv freeze...\n",
      "Capa conv4_block6_1_bn freeze...\n",
      "Capa conv4_block6_1_relu freeze...\n",
      "Capa conv4_block6_2_conv freeze...\n",
      "Capa conv4_block6_2_bn freeze...\n",
      "Capa conv4_block6_2_relu freeze...\n",
      "Capa conv4_block6_3_conv freeze...\n",
      "Capa conv4_block6_3_bn freeze...\n",
      "Capa conv4_block6_add freeze...\n",
      "Capa conv4_block6_out freeze...\n",
      "Capa conv4_block7_1_conv freeze...\n",
      "Capa conv4_block7_1_bn freeze...\n",
      "Capa conv4_block7_1_relu freeze...\n",
      "Capa conv4_block7_2_conv freeze...\n",
      "Capa conv4_block7_2_bn freeze...\n",
      "Capa conv4_block7_2_relu freeze...\n",
      "Capa conv4_block7_3_conv freeze...\n",
      "Capa conv4_block7_3_bn freeze...\n",
      "Capa conv4_block7_add freeze...\n",
      "Capa conv4_block7_out freeze...\n",
      "Capa conv4_block8_1_conv freeze...\n",
      "Capa conv4_block8_1_bn freeze...\n",
      "Capa conv4_block8_1_relu freeze...\n",
      "Capa conv4_block8_2_conv freeze...\n",
      "Capa conv4_block8_2_bn freeze...\n",
      "Capa conv4_block8_2_relu freeze...\n",
      "Capa conv4_block8_3_conv freeze...\n",
      "Capa conv4_block8_3_bn freeze...\n",
      "Capa conv4_block8_add freeze...\n",
      "Capa conv4_block8_out freeze...\n",
      "Capa conv4_block9_1_conv freeze...\n",
      "Capa conv4_block9_1_bn freeze...\n",
      "Capa conv4_block9_1_relu freeze...\n",
      "Capa conv4_block9_2_conv freeze...\n",
      "Capa conv4_block9_2_bn freeze...\n",
      "Capa conv4_block9_2_relu freeze...\n",
      "Capa conv4_block9_3_conv freeze...\n",
      "Capa conv4_block9_3_bn freeze...\n",
      "Capa conv4_block9_add freeze...\n",
      "Capa conv4_block9_out freeze...\n",
      "Capa conv4_block10_1_conv freeze...\n",
      "Capa conv4_block10_1_bn freeze...\n",
      "Capa conv4_block10_1_relu freeze...\n",
      "Capa conv4_block10_2_conv freeze...\n",
      "Capa conv4_block10_2_bn freeze...\n",
      "Capa conv4_block10_2_relu freeze...\n",
      "Capa conv4_block10_3_conv freeze...\n",
      "Capa conv4_block10_3_bn freeze...\n",
      "Capa conv4_block10_add freeze...\n",
      "Capa conv4_block10_out freeze...\n",
      "Capa conv4_block11_1_conv freeze...\n",
      "Capa conv4_block11_1_bn freeze...\n",
      "Capa conv4_block11_1_relu freeze...\n",
      "Capa conv4_block11_2_conv freeze...\n",
      "Capa conv4_block11_2_bn freeze...\n",
      "Capa conv4_block11_2_relu freeze...\n",
      "Capa conv4_block11_3_conv freeze...\n",
      "Capa conv4_block11_3_bn freeze...\n",
      "Capa conv4_block11_add freeze...\n",
      "Capa conv4_block11_out freeze...\n",
      "Capa conv4_block12_1_conv freeze...\n",
      "Capa conv4_block12_1_bn freeze...\n",
      "Capa conv4_block12_1_relu freeze...\n",
      "Capa conv4_block12_2_conv freeze...\n",
      "Capa conv4_block12_2_bn freeze...\n",
      "Capa conv4_block12_2_relu freeze...\n",
      "Capa conv4_block12_3_conv freeze...\n",
      "Capa conv4_block12_3_bn freeze...\n",
      "Capa conv4_block12_add freeze...\n",
      "Capa conv4_block12_out freeze...\n",
      "Capa conv4_block13_1_conv freeze...\n",
      "Capa conv4_block13_1_bn freeze...\n",
      "Capa conv4_block13_1_relu freeze...\n",
      "Capa conv4_block13_2_conv freeze...\n",
      "Capa conv4_block13_2_bn freeze...\n",
      "Capa conv4_block13_2_relu freeze...\n",
      "Capa conv4_block13_3_conv freeze...\n",
      "Capa conv4_block13_3_bn freeze...\n",
      "Capa conv4_block13_add freeze...\n",
      "Capa conv4_block13_out freeze...\n",
      "Capa conv4_block14_1_conv freeze...\n",
      "Capa conv4_block14_1_bn freeze...\n",
      "Capa conv4_block14_1_relu freeze...\n",
      "Capa conv4_block14_2_conv freeze...\n",
      "Capa conv4_block14_2_bn freeze...\n",
      "Capa conv4_block14_2_relu freeze...\n",
      "Capa conv4_block14_3_conv freeze...\n",
      "Capa conv4_block14_3_bn freeze...\n",
      "Capa conv4_block14_add freeze...\n",
      "Capa conv4_block14_out freeze...\n",
      "Capa conv4_block15_1_conv freeze...\n",
      "Capa conv4_block15_1_bn freeze...\n",
      "Capa conv4_block15_1_relu freeze...\n",
      "Capa conv4_block15_2_conv freeze...\n",
      "Capa conv4_block15_2_bn freeze...\n",
      "Capa conv4_block15_2_relu freeze...\n",
      "Capa conv4_block15_3_conv freeze...\n",
      "Capa conv4_block15_3_bn freeze...\n",
      "Capa conv4_block15_add freeze...\n",
      "Capa conv4_block15_out freeze...\n",
      "Capa conv4_block16_1_conv freeze...\n",
      "Capa conv4_block16_1_bn freeze...\n",
      "Capa conv4_block16_1_relu freeze...\n",
      "Capa conv4_block16_2_conv freeze...\n",
      "Capa conv4_block16_2_bn freeze...\n",
      "Capa conv4_block16_2_relu freeze...\n",
      "Capa conv4_block16_3_conv freeze...\n",
      "Capa conv4_block16_3_bn freeze...\n",
      "Capa conv4_block16_add freeze...\n",
      "Capa conv4_block16_out freeze...\n",
      "Capa conv4_block17_1_conv freeze...\n",
      "Capa conv4_block17_1_bn freeze...\n",
      "Capa conv4_block17_1_relu freeze...\n",
      "Capa conv4_block17_2_conv freeze...\n",
      "Capa conv4_block17_2_bn freeze...\n",
      "Capa conv4_block17_2_relu freeze...\n",
      "Capa conv4_block17_3_conv freeze...\n",
      "Capa conv4_block17_3_bn freeze...\n",
      "Capa conv4_block17_add freeze...\n",
      "Capa conv4_block17_out freeze...\n",
      "Capa conv4_block18_1_conv freeze...\n",
      "Capa conv4_block18_1_bn freeze...\n",
      "Capa conv4_block18_1_relu freeze...\n",
      "Capa conv4_block18_2_conv freeze...\n",
      "Capa conv4_block18_2_bn freeze...\n",
      "Capa conv4_block18_2_relu freeze...\n",
      "Capa conv4_block18_3_conv freeze...\n",
      "Capa conv4_block18_3_bn freeze...\n",
      "Capa conv4_block18_add freeze...\n",
      "Capa conv4_block18_out freeze...\n",
      "Capa conv4_block19_1_conv freeze...\n",
      "Capa conv4_block19_1_bn freeze...\n",
      "Capa conv4_block19_1_relu freeze...\n",
      "Capa conv4_block19_2_conv freeze...\n",
      "Capa conv4_block19_2_bn freeze...\n",
      "Capa conv4_block19_2_relu freeze...\n",
      "Capa conv4_block19_3_conv freeze...\n",
      "Capa conv4_block19_3_bn freeze...\n",
      "Capa conv4_block19_add freeze...\n",
      "Capa conv4_block19_out freeze...\n",
      "Capa conv4_block20_1_conv freeze...\n",
      "Capa conv4_block20_1_bn freeze...\n",
      "Capa conv4_block20_1_relu freeze...\n",
      "Capa conv4_block20_2_conv freeze...\n",
      "Capa conv4_block20_2_bn freeze...\n",
      "Capa conv4_block20_2_relu freeze...\n",
      "Capa conv4_block20_3_conv freeze...\n",
      "Capa conv4_block20_3_bn freeze...\n",
      "Capa conv4_block20_add freeze...\n",
      "Capa conv4_block20_out freeze...\n",
      "Capa conv4_block21_1_conv freeze...\n",
      "Capa conv4_block21_1_bn freeze...\n",
      "Capa conv4_block21_1_relu freeze...\n",
      "Capa conv4_block21_2_conv freeze...\n",
      "Capa conv4_block21_2_bn freeze...\n",
      "Capa conv4_block21_2_relu freeze...\n",
      "Capa conv4_block21_3_conv freeze...\n",
      "Capa conv4_block21_3_bn freeze...\n",
      "Capa conv4_block21_add freeze...\n",
      "Capa conv4_block21_out freeze...\n",
      "Capa conv4_block22_1_conv freeze...\n",
      "Capa conv4_block22_1_bn freeze...\n",
      "Capa conv4_block22_1_relu freeze...\n",
      "Capa conv4_block22_2_conv freeze...\n",
      "Capa conv4_block22_2_bn freeze...\n",
      "Capa conv4_block22_2_relu freeze...\n",
      "Capa conv4_block22_3_conv freeze...\n",
      "Capa conv4_block22_3_bn freeze...\n",
      "Capa conv4_block22_add freeze...\n",
      "Capa conv4_block22_out freeze...\n",
      "Capa conv4_block23_1_conv freeze...\n",
      "Capa conv4_block23_1_bn freeze...\n",
      "Capa conv4_block23_1_relu freeze...\n",
      "Capa conv4_block23_2_conv freeze...\n",
      "Capa conv4_block23_2_bn freeze...\n",
      "Capa conv4_block23_2_relu freeze...\n",
      "Capa conv4_block23_3_conv freeze...\n",
      "Capa conv4_block23_3_bn freeze...\n",
      "Capa conv4_block23_add freeze...\n",
      "Capa conv4_block23_out freeze...\n",
      "Capa conv4_block24_1_conv freeze...\n",
      "Capa conv4_block24_1_bn freeze...\n",
      "Capa conv4_block24_1_relu freeze...\n",
      "Capa conv4_block24_2_conv freeze...\n",
      "Capa conv4_block24_2_bn freeze...\n",
      "Capa conv4_block24_2_relu freeze...\n",
      "Capa conv4_block24_3_conv freeze...\n",
      "Capa conv4_block24_3_bn freeze...\n",
      "Capa conv4_block24_add freeze...\n",
      "Capa conv4_block24_out freeze...\n",
      "Capa conv4_block25_1_conv freeze...\n",
      "Capa conv4_block25_1_bn freeze...\n",
      "Capa conv4_block25_1_relu freeze...\n",
      "Capa conv4_block25_2_conv freeze...\n",
      "Capa conv4_block25_2_bn freeze...\n",
      "Capa conv4_block25_2_relu freeze...\n",
      "Capa conv4_block25_3_conv freeze...\n",
      "Capa conv4_block25_3_bn freeze...\n",
      "Capa conv4_block25_add freeze...\n",
      "Capa conv4_block25_out freeze...\n",
      "Capa conv4_block26_1_conv freeze...\n",
      "Capa conv4_block26_1_bn freeze...\n",
      "Capa conv4_block26_1_relu freeze...\n",
      "Capa conv4_block26_2_conv freeze...\n",
      "Capa conv4_block26_2_bn freeze...\n",
      "Capa conv4_block26_2_relu freeze...\n",
      "Capa conv4_block26_3_conv freeze...\n",
      "Capa conv4_block26_3_bn freeze...\n",
      "Capa conv4_block26_add freeze...\n",
      "Capa conv4_block26_out freeze...\n",
      "Capa conv4_block27_1_conv freeze...\n",
      "Capa conv4_block27_1_bn freeze...\n",
      "Capa conv4_block27_1_relu freeze...\n",
      "Capa conv4_block27_2_conv freeze...\n",
      "Capa conv4_block27_2_bn freeze...\n",
      "Capa conv4_block27_2_relu freeze...\n",
      "Capa conv4_block27_3_conv freeze...\n",
      "Capa conv4_block27_3_bn freeze...\n",
      "Capa conv4_block27_add freeze...\n",
      "Capa conv4_block27_out freeze...\n",
      "Capa conv4_block28_1_conv freeze...\n",
      "Capa conv4_block28_1_bn freeze...\n",
      "Capa conv4_block28_1_relu freeze...\n",
      "Capa conv4_block28_2_conv freeze...\n",
      "Capa conv4_block28_2_bn freeze...\n",
      "Capa conv4_block28_2_relu freeze...\n",
      "Capa conv4_block28_3_conv freeze...\n",
      "Capa conv4_block28_3_bn freeze...\n",
      "Capa conv4_block28_add freeze...\n",
      "Capa conv4_block28_out freeze...\n",
      "Capa conv4_block29_1_conv freeze...\n",
      "Capa conv4_block29_1_bn freeze...\n",
      "Capa conv4_block29_1_relu freeze...\n",
      "Capa conv4_block29_2_conv freeze...\n",
      "Capa conv4_block29_2_bn freeze...\n",
      "Capa conv4_block29_2_relu freeze...\n",
      "Capa conv4_block29_3_conv freeze...\n",
      "Capa conv4_block29_3_bn freeze...\n",
      "Capa conv4_block29_add freeze...\n",
      "Capa conv4_block29_out freeze...\n",
      "Capa conv4_block30_1_conv freeze...\n",
      "Capa conv4_block30_1_bn freeze...\n",
      "Capa conv4_block30_1_relu freeze...\n",
      "Capa conv4_block30_2_conv freeze...\n",
      "Capa conv4_block30_2_bn freeze...\n",
      "Capa conv4_block30_2_relu freeze...\n",
      "Capa conv4_block30_3_conv freeze...\n",
      "Capa conv4_block30_3_bn freeze...\n",
      "Capa conv4_block30_add freeze...\n",
      "Capa conv4_block30_out freeze...\n",
      "Capa conv4_block31_1_conv freeze...\n",
      "Capa conv4_block31_1_bn freeze...\n",
      "Capa conv4_block31_1_relu freeze...\n",
      "Capa conv4_block31_2_conv freeze...\n",
      "Capa conv4_block31_2_bn freeze...\n",
      "Capa conv4_block31_2_relu freeze...\n",
      "Capa conv4_block31_3_conv freeze...\n",
      "Capa conv4_block31_3_bn freeze...\n",
      "Capa conv4_block31_add freeze...\n",
      "Capa conv4_block31_out freeze...\n",
      "Capa conv4_block32_1_conv freeze...\n",
      "Capa conv4_block32_1_bn freeze...\n",
      "Capa conv4_block32_1_relu freeze...\n",
      "Capa conv4_block32_2_conv freeze...\n",
      "Capa conv4_block32_2_bn freeze...\n",
      "Capa conv4_block32_2_relu freeze...\n",
      "Capa conv4_block32_3_conv freeze...\n",
      "Capa conv4_block32_3_bn freeze...\n",
      "Capa conv4_block32_add freeze...\n",
      "Capa conv4_block32_out freeze...\n",
      "Capa conv4_block33_1_conv freeze...\n",
      "Capa conv4_block33_1_bn freeze...\n",
      "Capa conv4_block33_1_relu freeze...\n",
      "Capa conv4_block33_2_conv freeze...\n",
      "Capa conv4_block33_2_bn freeze...\n",
      "Capa conv4_block33_2_relu freeze...\n",
      "Capa conv4_block33_3_conv freeze...\n",
      "Capa conv4_block33_3_bn freeze...\n",
      "Capa conv4_block33_add freeze...\n",
      "Capa conv4_block33_out freeze...\n",
      "Capa conv4_block34_1_conv freeze...\n",
      "Capa conv4_block34_1_bn freeze...\n",
      "Capa conv4_block34_1_relu freeze...\n",
      "Capa conv4_block34_2_conv freeze...\n",
      "Capa conv4_block34_2_bn freeze...\n",
      "Capa conv4_block34_2_relu freeze...\n",
      "Capa conv4_block34_3_conv freeze...\n",
      "Capa conv4_block34_3_bn freeze...\n",
      "Capa conv4_block34_add freeze...\n",
      "Capa conv4_block34_out freeze...\n",
      "Capa conv4_block35_1_conv freeze...\n",
      "Capa conv4_block35_1_bn freeze...\n",
      "Capa conv4_block35_1_relu freeze...\n",
      "Capa conv4_block35_2_conv freeze...\n",
      "Capa conv4_block35_2_bn freeze...\n",
      "Capa conv4_block35_2_relu freeze...\n",
      "Capa conv4_block35_3_conv freeze...\n",
      "Capa conv4_block35_3_bn freeze...\n",
      "Capa conv4_block35_add freeze...\n",
      "Capa conv4_block35_out freeze...\n",
      "Capa conv4_block36_1_conv freeze...\n",
      "Capa conv4_block36_1_bn freeze...\n",
      "Capa conv4_block36_1_relu freeze...\n",
      "Capa conv4_block36_2_conv freeze...\n",
      "Capa conv4_block36_2_bn freeze...\n",
      "Capa conv4_block36_2_relu freeze...\n",
      "Capa conv4_block36_3_conv freeze...\n",
      "Capa conv4_block36_3_bn freeze...\n",
      "Capa conv4_block36_add freeze...\n",
      "Capa conv4_block36_out freeze...\n",
      "Capa conv5_block1_1_conv freeze...\n",
      "Capa conv5_block1_1_bn freeze...\n",
      "Capa conv5_block1_1_relu freeze...\n",
      "Capa conv5_block1_2_conv freeze...\n",
      "Capa conv5_block1_2_bn freeze...\n",
      "Capa conv5_block1_2_relu freeze...\n",
      "Capa conv5_block1_0_conv freeze...\n",
      "Capa conv5_block1_3_conv freeze...\n",
      "Capa conv5_block1_0_bn freeze...\n",
      "Capa conv5_block1_3_bn freeze...\n",
      "Capa conv5_block1_add freeze...\n",
      "Capa conv5_block1_out freeze...\n",
      "Capa conv5_block2_1_conv freeze...\n",
      "Capa conv5_block2_1_bn freeze...\n",
      "Capa conv5_block2_1_relu freeze...\n",
      "Capa conv5_block2_2_conv freeze...\n",
      "Capa conv5_block2_2_bn freeze...\n",
      "Capa conv5_block2_2_relu freeze...\n",
      "Capa conv5_block2_3_conv freeze...\n",
      "Capa conv5_block2_3_bn freeze...\n",
      "Capa conv5_block2_add freeze...\n",
      "Capa conv5_block2_out freeze...\n",
      "Capa conv5_block3_1_conv freeze...\n",
      "Capa conv5_block3_1_bn freeze...\n",
      "Capa conv5_block3_1_relu freeze...\n",
      "Capa conv5_block3_2_conv freeze...\n",
      "Capa conv5_block3_2_bn freeze...\n",
      "Capa conv5_block3_2_relu freeze...\n",
      "Capa conv5_block3_3_conv freeze...\n",
      "Capa conv5_block3_3_bn freeze...\n",
      "Capa conv5_block3_add freeze...\n",
      "Capa conv5_block3_out freeze...\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[131072,1000] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Add] name: fc1/random_uniform/",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-ac561014ed6a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m   \u001b[0mlast\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlast\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'fc1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'fc2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36msymbolic_fn_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_SYMBOLIC_SCOPE\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    461\u001b[0m                                          \u001b[1;34m'You can build it manually via: '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    462\u001b[0m                                          '`layer.build(batch_input_shape)`')\n\u001b[1;32m--> 463\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    464\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\keras\\layers\\core.py\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    893\u001b[0m                                       \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'kernel'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m                                       \u001b[0mregularizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel_regularizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m                                       constraint=self.kernel_constraint)\n\u001b[0m\u001b[0;32m    896\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m             self.bias = self.add_weight(shape=(self.units,),\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36madd_weight\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint)\u001b[0m\n\u001b[0;32m    277\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m             \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 279\u001b[1;33m         weight = K.variable(initializer(shape, dtype=dtype),\n\u001b[0m\u001b[0;32m    280\u001b[0m                             \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m                             \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\keras\\initializers.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, shape, dtype)\u001b[0m\n\u001b[0;32m    225\u001b[0m             \u001b[0mlimit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3.\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m             x = K.random_uniform(shape, -limit, limit,\n\u001b[1;32m--> 227\u001b[1;33m                                  dtype=dtype, seed=self.seed)\n\u001b[0m\u001b[0;32m    228\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[1;34m(shape, minval, maxval, dtype, seed)\u001b[0m\n\u001b[0;32m   4355\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtf_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4356\u001b[0m         return tf_keras_backend.random_uniform(\n\u001b[1;32m-> 4357\u001b[1;33m             shape, minval=minval, maxval=maxval, dtype=dtype, seed=seed)\n\u001b[0m\u001b[0;32m   4358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[1;34m(shape, minval, maxval, dtype, seed)\u001b[0m\n\u001b[0;32m   5624\u001b[0m     \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10e6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5625\u001b[0m   return random_ops.random_uniform(\n\u001b[1;32m-> 5626\u001b[1;33m       shape, minval=minval, maxval=maxval, dtype=dtype, seed=seed)\n\u001b[0m\u001b[0;32m   5627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5628\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\tensorflow_core\\python\\ops\\random_ops.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[1;34m(shape, minval, maxval, dtype, seed, name)\u001b[0m\n\u001b[0;32m    271\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m       \u001b[0mrnd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_random_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_uniform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 273\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrnd\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmaxval\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mminval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    274\u001b[0m     \u001b[1;31m# TODO(b/132092188): C++ shape inference inside functional ops does not\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m     \u001b[1;31m# cross FuncGraph boundaries since that information is only available in\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m    341\u001b[0m         \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 343\u001b[1;33m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    344\u001b[0m   \u001b[1;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6604\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" name: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6605\u001b[0m   \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6606\u001b[1;33m   \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6607\u001b[0m   \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6608\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[131072,1000] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Add] name: fc1/random_uniform/"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.applications import DenseNet121, ResNet152, ResNet152V2\n",
    "from keras.applications import imagenet_utils\n",
    "from tensorflow.keras import optimizers\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.engine import Model\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "from keras.layers import Dropout\n",
    "input_shape = (256, 256, 3)\n",
    "base_model = ResNet152(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "for layer in base_model.layers: \n",
    "  layer.trainable = False\n",
    "  print('Capa ' + layer.name + ' freeze...')\n",
    "  last = base_model.layers[-1].output\n",
    "x = Flatten()(last)\n",
    "x = Dense(1000, activation='relu', name='fc1')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(200, activation='relu', name='fc2')(x)\n",
    "x = Dense(3, activation='softmax', name='predictions')(x)\n",
    "model_resnet = Model(base_model.input, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nresnet152 (Model)            (None, 1000)              60419944  \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 1000)              0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 512)               512512    \n_________________________________________________________________\ndense_3 (Dense)              (None, 3)                 1539      \n=================================================================\nTotal params: 60,933,995\nTrainable params: 60,610,091\nNon-trainable params: 323,904\n_________________________________________________________________\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "9556797e-02,\n",
       "        -3.03886831e-03,  5.59574319e-03, -6.19558292e-03, -1.44089423e-02,\n",
       "        -1.56995319e-02, -1.94675308e-02,  1.35611498e-03,  4.09621513e-03,\n",
       "        -5.61026763e-03,  1.76017580e-03, -1.12154484e-02,  7.14821974e-03,\n",
       "        -2.15429394e-03, -4.72499349e-04, -7.70794926e-03, -9.33720917e-03,\n",
       "        -5.24849305e-03, -6.99713535e-04,  1.87406298e-02,  3.86947626e-03,\n",
       "        -7.53889792e-03, -1.10653955e-02,  9.53404885e-03, -3.97438556e-03,\n",
       "        -1.01516489e-03, -9.80561972e-03, -4.98154899e-03,  1.15464767e-02,\n",
       "        -2.77407817e-03,  4.13622148e-03, -2.49644020e-03, -6.09258981e-03,\n",
       "        -5.14376117e-03, -1.90166419e-03,  1.55179966e-02, -1.01111201e-03,\n",
       "        -2.02945853e-03, -3.01633426e-03,  7.23772589e-03, -6.00466831e-03,\n",
       "         1.67525057e-02,  1.02070207e-02,  1.69195724e-03, -3.95877054e-04,\n",
       "         3.42533225e-03,  7.03724008e-03, -2.65088701e-03,  1.61548350e-02,\n",
       "         1.24175847e-02,  1.32450170e-03, -5.92421321e-03,  3.26480605e-02,\n",
       "         1.03983460e-02,  7.64538534e-03, -9.72130429e-03,  6.61049783e-03,\n",
       "        -2.10575052e-02,  2.02274206e-03,  1.83587950e-02,  2.23432183e-02,\n",
       "         1.31354202e-02, -2.96979700e-03, -1.20835947e-02,  1.15633023e-03,\n",
       "         9.37642716e-03,  1.51679600e-02, -1.30935013e-02,  6.02254830e-03,\n",
       "         1.00580286e-02, -6.52412837e-03, -4.76079714e-03,  2.75034551e-03,\n",
       "        -4.76626260e-03,  1.59977991e-02,  5.80278458e-03, -6.67522568e-03,\n",
       "         1.66253764e-02, -5.78458048e-03,  1.03291646e-02,  1.49781741e-02,\n",
       "        -1.12074064e-02,  1.70339532e-02, -5.33141429e-03,  4.95499885e-03,\n",
       "        -7.48433499e-03,  4.09629056e-03,  1.44642731e-02,  4.48996812e-04,\n",
       "         2.28728000e-02,  3.74660455e-03,  8.21150932e-03,  3.69527173e-04,\n",
       "         2.30344664e-02,  3.99409514e-03,  1.35335494e-02,  2.02502981e-02,\n",
       "         1.17570600e-02, -7.13810325e-03,  1.29578484e-03, -9.23046842e-03,\n",
       "         8.67221877e-03,  1.40925581e-02, -3.77343036e-03,  1.03738215e-02,\n",
       "         9.43543762e-03, -4.86864708e-03, -2.25962758e-05,  1.70898363e-02,\n",
       "        -8.92745610e-03, -7.62722781e-03,  2.93137832e-03, -6.31618639e-03,\n",
       "         6.76832441e-03, -1.80218450e-03,  4.75467462e-03, -3.00506363e-03,\n",
       "        -5.94845787e-03, -5.01755904e-03, -9.33186093e-04, -1.14047306e-03,\n",
       "        -9.40139778e-03, -1.04713524e-02,  2.19642840e-04, -8.25522293e-05,\n",
       "        -1.18014142e-02, -4.52195620e-03,  1.00071607e-02,  1.77035487e-04,\n",
       "         5.72900288e-03,  1.51623683e-02, -8.43691081e-03, -9.64998268e-03,\n",
       "         3.05746985e-03, -3.11861280e-03, -1.29911061e-02,  3.20472312e-03,\n",
       "        -7.76608521e-03,  1.02055175e-02, -4.76048980e-03, -1.43621759e-02,\n",
       "         1.06977560e-02,  1.19972425e-02, -8.90834443e-03, -3.06846807e-03,\n",
       "        -8.36721621e-03,  1.33686711e-03, -2.34270096e-03, -1.33351441e-02,\n",
       "        -3.75416595e-03, -5.46928728e-03, -4.86867223e-03, -6.14542793e-03,\n",
       "        -4.67675226e-03, -8.69522057e-03, -3.17483116e-03,  1.32891694e-02,\n",
       "        -1.30126812e-03,  4.93058190e-03, -1.11733396e-02,  4.79325559e-03,\n",
       "        -3.97013593e-03,  6.73755119e-03,  1.60918012e-02, -1.65692950e-03,\n",
       "        -1.72196317e-03,  3.44009663e-04,  3.53796931e-04, -6.46991096e-03,\n",
       "        -1.19310780e-03,  1.64904483e-02,  9.83757898e-03,  3.32357688e-03,\n",
       "        -3.14954726e-04, -8.52500927e-03, -7.08085392e-03,  3.62485694e-03,\n",
       "        -1.26088485e-02, -1.35421976e-02, -1.69409104e-02, -1.34387473e-02,\n",
       "        -9.15959291e-03, -7.38361105e-03, -7.15607684e-03, -4.19895444e-03,\n",
       "        -9.37258638e-03, -7.55161420e-03, -1.00670112e-02, -8.96925479e-03,\n",
       "        -3.46953259e-03,  3.91044095e-03, -8.25131219e-03, -3.47222690e-03,\n",
       "         1.31175136e-02, -6.61173044e-03, -7.99378939e-03, -1.84465833e-02,\n",
       "         2.43294681e-03, -1.73565280e-02,  5.63145336e-03,  3.92813096e-03,\n",
       "        -6.03435654e-03, -8.80385097e-03,  9.80735384e-03,  6.93694397e-04,\n",
       "         1.32924737e-02, -4.31459583e-03, -5.77985495e-03, -1.46850850e-02,\n",
       "         4.63540619e-03,  1.55240961e-03, -3.24034248e-03,  1.98160019e-03,\n",
       "         1.47332181e-03, -8.78400053e-04,  8.95841978e-03,  2.65967159e-04,\n",
       "        -1.63968105e-03,  9.28368652e-04, -2.97454325e-03, -3.24912067e-03,\n",
       "        -9.93929803e-03, -2.20709876e-03, -6.92097843e-03,  2.50653317e-03,\n",
       "        -2.58252886e-03,  7.99628068e-03,  9.77588235e-04, -5.96814184e-03,\n",
       "        -9.28868912e-03,  3.44109070e-03, -4.20789141e-03, -4.94303880e-03,\n",
       "        -4.54504462e-03,  2.10080086e-03, -2.74007325e-03,  9.90770571e-03,\n",
       "        -5.14878891e-03, -7.43362308e-03,  5.84140711e-04,  8.94240849e-03,\n",
       "        -1.27475420e-02, -1.24460841e-02,  9.60345496e-05, -9.71936062e-03,\n",
       "        -4.57033794e-03, -5.76952565e-03, -3.15712369e-03,  1.09256487e-02,\n",
       "        -1.69304367e-02, -1.79341938e-02, -6.28638919e-03, -1.58410408e-02,\n",
       "        -1.34977726e-02, -1.02013648e-02,  4.65244008e-03,  3.85881262e-03,\n",
       "        -6.00244431e-03,  1.49103189e-02, -4.05256543e-03, -9.47679672e-03,\n",
       "        -1.86666865e-02,  5.82741154e-03,  2.61904486e-03,  6.56158524e-03,\n",
       "        -1.88534930e-02,  1.00488579e-02,  3.03492672e-03, -5.74550452e-03,\n",
       "         4.75766324e-03,  1.05426302e-02,  1.74168812e-03,  2.20707501e-03,\n",
       "         3.05377622e-03, -5.65934787e-03, -4.56037046e-03, -3.21368279e-04,\n",
       "        -8.24785978e-03,  1.77876820e-04,  9.18562617e-03,  1.86092295e-02,\n",
       "         7.96520431e-03, -8.82067438e-03, -1.13389809e-02, -1.73563231e-02,\n",
       "         1.80767104e-02,  8.67538899e-03, -1.86287158e-03, -1.15229675e-04,\n",
       "         7.27490755e-03,  6.32036058e-03,  9.01881792e-03, -6.56916434e-03,\n",
       "         5.52683696e-03,  2.78116437e-03, -5.37483580e-03, -1.19268172e-03,\n",
       "         5.73732052e-03,  9.01972223e-03,  4.32002777e-03, -1.73000954e-02,\n",
       "        -3.96598392e-04,  1.58192609e-02,  1.89948501e-03,  1.09769357e-03,\n",
       "         1.31064514e-02, -4.47630789e-03, -4.83752694e-03, -2.92376964e-03,\n",
       "        -1.71786395e-03, -2.85061682e-03,  1.04723349e-02,  1.43311396e-02,\n",
       "         8.80355947e-03,  1.79296546e-02, -7.96711911e-03, -3.88192059e-03,\n",
       "         9.78119671e-03, -6.39612274e-03,  8.92848417e-04,  1.52157638e-02,\n",
       "         1.04567735e-02,  1.83301256e-03, -6.85842149e-03,  9.55190323e-03,\n",
       "         1.07122120e-02, -2.08814582e-03,  1.95286367e-02,  8.49094428e-03,\n",
       "         7.51151564e-03,  4.11364855e-03, -1.13980044e-02, -1.22377241e-03,\n",
       "        -1.32681923e-02, -1.98487565e-03, -9.79316072e-04,  8.95048026e-03,\n",
       "         9.65973642e-03, -4.13146056e-03, -6.59803487e-03, -3.38856014e-03,\n",
       "        -2.41418276e-03, -2.55842693e-03,  5.13704866e-03,  1.01718158e-02,\n",
       "         1.30684422e-02, -3.90918599e-03, -1.50184678e-02,  1.18433824e-02,\n",
       "         1.21713511e-03, -5.02785575e-03,  3.64133157e-03, -1.76290493e-03,\n",
       "        -9.70920082e-03, -8.82941671e-03,  3.00209457e-03,  5.48392534e-03,\n",
       "        -1.33355828e-02, -3.32093844e-03, -5.63873025e-03, -1.56177972e-02,\n",
       "         1.08396346e-02,  2.33611534e-03,  2.80437851e-03, -9.18554794e-03,\n",
       "         9.39922966e-03, -7.60939438e-03, -1.00451196e-02,  5.41059719e-03,\n",
       "        -3.29755922e-03, -2.08276269e-05, -5.19455876e-04,  1.77877508e-02,\n",
       "         7.20759062e-03, -2.56946753e-03,  3.68640787e-04, -1.18416894e-04,\n",
       "        -6.69010077e-03,  1.57121965e-03,  6.90295408e-03,  3.05868685e-02,\n",
       "        -6.93517504e-03, -1.31362751e-02,  9.50232055e-03,  1.29720317e-02,\n",
       "         9.21280822e-04,  7.80978356e-04, -3.82334995e-03, -2.06312677e-03,\n",
       "         1.01335160e-02, -8.64876807e-03,  5.35372272e-03, -4.65719029e-03,\n",
       "         1.41386036e-02,  6.28356077e-03, -9.63005144e-03,  1.49443075e-02,\n",
       "        -2.45732795e-02,  5.27211744e-03, -4.10543988e-03,  1.43650090e-02,\n",
       "        -4.13100934e-03, -4.65736212e-03, -1.75014057e-03, -7.09730480e-03,\n",
       "        -1.13934418e-02, -8.80728289e-03,  3.80223664e-03,  1.84721037e-04,\n",
       "         3.11941281e-03, -4.24815062e-03,  2.26606568e-03, -2.14786944e-03,\n",
       "        -6.50133006e-03,  9.30661522e-03,  1.21698026e-02, -1.86590449e-04,\n",
       "        -1.26107978e-02,  1.56030804e-03, -3.72271310e-03,  3.00564989e-03,\n",
       "        -7.46600889e-03, -9.11617372e-03,  4.81187738e-03,  9.33842268e-03,\n",
       "         1.93946052e-03, -1.23331603e-02, -6.03214465e-03,  1.37939479e-03,\n",
       "         5.57315024e-03, -4.28909576e-03, -3.21730273e-03,  1.06844353e-02,\n",
       "        -1.66532432e-03,  4.87028947e-03, -5.77409519e-03,  1.08166104e-02,\n",
       "         6.16751902e-04, -7.75575114e-04,  1.19968532e-02, -1.00800321e-02,\n",
       "        -3.19443690e-03, -4.15276503e-03, -1.69515535e-02,  6.40581129e-03,\n",
       "        -1.38108572e-03,  7.65811000e-03, -1.98689080e-03, -5.06253401e-03,\n",
       "        -1.11356191e-02,  6.64983410e-03,  1.57158717e-03, -1.29821738e-02,\n",
       "        -1.47059560e-03, -3.84889223e-04, -7.43878819e-03, -2.34379387e-03,\n",
       "         1.16134500e-02,  2.11775210e-03,  1.87831814e-03,  7.87365343e-03,\n",
       "         5.04190568e-03,  8.79637431e-03, -4.90381336e-03,  1.18320517e-03,\n",
       "         8.25761631e-03, -3.58707155e-03,  4.20428673e-03, -1.45286892e-03,\n",
       "        -3.10306787e-03,  3.65275238e-03,  3.40104545e-03, -3.15775309e-04,\n",
       "         3.78860022e-05,  2.38313759e-03,  1.26393493e-02, -1.08415922e-02,\n",
       "         1.06617613e-02,  4.67993692e-03,  2.44076848e-02,  2.07303613e-02,\n",
       "         1.07764266e-02, -1.24741415e-03,  1.94923934e-02,  6.48867618e-03,\n",
       "         6.13185402e-04, -2.69449665e-04, -6.54792227e-03, -7.13564875e-03,\n",
       "         6.06148271e-03, -4.20505973e-03, -1.23738237e-02, -2.50892807e-03,\n",
       "         3.54298484e-03,  2.24102056e-03,  7.41188088e-03, -1.51585191e-02,\n",
       "        -1.14167370e-02, -1.40852085e-03,  9.90582164e-03,  6.44275313e-03,\n",
       "         6.80060545e-03, -1.05568478e-02,  1.11232968e-02, -1.13644777e-02,\n",
       "        -4.71439073e-03,  5.52580738e-03,  2.86299121e-02,  2.69695534e-03,\n",
       "         1.15313986e-02,  1.02706738e-02,  3.16866953e-03,  1.78009234e-02,\n",
       "         7.89092202e-03,  1.30117927e-02, -8.71702936e-03,  3.53623042e-03,\n",
       "        -1.00927800e-03, -2.47111404e-03,  1.77041106e-02, -8.19355249e-04,\n",
       "         1.35052288e-02,  7.68816704e-03,  6.49422780e-03,  1.48200651e-03,\n",
       "        -1.18232416e-02, -2.48377230e-02,  6.23211163e-05,  1.26556121e-02,\n",
       "         1.39310285e-02,  2.10281480e-02,  4.71695699e-03, -1.42418342e-02,\n",
       "         8.93593766e-03, -1.27169117e-03,  4.04767506e-03, -5.05276350e-03,\n",
       "         3.10241454e-03,  4.46069567e-03,  3.41503182e-03,  1.46586811e-02,\n",
       "         1.20161718e-03, -9.77656059e-03, -2.41629453e-03, -2.29441691e-02,\n",
       "        -1.37003195e-02, -1.42372120e-02, -4.69321664e-03, -5.48373326e-04,\n",
       "         1.47694973e-02, -5.61913988e-03, -1.59103777e-02,  6.53525162e-03,\n",
       "         2.94815958e-03, -1.12502547e-02, -1.26070576e-02, -8.13462399e-03,\n",
       "         1.04988972e-02,  9.61043034e-03, -5.21842390e-03,  9.71280411e-03,\n",
       "         1.70543361e-02, -4.35297424e-03,  1.18166506e-02, -4.08785651e-03,\n",
       "         8.59789798e-05,  1.26897288e-03, -4.65471391e-03,  6.23309799e-03,\n",
       "        -1.30061191e-02,  5.06686792e-03,  2.47815362e-04, -1.03949523e-02,\n",
       "         2.04445925e-02, -1.29190516e-02,  2.10389006e-03,  9.07014217e-03,\n",
       "         1.86516996e-03,  1.29018966e-02,  3.02324519e-02, -2.64193653e-03,\n",
       "        -6.51703123e-03, -7.95192644e-03, -6.21271972e-03, -9.12061613e-03,\n",
       "        -8.09794571e-03,  2.53032544e-03,  4.23709396e-03,  2.31851917e-02,\n",
       "         6.32381486e-03,  9.55308322e-03, -4.71282424e-03, -1.72721688e-03,\n",
       "         5.10663725e-03,  1.37091707e-03,  1.63880996e-02,  9.67454223e-04,\n",
       "        -2.13862420e-03, -1.03422971e-02,  1.42881053e-03,  1.05503434e-02,\n",
       "         1.52108585e-02,  6.41681440e-03, -1.32768806e-02,  4.85209841e-03,\n",
       "        -8.08783807e-03,  2.88396794e-02,  1.59004715e-03, -7.05259293e-03,\n",
       "         1.45748379e-02,  3.60288983e-03,  1.47434454e-02, -1.14900721e-02,\n",
       "         9.47319902e-03,  2.18432993e-04,  7.74253253e-03,  1.99235673e-03,\n",
       "         3.24466964e-03,  1.15727913e-02,  9.47876554e-03, -3.30028823e-03,\n",
       "        -1.61364337e-03, -9.09764960e-04, -9.79104079e-03, -2.27665808e-03,\n",
       "         5.05428435e-03,  2.18711793e-02, -8.39413237e-03, -1.26130390e-03,\n",
       "        -1.92703982e-03,  9.11939330e-03,  3.41318082e-03,  3.33236600e-03,\n",
       "         1.25438180e-02, -3.21026286e-03,  1.41018825e-02, -8.04239511e-03,\n",
       "        -8.48085806e-03, -1.29012428e-02,  5.09728212e-03,  5.11820102e-03,\n",
       "        -1.45823555e-03,  3.20334849e-03, -2.50434061e-03, -8.17380566e-03,\n",
       "         8.61477200e-03, -5.53861912e-03, -1.43723981e-02,  1.75992157e-02,\n",
       "         1.28539279e-02,  7.35211652e-03, -2.42001601e-02, -1.12730414e-02,\n",
       "         3.73531180e-03, -4.61429078e-03, -7.52690388e-03,  1.45019125e-02,\n",
       "        -1.50095606e-02,  6.67921267e-03, -8.81818868e-03, -1.18253846e-02,\n",
       "        -5.80187188e-05,  1.53788794e-02, -4.65770857e-03, -6.78106956e-03,\n",
       "         1.16743678e-02,  1.88310994e-04, -7.62196863e-03,  6.30633766e-03,\n",
       "        -1.03999041e-02,  2.09435672e-02, -1.61433779e-02, -3.43930582e-03,\n",
       "         5.83304465e-03, -5.18309977e-03,  7.83764943e-03,  1.33233247e-02,\n",
       "        -1.10199545e-02, -1.45529788e-02,  2.95592286e-03,  5.61181922e-03,\n",
       "         4.06606792e-04, -1.50928448e-03,  4.30180365e-03, -7.63239572e-03,\n",
       "         6.70153601e-03, -1.05674732e-02,  2.93116365e-03, -5.13834739e-03,\n",
       "        -2.11324729e-03,  2.21403292e-03,  1.18750576e-02,  4.24177572e-03,\n",
       "        -3.16899666e-03,  1.96875092e-02,  1.73037294e-02, -3.87495942e-03,\n",
       "         1.04923192e-02,  1.52655051e-03, -1.57376844e-03,  3.48609802e-03,\n",
       "        -1.81264360e-03,  1.87633242e-02,  1.00473249e-02, -1.71994546e-03,\n",
       "         5.35254180e-03,  3.91008286e-03,  2.10608244e-02, -4.42241924e-03,\n",
       "         6.52893540e-03, -1.06918644e-02, -1.83899198e-02, -2.57808802e-04,\n",
       "        -1.53911998e-02, -2.24260613e-03, -3.67452530e-03,  3.30994721e-03,\n",
       "        -2.97834468e-03,  1.17068393e-02, -7.88432360e-03, -3.32208560e-03,\n",
       "        -6.54105190e-03, -4.74087894e-03, -4.05946514e-03,  1.16259768e-03,\n",
       "         1.31757986e-02, -7.40259048e-03,  1.16051070e-03, -9.16899834e-03,\n",
       "         1.70657728e-02, -8.86415225e-03, -2.35624406e-02,  9.44653805e-03,\n",
       "         1.29630174e-02,  5.43810893e-03, -1.09534627e-02,  3.90088409e-02,\n",
       "         2.57828273e-02, -5.68295224e-03,  1.45632625e-02,  1.60557567e-03,\n",
       "        -1.40572037e-03,  3.49712471e-04, -1.10771274e-02, -8.03049933e-03,\n",
       "         2.04878161e-03,  7.64166471e-03,  1.38587726e-03, -1.64962132e-02,\n",
       "         1.06933797e-02, -3.27344984e-03, -2.86214286e-03,  1.61688920e-04,\n",
       "         4.21944540e-03,  2.03868952e-02,  1.89398210e-02,  8.67770147e-03,\n",
       "        -4.66045085e-03, -5.86784352e-03,  2.01220345e-02,  2.42930837e-04,\n",
       "        -4.22233576e-03, -1.21075548e-02, -2.34851358e-03,  1.11977253e-02,\n",
       "         1.12664758e-03,  2.54674494e-04,  2.00775694e-02,  1.64119317e-03,\n",
       "         6.77086087e-03,  5.55932242e-03, -8.96442030e-03, -4.32497123e-03,\n",
       "        -1.23546552e-02, -1.04777636e-02,  6.11034781e-03,  7.55395135e-03,\n",
       "         1.15005951e-02,  3.63149308e-03, -9.57864057e-03,  2.16253512e-02,\n",
       "        -1.29344771e-02, -1.29512632e-02, -8.90157931e-03,  6.29102069e-05,\n",
       "        -1.18619471e-03,  2.43535005e-02,  2.59602792e-03, -1.13656642e-02,\n",
       "         1.41308480e-03, -1.39698377e-02,  8.37891083e-03, -6.25225599e-04,\n",
       "        -2.23182887e-03, -8.62339791e-03, -5.44487685e-03, -5.54621499e-03,\n",
       "        -5.27577195e-03, -1.19192591e-02, -5.56429103e-03, -4.20737267e-03,\n",
       "         1.91512707e-04, -9.26118344e-03, -4.05699061e-03, -1.38338590e-02,\n",
       "         2.72105332e-03,  5.29895211e-03,  9.15424433e-03,  6.54399628e-03,\n",
       "        -6.32682117e-03, -1.13063911e-03,  7.27210753e-03, -8.50920379e-03,\n",
       "        -1.10829864e-02, -4.25436208e-03,  7.31252832e-03, -1.59512013e-02,\n",
       "        -4.20054561e-03, -3.19566322e-03, -1.10493898e-02, -9.87218972e-03,\n",
       "        -1.11588705e-02, -4.14475449e-04,  1.09431315e-02,  1.23545052e-02,\n",
       "         8.63941107e-03,  8.36413912e-03,  2.94832513e-03,  1.21428194e-02,\n",
       "         2.52414000e-04,  8.27304181e-03, -8.05652700e-03, -5.31177456e-03,\n",
       "         1.25674345e-03,  2.16097366e-02,  1.51053537e-02, -1.74431577e-02,\n",
       "         2.98133981e-03, -9.06251464e-03,  2.33670939e-02,  3.17921932e-03,\n",
       "         1.05441809e-02, -6.58776425e-03, -7.04662502e-03,  6.11967407e-03,\n",
       "        -5.15498628e-04,  4.78396518e-03,  3.44136468e-04, -5.53122861e-03,\n",
       "        -3.40004615e-03, -2.31636763e-02, -3.96835897e-03,  2.73310463e-03,\n",
       "        -1.37554924e-03, -1.55905290e-02,  7.43286684e-04,  1.03627210e-02],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_2/kernel:0' shape=(1000, 512) dtype=float32, numpy=\n",
       " array([[-2.8168056e-02,  3.0349888e-02,  5.4285675e-04, ...,\n",
       "          3.5644002e-02,  5.6336187e-02,  2.7194619e-06],\n",
       "        [ 5.1934160e-02, -4.2540193e-02, -6.1788056e-02, ...,\n",
       "         -5.6833483e-02, -2.4384361e-02,  2.2843443e-02],\n",
       "        [-4.7053002e-02, -9.2534497e-03,  5.2134544e-02, ...,\n",
       "         -6.7440830e-03, -2.8350733e-02,  1.6038865e-02],\n",
       "        ...,\n",
       "        [-2.3462437e-02,  2.3493707e-02, -1.5866823e-02, ...,\n",
       "         -2.9722549e-02, -3.8708918e-02,  2.0353645e-02],\n",
       "        [ 1.8182397e-03, -3.6613546e-02,  2.1011882e-02, ...,\n",
       "         -4.6817563e-02, -2.2097874e-02, -5.7911694e-02],\n",
       "        [ 1.6256943e-02,  4.6516821e-02, -4.4776682e-02, ...,\n",
       "         -9.4827302e-03,  5.2250028e-02,  6.1061382e-03]], dtype=float32)>,\n",
       " <tf.Variable 'dense_2/bias:0' shape=(512,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'dense_3/kernel:0' shape=(512, 3) dtype=float32, numpy=\n",
       " array([[ 0.07541474, -0.10301411,  0.09426226],\n",
       "        [-0.09002829, -0.02751358,  0.03571581],\n",
       "        [ 0.04841036, -0.07134601, -0.09006737],\n",
       "        ...,\n",
       "        [-0.08351375,  0.03933679, -0.07157948],\n",
       "        [ 0.04907174,  0.06864613, -0.0179866 ],\n",
       "        [-0.01290536,  0.07376329, -0.10543016]], dtype=float32)>,\n",
       " <tf.Variable 'dense_3/bias:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>]"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "# Create Model\n",
    "# ------------\n",
    "\n",
    "finetuning = True\n",
    "\n",
    "if finetuning:\n",
    "    freeze_until = 15 # layer from which we want to fine-tune\n",
    "    \n",
    "    for layer in desnet.layers[:freeze_until]:\n",
    "        layer.trainable = False\n",
    "else:\n",
    "    vgg.trainable = False\n",
    "    \n",
    "modeldes = tf.keras.Sequential()\n",
    "modeldes.add(desnet)\n",
    "modeldes.add(tf.keras.layers.Flatten())\n",
    "modeldes.add(tf.keras.layers.Dense(units=512, activation='relu'))\n",
    "modeldes.add(tf.keras.layers.Dense(units=num_classes, activation='softmax'))\n",
    "\n",
    "# Visualize created model as a table\n",
    "modeldes.summary()\n",
    "\n",
    "# Visualize initialized weights\n",
    "modeldes.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization params\n",
    "# -------------------\n",
    "\n",
    "# Loss\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "# learning rate\n",
    "lr = 1e-4\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "# -------------------\n",
    "\n",
    "# Validation metrics\n",
    "# ------------------\n",
    "\n",
    "metrics = ['accuracy']\n",
    "# ------------------\n",
    "\n",
    "# Compile Model\n",
    "modeldes.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# from tensorflow.compat.v1 import ConfigProto\n",
    "# from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "# config = ConfigProto()\n",
    "# config.gpu_options.allow_growth = True\n",
    "# session = InteractiveSession(config=config)\n",
    "\n",
    "cwd = '/content/drive/My Drive/Keras3'\n",
    "\n",
    "exps_dir = os.path.join(cwd, 'transfer_learning_experiments')\n",
    "if not os.path.exists(exps_dir):\n",
    "    os.makedirs(exps_dir)\n",
    "\n",
    "now = datetime.now().strftime('%b%d_%H-%M-%S')\n",
    "\n",
    "model_name = 'CNN'\n",
    "\n",
    "exp_dir = os.path.join(exps_dir, model_name + '_' + str(now))\n",
    "if not os.path.exists(exp_dir):\n",
    "    os.makedirs(exp_dir)\n",
    "    \n",
    "callbacks = []\n",
    "\n",
    "# Model checkpoint\n",
    "# ----------------\n",
    "ckpt_dir = os.path.join(exp_dir, 'ckpts')\n",
    "if not os.path.exists(ckpt_dir):\n",
    "    os.makedirs(ckpt_dir)\n",
    "\n",
    "ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(ckpt_dir, 'cp.ckpt'), \n",
    "                                                   save_weights_only=True)  # False to save the model directly\n",
    "callbacks.append(ckpt_callback)\n",
    "\n",
    "# Visualize Learning on Tensorboard\n",
    "# ---------------------------------\n",
    "tb_dir = os.path.join(exp_dir, 'tb_logs')\n",
    "if not os.path.exists(tb_dir):\n",
    "    os.makedirs(tb_dir)\n",
    "    \n",
    "# By default shows losses and metrics for both training and validation\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_dir,\n",
    "                                             profile_batch=0,\n",
    "                                             histogram_freq=1)  # if 1 shows weights histograms\n",
    "callbacks.append(tb_callback)\n",
    "\n",
    "# Early Stopping\n",
    "# --------------\n",
    "early_stop = False\n",
    "if early_stop:\n",
    "    es_callback = tf.keras.callback.EarlyStopping(monitor='val_loss', patience=10)\n",
    "    callbacks.append(es_callback)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 562 steps, validate for 141 steps\n",
      "Epoch 1/30\n",
      "  1/562 [..............................] - ETA: 9:14:30"
     ]
    },
    {
     "output_type": "error",
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node sequential_1/resnet152/conv3_block3_3_bn/FusedBatchNormV3 (defined at <ipython-input-18-5b3f610e54e1>:6) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_distributed_function_282415]\n\nFunction call stack:\ndistributed_function\n",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-5b3f610e54e1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalid_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_gen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m           callbacks=callbacks)\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# How to visualize Tensorboard\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    630\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 632\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    633\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node sequential_1/resnet152/conv3_block3_3_bn/FusedBatchNormV3 (defined at <ipython-input-18-5b3f610e54e1>:6) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_distributed_function_282415]\n\nFunction call stack:\ndistributed_function\n"
     ]
    }
   ],
   "source": [
    "modeldes.fit(x=train_gen,\n",
    "          epochs=30,  #### set repeat in training dataset\n",
    "          steps_per_epoch=len(train_gen),\n",
    "          validation_data=valid_dataset,\n",
    "          validation_steps=len(valid_gen), \n",
    "          callbacks=callbacks)\n",
    "\n",
    "# How to visualize Tensorboard\n",
    "\n",
    "# 1. tensorboard --logdir EXPERIMENTS_DIR --port PORT     <- from terminal\n",
    "# 2. localhost:PORT   <- in your browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops.RepeatDataset"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "type(train_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "keras_preprocessing.image.directory_iterator.DirectoryIterator"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "type(train_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}