{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Basic_Model_VQA_2_CORRECT.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.7.9 64-bit ('tensorflow_gpuenv': conda)",
      "metadata": {
        "interpreter": {
          "hash": "b4475d159700ac7f63d83dbd0a06e80f15c08c0a62544dac6ddf2e61acd99b97"
        }
      }
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9-final"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfDYBEE9UTbv"
      },
      "source": [
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4J8gufz1UTb9"
      },
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import shutil\n",
        "from tensorflow.keras.applications import InceptionResNetV2\n",
        "\n",
        "# Set the seed for random operations. \n",
        "# This let our experiments to be reproducible. \n",
        "SEED = 1234\n",
        "tf.random.set_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# Get current working directory\n",
        "cwd = os.getcwd()\n",
        "\n",
        "for gpu in tf.config.experimental.list_physical_devices('GPU'):\n",
        "    tf.config.experimental.set_memory_growth(gpu, True)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "t74cL6CTVDLX",
        "outputId": "75fe7e1f-96f7-45c2-bcf5-86517be9c499"
      },
      "source": [
        "cwd = os.getcwd()\n",
        "cwd"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'c:\\\\Users\\\\enric\\\\Downloads\\\\AN2DL-1st-Project\\\\3rd Challenge'"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGmpHrx1VHA4",
        "outputId": "b381cf12-bdc5-4dbb-db0e-c2349a48109f"
      },
      "source": [
        "dataset_dir = os.path.join(cwd, 'VQA_Dataset')\n",
        "#if os.path.exists(dataset_dir):\n",
        "#  shutil.rmtree(dataset_dir)\n",
        "\n",
        "#!unzip  '/content/drive/MyDrive/anndl-2020-vqa.zip'\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1JRUORzUTcC"
      },
      "source": [
        "# Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPIPytlFUTcD"
      },
      "source": [
        "img_w = 700\n",
        "img_h = 400\n",
        "batch_size = 4\n",
        "lr = 1e-3\n",
        "\n",
        "MAX_NUM_WORDS = 5000 # max number of unique words in dictionary\n",
        "\n",
        "FEATURES = 1536 # size of feature vector for images and questions\n",
        "\n",
        "UNITS = 512\n",
        "\n",
        "PERC_DROP = 0.4\n",
        "\n",
        "decay = 0.5\n",
        "minimum = 1e-6"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIv0si0qUTcE"
      },
      "source": [
        "labels_dict = {\n",
        "        '0': 0,\n",
        "        '1': 1,\n",
        "        '2': 2,\n",
        "        '3': 3,\n",
        "        '4': 4,\n",
        "        '5': 5,\n",
        "        'apple': 6,\n",
        "        'baseball': 7,\n",
        "        'bench': 8,\n",
        "        'bike': 9,\n",
        "        'bird': 10,\n",
        "        'black': 11,\n",
        "        'blanket': 12,\n",
        "        'blue': 13,\n",
        "        'bone': 14,\n",
        "        'book': 15,\n",
        "        'boy': 16,\n",
        "        'brown': 17,\n",
        "        'cat': 18,\n",
        "        'chair': 19,\n",
        "        'couch': 20,\n",
        "        'dog': 21,\n",
        "        'floor': 22,\n",
        "        'food': 23,\n",
        "        'football': 24,\n",
        "        'girl': 25,\n",
        "        'grass': 26,\n",
        "        'gray': 27,\n",
        "        'green': 28,\n",
        "        'left': 29,\n",
        "        'log': 30,\n",
        "        'man': 31,\n",
        "        'monkey bars': 32,\n",
        "        'no': 33,\n",
        "        'nothing': 34,\n",
        "        'orange': 35,\n",
        "        'pie': 36,\n",
        "        'plant': 37,\n",
        "        'playing': 38,\n",
        "        'red': 39,\n",
        "        'right': 40,\n",
        "        'rug': 41,\n",
        "        'sandbox': 42,\n",
        "        'sitting': 43,\n",
        "        'sleeping': 44,\n",
        "        'soccer': 45,\n",
        "        'squirrel': 46,\n",
        "        'standing': 47,\n",
        "        'stool': 48,\n",
        "        'sunny': 49,\n",
        "        'table': 50,\n",
        "        'tree': 51,\n",
        "        'watermelon': 52,\n",
        "        'white': 53,\n",
        "        'wine': 54,\n",
        "        'woman': 55,\n",
        "        'yellow': 56,\n",
        "        'yes': 57\n",
        "}\n",
        "\n",
        "num_answers = len(labels_dict)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOpOSZc_UTcF"
      },
      "source": [
        "# Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQapmFzNUTcF"
      },
      "source": [
        "import json\n",
        "def unwrap_weighted(path, split = 0.2):\n",
        "    \n",
        "    dataset_dir = os.path.join(path, 'train_questions_annotations.json')\n",
        "    training_dir = os.path.join(path, 'training.json')\n",
        "    validation_dir = os.path.join(path, 'validation.json')\n",
        "        \n",
        "    dic_images = None\n",
        "    \n",
        "    with open(dataset_dir) as f:\n",
        "       dic_images = json.load(f)\n",
        "        \n",
        "    dict_keys = list(dic_images.keys())\n",
        "    np.random.shuffle(dict_keys)\n",
        "    questions = int(round(split*len(dict_keys)))\n",
        "        \n",
        "    dic_validations = { dict_keys[i]:dic_images[dict_keys[i]] for i in range(questions)}\n",
        "    dic_training = {dict_keys[i]:dic_images[dict_keys[i]] for i in range(questions, len(dict_keys))}\n",
        "        \n",
        "    with open(training_dir, 'w') as fp:\n",
        "       json.dump(dic_training, fp)\n",
        "    with open(validation_dir, 'w') as fp:\n",
        "       json.dump(dic_validations, fp)\n",
        "\n",
        "path = os.getcwd()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUFnliG7UTcG"
      },
      "source": [
        "def get_token_dic_quest(path, max_num_words = 5000):\n",
        "    from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "    dataset_dir = os.path.join(path, 'train_questions_annotations.json')\n",
        "    \n",
        "    # Load dataset\n",
        "    with open(dataset_dir) as f:\n",
        "        dic_images = json.load(f)\n",
        "\n",
        "    # Get all questions as strings in a list\n",
        "    questions = [dic['question'] for dic in dic_images.values()]\n",
        "\n",
        "    # Strip '?' from questions\n",
        "    questions = [s.translate(str.maketrans('', '', '?')).lower() for s in questions if not s == '']\n",
        "    questions_tokenizer = Tokenizer(num_words=max_num_words)\n",
        "    questions_tokenizer.fit_on_texts(questions)\n",
        "\n",
        "    questions_wtoi = questions_tokenizer.word_index # index 0 reserved for padding\n",
        "    \n",
        "    questions_tokenized = questions_tokenizer.texts_to_sequences(questions)\n",
        "    max_question_length = max(len(sentence) for sentence in questions_tokenized)\n",
        "    \n",
        "    return questions_tokenizer, questions_wtoi, max_question_length\n",
        "\n",
        "\n",
        "def from_questions_to_dict(path, dict_req, max_num_words = 5000):\n",
        "    from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "    \n",
        "    # Return dictionary q_wtoi\n",
        "    tokenizer, wtoi, max_len = get_token_dic_quest(path, max_num_words = 5000)\n",
        "    \n",
        "    translated_dics = []\n",
        "    \n",
        "    for dic in dict_req:\n",
        "        \n",
        "        question = dic['question'].translate(str.maketrans('', '', '?')).lower()\n",
        "        question = tokenizer.texts_to_sequences([question])\n",
        "        question = pad_sequences(question, maxlen=max_len)\n",
        "        dic['question'] = question[0]\n",
        "        dic['answer'] = labels_dict[dic['answer']]\n",
        "        translated_dics.append(dic)\n",
        "    \n",
        "    return translated_dics"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bysPOHz0UTcI"
      },
      "source": [
        "from PIL import Image\n",
        "    \n",
        "# Patches Generator\n",
        "class dataset_generator(tf.keras.utils.Sequence):\n",
        "\n",
        "  def __init__(self, path, preprocessing, subset = \"training\", image_generator = None, batch_size = 5, max_num_words=5000):\n",
        "    json_file = subset + \".json\"\n",
        "    dat_dir = os.path.join(path, 'VQA_Dataset')\n",
        "    subset_file = os.path.join(dat_dir, json_file)\n",
        "    \n",
        "    with open(subset_file) as f:\n",
        "       dictionaries = json.load(f)\n",
        "       dictionaries = dictionaries.values()\n",
        "       self.dictionary = from_questions_to_dict(dat_dir, dictionaries, max_num_words)\n",
        "    \n",
        "    self.batch_size = batch_size\n",
        "    self.image_generator = image_generator\n",
        "    self.preprocessing = preprocessing\n",
        "    self.dat_dir = dat_dir\n",
        "    self.gen = image_generator\n",
        "    self.batch_size = batch_size\n",
        "    self.max_num_words = max_num_words\n",
        "    self.n = 0\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.dictionary)//self.batch_size\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    lower_bound = index*self.batch_size\n",
        "    upper_bound = (index+1)*self.batch_size\n",
        "    \n",
        "    batch_img = []\n",
        "    batch_que = []\n",
        "    batch_ans = []\n",
        "    \n",
        "    for idx in range(lower_bound, upper_bound):\n",
        "        img, que, ans = self.__data_generation__(idx)\n",
        "        batch_img.append(img)\n",
        "        batch_que.append(que)\n",
        "        batch_ans.append(ans)\n",
        "        \n",
        "    batch_img = np.stack(batch_img, axis=0)\n",
        "    batch_que = np.stack(batch_que, axis=0)\n",
        "    batch_ans = np.stack(batch_ans, axis=0)\n",
        "    \n",
        "    x = [batch_img, batch_que]\n",
        "    y = batch_ans\n",
        "    \n",
        "    return x, y\n",
        "    \n",
        "    \n",
        "  def __data_generation__(self, idx):\n",
        "    actual_dict = self.dictionary[idx]\n",
        "    \n",
        "    img_name = actual_dict['image_id']\n",
        "    answer = actual_dict['answer']\n",
        "    question = actual_dict['question']\n",
        "    \n",
        "    actual_img = Image.open(os.path.join(self.dat_dir, \"Images\", img_name + \".png\"))\n",
        "    actual_img = actual_img.convert('RGB')\n",
        "    img_arr = np.array(actual_img)\n",
        "    img_arr = np.expand_dims(img_arr, axis=0)\n",
        "    \n",
        "    if self.image_generator is not None:\n",
        "        img_arr = self.gen.random_transform(img_arr)\n",
        "    \n",
        "    if self.preprocessing is not None:\n",
        "        img_arr = self.preprocessing(img_arr)\n",
        "        \n",
        "    img_arr = np.squeeze(img_arr, axis=0)\n",
        "    \n",
        "    return img_arr, question, answer"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXPpjZmNUTcJ"
      },
      "source": [
        "Datasets generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCpK8iuxUTcL"
      },
      "source": [
        "unwrap_weighted(os.path.join(path, 'VQA_Dataset'))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "preprocessing_function_inception = tf.keras.applications.inception_resnet_v2.preprocess_input\n",
        "\n",
        "gen = dataset_generator(path = os.getcwd(), preprocessing = preprocessing_function_inception, \n",
        "                  subset = \"training\", image_generator = None, max_num_words=5000, batch_size = batch_size)\n",
        "\n",
        "gen_val = dataset_generator(path = os.getcwd(), preprocessing = preprocessing_function_inception, \n",
        "                  subset = \"validation\", image_generator = None, max_num_words=5000, batch_size = batch_size)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9ACdnU_UTcY"
      },
      "source": [
        "# Image Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "tags": [
          "outputPrepend"
        ]
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "______________________\n",
            "batch_normalization_181 (BatchN (None, 11, 20, 224)  672         conv2d_181[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_181 (Activation)     (None, 11, 20, 224)  0           batch_normalization_181[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_179 (Conv2D)             (None, 11, 20, 192)  399360      block8_4_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_182 (Conv2D)             (None, 11, 20, 256)  172032      activation_181[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_179 (BatchN (None, 11, 20, 192)  576         conv2d_179[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_182 (BatchN (None, 11, 20, 256)  768         conv2d_182[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_179 (Activation)     (None, 11, 20, 192)  0           batch_normalization_179[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_182 (Activation)     (None, 11, 20, 256)  0           batch_normalization_182[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_5_mixed (Concatenate)    (None, 11, 20, 448)  0           activation_179[0][0]             \n",
            "                                                                 activation_182[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_5_conv (Conv2D)          (None, 11, 20, 2080) 933920      block8_5_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_5 (Lambda)               (None, 11, 20, 2080) 0           block8_4_ac[0][0]                \n",
            "                                                                 block8_5_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_5_ac (Activation)        (None, 11, 20, 2080) 0           block8_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_184 (Conv2D)             (None, 11, 20, 192)  399360      block8_5_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_184 (BatchN (None, 11, 20, 192)  576         conv2d_184[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_184 (Activation)     (None, 11, 20, 192)  0           batch_normalization_184[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_185 (Conv2D)             (None, 11, 20, 224)  129024      activation_184[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_185 (BatchN (None, 11, 20, 224)  672         conv2d_185[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_185 (Activation)     (None, 11, 20, 224)  0           batch_normalization_185[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_183 (Conv2D)             (None, 11, 20, 192)  399360      block8_5_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_186 (Conv2D)             (None, 11, 20, 256)  172032      activation_185[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_183 (BatchN (None, 11, 20, 192)  576         conv2d_183[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_186 (BatchN (None, 11, 20, 256)  768         conv2d_186[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_183 (Activation)     (None, 11, 20, 192)  0           batch_normalization_183[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_186 (Activation)     (None, 11, 20, 256)  0           batch_normalization_186[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_6_mixed (Concatenate)    (None, 11, 20, 448)  0           activation_183[0][0]             \n",
            "                                                                 activation_186[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_6_conv (Conv2D)          (None, 11, 20, 2080) 933920      block8_6_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_6 (Lambda)               (None, 11, 20, 2080) 0           block8_5_ac[0][0]                \n",
            "                                                                 block8_6_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_6_ac (Activation)        (None, 11, 20, 2080) 0           block8_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_188 (Conv2D)             (None, 11, 20, 192)  399360      block8_6_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_188 (BatchN (None, 11, 20, 192)  576         conv2d_188[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_188 (Activation)     (None, 11, 20, 192)  0           batch_normalization_188[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_189 (Conv2D)             (None, 11, 20, 224)  129024      activation_188[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_189 (BatchN (None, 11, 20, 224)  672         conv2d_189[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_189 (Activation)     (None, 11, 20, 224)  0           batch_normalization_189[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_187 (Conv2D)             (None, 11, 20, 192)  399360      block8_6_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_190 (Conv2D)             (None, 11, 20, 256)  172032      activation_189[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_187 (BatchN (None, 11, 20, 192)  576         conv2d_187[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_190 (BatchN (None, 11, 20, 256)  768         conv2d_190[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_187 (Activation)     (None, 11, 20, 192)  0           batch_normalization_187[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_190 (Activation)     (None, 11, 20, 256)  0           batch_normalization_190[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_7_mixed (Concatenate)    (None, 11, 20, 448)  0           activation_187[0][0]             \n",
            "                                                                 activation_190[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_7_conv (Conv2D)          (None, 11, 20, 2080) 933920      block8_7_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_7 (Lambda)               (None, 11, 20, 2080) 0           block8_6_ac[0][0]                \n",
            "                                                                 block8_7_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_7_ac (Activation)        (None, 11, 20, 2080) 0           block8_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_192 (Conv2D)             (None, 11, 20, 192)  399360      block8_7_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_192 (BatchN (None, 11, 20, 192)  576         conv2d_192[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_192 (Activation)     (None, 11, 20, 192)  0           batch_normalization_192[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_193 (Conv2D)             (None, 11, 20, 224)  129024      activation_192[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_193 (BatchN (None, 11, 20, 224)  672         conv2d_193[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_193 (Activation)     (None, 11, 20, 224)  0           batch_normalization_193[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_191 (Conv2D)             (None, 11, 20, 192)  399360      block8_7_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_194 (Conv2D)             (None, 11, 20, 256)  172032      activation_193[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_191 (BatchN (None, 11, 20, 192)  576         conv2d_191[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_194 (BatchN (None, 11, 20, 256)  768         conv2d_194[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_191 (Activation)     (None, 11, 20, 192)  0           batch_normalization_191[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_194 (Activation)     (None, 11, 20, 256)  0           batch_normalization_194[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_8_mixed (Concatenate)    (None, 11, 20, 448)  0           activation_191[0][0]             \n",
            "                                                                 activation_194[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_8_conv (Conv2D)          (None, 11, 20, 2080) 933920      block8_8_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_8 (Lambda)               (None, 11, 20, 2080) 0           block8_7_ac[0][0]                \n",
            "                                                                 block8_8_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_8_ac (Activation)        (None, 11, 20, 2080) 0           block8_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_196 (Conv2D)             (None, 11, 20, 192)  399360      block8_8_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_196 (BatchN (None, 11, 20, 192)  576         conv2d_196[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_196 (Activation)     (None, 11, 20, 192)  0           batch_normalization_196[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_197 (Conv2D)             (None, 11, 20, 224)  129024      activation_196[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_197 (BatchN (None, 11, 20, 224)  672         conv2d_197[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_197 (Activation)     (None, 11, 20, 224)  0           batch_normalization_197[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_195 (Conv2D)             (None, 11, 20, 192)  399360      block8_8_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_198 (Conv2D)             (None, 11, 20, 256)  172032      activation_197[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_195 (BatchN (None, 11, 20, 192)  576         conv2d_195[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_198 (BatchN (None, 11, 20, 256)  768         conv2d_198[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_195 (Activation)     (None, 11, 20, 192)  0           batch_normalization_195[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_198 (Activation)     (None, 11, 20, 256)  0           batch_normalization_198[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_9_mixed (Concatenate)    (None, 11, 20, 448)  0           activation_195[0][0]             \n",
            "                                                                 activation_198[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_9_conv (Conv2D)          (None, 11, 20, 2080) 933920      block8_9_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_9 (Lambda)               (None, 11, 20, 2080) 0           block8_8_ac[0][0]                \n",
            "                                                                 block8_9_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_9_ac (Activation)        (None, 11, 20, 2080) 0           block8_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_200 (Conv2D)             (None, 11, 20, 192)  399360      block8_9_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_200 (BatchN (None, 11, 20, 192)  576         conv2d_200[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_200 (Activation)     (None, 11, 20, 192)  0           batch_normalization_200[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_201 (Conv2D)             (None, 11, 20, 224)  129024      activation_200[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_201 (BatchN (None, 11, 20, 224)  672         conv2d_201[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_201 (Activation)     (None, 11, 20, 224)  0           batch_normalization_201[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_199 (Conv2D)             (None, 11, 20, 192)  399360      block8_9_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_202 (Conv2D)             (None, 11, 20, 256)  172032      activation_201[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_199 (BatchN (None, 11, 20, 192)  576         conv2d_199[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_202 (BatchN (None, 11, 20, 256)  768         conv2d_202[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_199 (Activation)     (None, 11, 20, 192)  0           batch_normalization_199[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_202 (Activation)     (None, 11, 20, 256)  0           batch_normalization_202[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_10_mixed (Concatenate)   (None, 11, 20, 448)  0           activation_199[0][0]             \n",
            "                                                                 activation_202[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_10_conv (Conv2D)         (None, 11, 20, 2080) 933920      block8_10_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block8_10 (Lambda)              (None, 11, 20, 2080) 0           block8_9_ac[0][0]                \n",
            "                                                                 block8_10_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv_7b (Conv2D)                (None, 11, 20, 1536) 3194880     block8_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv_7b_bn (BatchNormalization) (None, 11, 20, 1536) 4608        conv_7b[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv_7b_ac (Activation)         (None, 11, 20, 1536) 0           conv_7b_bn[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 54,336,736\n",
            "Trainable params: 0\n",
            "Non-trainable params: 54,336,736\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "image_encoder_incpetion = tf.keras.applications.InceptionResNetV2(\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\",\n",
        "    input_shape=(img_h, img_w, 3)\n",
        ")\n",
        "\n",
        "for layer in image_encoder_incpetion.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "image_encoder_incpetion.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYXzWaM3UTcu"
      },
      "source": [
        "# Question Encoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9R_QqwkcUTcv"
      },
      "source": [
        "Load questions into a List"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARot36DMUTcv",
        "outputId": "dde86d2b-e47c-466f-adda-9e09d1fa1cf4"
      },
      "source": [
        "import json\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "dataset_dir = os.path.join(cwd, \"VQA_Dataset\", \"train_questions_annotations.json\")\n",
        "\n",
        "# Load dataset\n",
        "with open(dataset_dir) as f:\n",
        "    dic_images = json.load(f)\n",
        "            \n",
        "# Get all questions as strings in a list\n",
        "questions = [dic['question'] for dic in dic_images.values()]\n",
        "\n",
        "# Strip '?' from questions\n",
        "questions = [s.translate(str.maketrans('', '', '?')).lower() for s in questions if not s == '']\n",
        "print(questions[12])\n",
        "\n",
        "# max_words_in_sentence = max(len(question.split(' ')) for question in questions)\n",
        "# print(max_words_in_sentence)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "is there books on the bookshelf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdpNNjHfUTcv"
      },
      "source": [
        "Tokenize questions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOO22cQgUTcw",
        "outputId": "dbf7031a-2054-412c-8b16-475f78a0f976"
      },
      "source": [
        "# Create Tokenizer to convert words to integers\n",
        "questions_tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
        "questions_tokenizer.fit_on_texts(questions)\n",
        "\n",
        "questions_tokenized = questions_tokenizer.texts_to_sequences(questions)\n",
        "# each sentence into a sequence of tokens (in this case, only the 20000 most frequent)\n",
        "\n",
        "# \"hello raffaele\" -> [9, 78] \n",
        "\n",
        "questions_wtoi = questions_tokenizer.word_index # index 0 reserved for padding\n",
        "print('Total number of words:', len(questions_wtoi))\n",
        "\n",
        "print(questions_tokenized[0])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of words: 4640\n[47, 797, 1903]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymzic0aBUTcx",
        "outputId": "b1e5dd94-e020-4e38-ad9c-0f52930bb9e1"
      },
      "source": [
        "max_question_length = max(len(sentence) for sentence in questions_tokenized)\n",
        "print('Max question length:', max_question_length)\n",
        "\n",
        "# Pad to max question sentence length\n",
        "padded_questions = pad_sequences(questions_tokenized, maxlen=max_question_length)\n",
        "\n",
        "print(\"Padded questions shape:\", padded_questions.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max question length: 21\n",
            "Padded questions shape: (58832, 21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zo77RrxhUTcx"
      },
      "source": [
        "Load pre-trained GloVe embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcZ0PoapUTcx",
        "outputId": "8a3c55fd-fbbc-4e66-d574-cadf0f7b6ecb"
      },
      "source": [
        "#!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "#!unzip -q glove.6B.zip\n",
        "\n",
        "path_to_glove_file = os.path.join(cwd,'glove.6B\\glove.6B.100d.txt')\n",
        "\n",
        "embeddings_index = {}\n",
        "with open(path_to_glove_file, encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        word, coefs = line.split(maxsplit=1)\n",
        "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "print(\"Found\", len(embeddings_index), \"word vectors.\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 400000 word vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6qr1hXpUTcy",
        "outputId": "ce8b1e69-9b95-4343-ef8e-ceba9af99215"
      },
      "source": [
        "num_tokens = len(questions_wtoi) + 1\n",
        "embedding_dim = 100\n",
        "\n",
        "hits = 0\n",
        "misses = 0\n",
        "\n",
        "# Prepare embedding matrix\n",
        "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
        "for word, i in questions_wtoi.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # Words not found in embedding index will be all-zeros.\n",
        "        # This includes the representation for \"padding\" and \"OOV\"\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "        hits += 1\n",
        "    else:\n",
        "        misses += 1\n",
        "print(\"Converted %d words (%d misses)\" % (hits, misses))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converted 4496 words (144 misses)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTodOAuEUTcy"
      },
      "source": [
        "Create question encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gd6axT5yUTcy",
        "outputId": "be07b6fc-9a04-41cf-9e1e-448a8fc9fe90"
      },
      "source": [
        "embedding_layer = tf.keras.layers.Embedding(\n",
        "    num_tokens,\n",
        "    embedding_dim,\n",
        "    embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix),\n",
        "    trainable=False,\n",
        "    mask_zero=True,\n",
        "    input_length=max_question_length\n",
        ")\n",
        "\n",
        "question_encoder = tf.keras.models.Sequential()\n",
        "question_encoder.add(tf.keras.layers.Input(shape=(max_question_length,), dtype=\"int64\"))\n",
        "question_encoder.add(embedding_layer)\n",
        "question_encoder.add(tf.keras.layers.Dropout(PERC_DROP))\n",
        "question_encoder.add(tf.keras.layers.LSTM(units=FEATURES))\n",
        "\n",
        "question_encoder.summary()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding (Embedding)        (None, 21, 100)           464100    \n_________________________________________________________________\ndropout (Dropout)            (None, 21, 100)           0         \n_________________________________________________________________\nlstm (LSTM)                  (None, 1536)              10057728  \n=================================================================\nTotal params: 10,521,828\nTrainable params: 10,057,728\nNon-trainable params: 464,100\n_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqW-8-KqUTcz"
      },
      "source": [
        "# Create complete model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zC02WONzUTc5"
      },
      "source": [
        "Load indexes for answers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ova0isjGUTc6",
        "outputId": "44ce04cb-9aaf-4fbb-c883-6fc29ae34bfb",
        "tags": [
          "outputPrepend"
        ]
      },
      "source": [
        "multiplied_features = tf.keras.layers.Multiply()([image_encoder_incpetion.layers[-1].output, question_encoder.layers[-1].output])\n",
        "dense_1 = tf.keras.layers.Dense(UNITS, activation='tanh')(multiplied_features)\n",
        "drop_1 = tf.keras.layers.Dropout(PERC_DROP)(dense_1)\n",
        "out = tf.keras.layers.Dense(num_answers, activation='softmax')(drop_1)\n",
        "network = tf.keras.models.Model(inputs=[image_encoder_incpetion.layers[0].input, question_encoder.layers[0].input], outputs=out)\n",
        "\n",
        "network.summary()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             \n",
            "                                                                 activation_182[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_5_conv (Conv2D)          (None, 11, 20, 2080) 933920      block8_5_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_5 (Lambda)               (None, 11, 20, 2080) 0           block8_4_ac[0][0]                \n",
            "                                                                 block8_5_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_5_ac (Activation)        (None, 11, 20, 2080) 0           block8_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_184 (Conv2D)             (None, 11, 20, 192)  399360      block8_5_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_184 (BatchN (None, 11, 20, 192)  576         conv2d_184[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_184 (Activation)     (None, 11, 20, 192)  0           batch_normalization_184[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_185 (Conv2D)             (None, 11, 20, 224)  129024      activation_184[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_185 (BatchN (None, 11, 20, 224)  672         conv2d_185[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_185 (Activation)     (None, 11, 20, 224)  0           batch_normalization_185[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_183 (Conv2D)             (None, 11, 20, 192)  399360      block8_5_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_186 (Conv2D)             (None, 11, 20, 256)  172032      activation_185[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_183 (BatchN (None, 11, 20, 192)  576         conv2d_183[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_186 (BatchN (None, 11, 20, 256)  768         conv2d_186[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_183 (Activation)     (None, 11, 20, 192)  0           batch_normalization_183[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_186 (Activation)     (None, 11, 20, 256)  0           batch_normalization_186[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_6_mixed (Concatenate)    (None, 11, 20, 448)  0           activation_183[0][0]             \n",
            "                                                                 activation_186[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_6_conv (Conv2D)          (None, 11, 20, 2080) 933920      block8_6_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_6 (Lambda)               (None, 11, 20, 2080) 0           block8_5_ac[0][0]                \n",
            "                                                                 block8_6_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_6_ac (Activation)        (None, 11, 20, 2080) 0           block8_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_188 (Conv2D)             (None, 11, 20, 192)  399360      block8_6_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_188 (BatchN (None, 11, 20, 192)  576         conv2d_188[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_188 (Activation)     (None, 11, 20, 192)  0           batch_normalization_188[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_189 (Conv2D)             (None, 11, 20, 224)  129024      activation_188[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_189 (BatchN (None, 11, 20, 224)  672         conv2d_189[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_189 (Activation)     (None, 11, 20, 224)  0           batch_normalization_189[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_187 (Conv2D)             (None, 11, 20, 192)  399360      block8_6_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_190 (Conv2D)             (None, 11, 20, 256)  172032      activation_189[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_187 (BatchN (None, 11, 20, 192)  576         conv2d_187[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_190 (BatchN (None, 11, 20, 256)  768         conv2d_190[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_187 (Activation)     (None, 11, 20, 192)  0           batch_normalization_187[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_190 (Activation)     (None, 11, 20, 256)  0           batch_normalization_190[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_7_mixed (Concatenate)    (None, 11, 20, 448)  0           activation_187[0][0]             \n",
            "                                                                 activation_190[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_7_conv (Conv2D)          (None, 11, 20, 2080) 933920      block8_7_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_7 (Lambda)               (None, 11, 20, 2080) 0           block8_6_ac[0][0]                \n",
            "                                                                 block8_7_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_7_ac (Activation)        (None, 11, 20, 2080) 0           block8_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_192 (Conv2D)             (None, 11, 20, 192)  399360      block8_7_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_192 (BatchN (None, 11, 20, 192)  576         conv2d_192[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_192 (Activation)     (None, 11, 20, 192)  0           batch_normalization_192[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_193 (Conv2D)             (None, 11, 20, 224)  129024      activation_192[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_193 (BatchN (None, 11, 20, 224)  672         conv2d_193[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_193 (Activation)     (None, 11, 20, 224)  0           batch_normalization_193[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_191 (Conv2D)             (None, 11, 20, 192)  399360      block8_7_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_194 (Conv2D)             (None, 11, 20, 256)  172032      activation_193[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_191 (BatchN (None, 11, 20, 192)  576         conv2d_191[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_194 (BatchN (None, 11, 20, 256)  768         conv2d_194[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_191 (Activation)     (None, 11, 20, 192)  0           batch_normalization_191[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_194 (Activation)     (None, 11, 20, 256)  0           batch_normalization_194[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_8_mixed (Concatenate)    (None, 11, 20, 448)  0           activation_191[0][0]             \n",
            "                                                                 activation_194[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_8_conv (Conv2D)          (None, 11, 20, 2080) 933920      block8_8_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_8 (Lambda)               (None, 11, 20, 2080) 0           block8_7_ac[0][0]                \n",
            "                                                                 block8_8_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_8_ac (Activation)        (None, 11, 20, 2080) 0           block8_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_196 (Conv2D)             (None, 11, 20, 192)  399360      block8_8_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_196 (BatchN (None, 11, 20, 192)  576         conv2d_196[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_196 (Activation)     (None, 11, 20, 192)  0           batch_normalization_196[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_197 (Conv2D)             (None, 11, 20, 224)  129024      activation_196[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_197 (BatchN (None, 11, 20, 224)  672         conv2d_197[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_197 (Activation)     (None, 11, 20, 224)  0           batch_normalization_197[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_195 (Conv2D)             (None, 11, 20, 192)  399360      block8_8_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_198 (Conv2D)             (None, 11, 20, 256)  172032      activation_197[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_195 (BatchN (None, 11, 20, 192)  576         conv2d_195[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_198 (BatchN (None, 11, 20, 256)  768         conv2d_198[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_195 (Activation)     (None, 11, 20, 192)  0           batch_normalization_195[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_198 (Activation)     (None, 11, 20, 256)  0           batch_normalization_198[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_9_mixed (Concatenate)    (None, 11, 20, 448)  0           activation_195[0][0]             \n",
            "                                                                 activation_198[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_9_conv (Conv2D)          (None, 11, 20, 2080) 933920      block8_9_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_9 (Lambda)               (None, 11, 20, 2080) 0           block8_8_ac[0][0]                \n",
            "                                                                 block8_9_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_9_ac (Activation)        (None, 11, 20, 2080) 0           block8_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_200 (Conv2D)             (None, 11, 20, 192)  399360      block8_9_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_200 (BatchN (None, 11, 20, 192)  576         conv2d_200[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_200 (Activation)     (None, 11, 20, 192)  0           batch_normalization_200[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_201 (Conv2D)             (None, 11, 20, 224)  129024      activation_200[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_201 (BatchN (None, 11, 20, 224)  672         conv2d_201[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_201 (Activation)     (None, 11, 20, 224)  0           batch_normalization_201[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_199 (Conv2D)             (None, 11, 20, 192)  399360      block8_9_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_202 (Conv2D)             (None, 11, 20, 256)  172032      activation_201[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_199 (BatchN (None, 11, 20, 192)  576         conv2d_199[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_202 (BatchN (None, 11, 20, 256)  768         conv2d_202[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_199 (Activation)     (None, 11, 20, 192)  0           batch_normalization_199[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_202 (Activation)     (None, 11, 20, 256)  0           batch_normalization_202[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_10_mixed (Concatenate)   (None, 11, 20, 448)  0           activation_199[0][0]             \n",
            "                                                                 activation_202[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_10_conv (Conv2D)         (None, 11, 20, 2080) 933920      block8_10_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block8_10 (Lambda)              (None, 11, 20, 2080) 0           block8_9_ac[0][0]                \n",
            "                                                                 block8_10_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 21)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv_7b (Conv2D)                (None, 11, 20, 1536) 3194880     block8_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 21, 100)      464100      input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv_7b_bn (BatchNormalization) (None, 11, 20, 1536) 4608        conv_7b[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 21, 100)      0           embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv_7b_ac (Activation)         (None, 11, 20, 1536) 0           conv_7b_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 1536)         10057728    dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "multiply (Multiply)             (None, 11, 20, 1536) 0           conv_7b_ac[0][0]                 \n",
            "                                                                 lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 11, 20, 512)  786944      multiply[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 11, 20, 512)  0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 11, 20, 58)   29754       dropout_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 65,675,262\n",
            "Trainable params: 10,874,426\n",
            "Non-trainable params: 54,800,836\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpEEfu3ECEBu",
        "outputId": "5be72fad-c095-4e72-e0e8-d8202e929a28"
      },
      "source": [
        "learnings_r = [1e-3,2e-3,1e-4,2e-4,1e-6,2e-6,3e-6]\n",
        "for lr in learnings_r:\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "  metrics = ['accuracy']\n",
        "  loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "  network.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
        "  import os\n",
        "  from datetime import datetime\n",
        "\n",
        "  cwd = os.getcwd()\n",
        "\n",
        "  exps_dir = os.path.join('ResultsVQA', 'basic_model')\n",
        "  if not os.path.exists(exps_dir):\n",
        "      os.makedirs(exps_dir)\n",
        "\n",
        "  now = datetime.now().strftime('%b%d_%H-%M-%S')\n",
        "\n",
        "  exp_name = 'exp'\n",
        "\n",
        "  exp_dir = os.path.join(exps_dir, exp_name + '_' + str(now))\n",
        "  if not os.path.exists(exp_dir):\n",
        "      os.makedirs(exp_dir)\n",
        "      \n",
        "  callbacks = []\n",
        "\n",
        "  # Model checkpoint\n",
        "  # ----------------\n",
        "  ckpt_dir = os.path.join(exp_dir, 'ckpts')\n",
        "  if not os.path.exists(ckpt_dir):\n",
        "      os.makedirs(ckpt_dir)\n",
        "\n",
        "  ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(ckpt_dir, 'cp_{epoch:02d}.ckpt'), \n",
        "                                                    save_weights_only=True, save_best_only=True)  # False to save the model directly\n",
        "  callbacks.append(ckpt_callback)\n",
        "\n",
        "  # Early Stopping\n",
        "  # --------------\n",
        "  early_stop = True\n",
        "  if early_stop:\n",
        "      es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
        "      callbacks.append(es_callback)\n",
        "\n",
        "      # Callback Reduce On Plateau\n",
        "  # ------------------\n",
        "  red_callback = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "      monitor=\"val_loss\",\n",
        "      factor=decay,\n",
        "      patience=5,\n",
        "      verbose=1,\n",
        "      mode=\"min\",\n",
        "      cooldown=0,\n",
        "      min_lr=minimum\n",
        "  )\n",
        "\n",
        "  callbacks.append(red_callback)\n",
        "\n",
        "  # ---------------------------------\n",
        "  network.fit(x=gen,\n",
        "            epochs=10,\n",
        "            steps_per_epoch=len(gen),\n",
        "            validation_data=gen_val,\n",
        "            validation_steps=len(gen_val),\n",
        "            callbacks=callbacks)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:sample_weight modes were coerced from\n",
            "  ...\n",
            "    to  \n",
            "  ['...']\n",
            "WARNING:tensorflow:sample_weight modes were coerced from\n",
            "  ...\n",
            "    to  \n",
            "  ['...']\n",
            "Train for 11766 steps, validate for 2941 steps\n",
            "Epoch 1/10\n",
            "    1/11766 [..............................] - ETA: 72:35:19WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: \n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: lr\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": " Incompatible shapes: [4,1] vs. [4,11,20]\n\t [[node metrics/accuracy/Equal (defined at <ipython-input-20-f8b244083ab8>:63) ]] [Op:__inference_distributed_function_45774]\n\nFunction call stack:\ndistributed_function\n",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-20-f8b244083ab8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgen_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgen_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m             callbacks=callbacks)\n\u001b[0m",
            "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    630\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 632\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    633\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
            "\u001b[1;31mInvalidArgumentError\u001b[0m:  Incompatible shapes: [4,1] vs. [4,11,20]\n\t [[node metrics/accuracy/Equal (defined at <ipython-input-20-f8b244083ab8>:63) ]] [Op:__inference_distributed_function_45774]\n\nFunction call stack:\ndistributed_function\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhV3bWhTs9ji"
      },
      "source": [
        "# Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvB8rOu5K1uM"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import string\n",
        "from PIL import Image\n",
        "\n",
        "path = './VQA_Dataset/test_questions.json'\n",
        "max_question_length = 21\n",
        "# preprocessing_function = tf.keras.applications.vgg16.preprocess_input\n",
        "dat_dir = './VQA_Dataset/Images'\n",
        "# ckpt_dir = os.path.join(cwd, 'Checkpoints', model_name)\n",
        "# network.load_weights(os.path.join(ckpt_dir, 'basic_model_xception-weights-Jan08_22-02-28-epoch-04'))\n",
        "#os.listdir('/content/drive/MyDrive/ResultsVQA/exp_Jan06_23-07-25/ckpts')\n",
        "#network.load_weights('/content/drive/MyDrive/ResultsVQA/exp_Jan06_23-07-25/ckpts/cp_23')\n",
        "\n",
        "with open(path) as f:\n",
        "       dic_test = json.load(f)\n",
        "\n",
        "dic_test_values = dic_test.values()\n",
        "test_questions = [q['question'].lower().translate(str.maketrans('', '', string.punctuation)) for q in dic_test_values]\n",
        "\n",
        "test_tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
        "test_tokenizer.fit_on_texts(test_questions)\n",
        "\n",
        "test_wtoi = test_tokenizer.word_index\n",
        "\n",
        "test_tokenized = test_tokenizer.texts_to_sequences(test_questions)\n",
        "\n",
        "# print(test_tokenized[45])\n",
        "# max_question_length = max(len(sentence) for sentence in test_tokenized)        \n",
        "\n",
        "results = dict()\n",
        "\n",
        "count = 0\n",
        "print('Prediction started, printing every 100 samples computed...')\n",
        "\n",
        "for question_id in dic_test.keys():\n",
        "    \n",
        "    temp_dic = dic_test[question_id]\n",
        "    # print(temp)\n",
        "    \n",
        "    # Get question text\n",
        "    question = temp_dic['question'].lower().translate(str.maketrans('', '', string.punctuation))\n",
        "    # print(question)\n",
        "    \n",
        "    # Get related image\n",
        "    image_id = temp_dic['image_id']\n",
        "    \n",
        "    # Open image and apply preprocessing\n",
        "    img = Image.open(os.path.join(dat_dir, image_id + \".png\"))\n",
        "    img = img.convert('RGB')\n",
        "    img_arr = np.array(img)\n",
        "    img_arr = np.expand_dims(img_arr, axis=0)\n",
        "    img_arr = preprocessing_function(img_arr)\n",
        "    \n",
        "    # Tokenize question text with test tokenizer\n",
        "    #question_tokenized = test_tokenizer.texts_to_sequences([question])\n",
        "    \n",
        "    # Tokenize question text with QUESITIONS tokenizer from training phase\n",
        "    question_tokenized = questions_tokenizer.texts_to_sequences([question])\n",
        "    \n",
        "    # Pad question to correct length (21)\n",
        "    padded_question = pad_sequences(question_tokenized, maxlen=max_question_length)\n",
        "    # print(padded_question)\n",
        "    \n",
        "    # Get prediction\n",
        "    result = network.predict([img_arr, padded_question], verbose=0, batch_size=1)\n",
        "    \n",
        "    # Get index with max probability\n",
        "    result = tf.argmax(result[0])\n",
        "    result = int(result)\n",
        "    # itoa = {v: k for k, v in labels_dict.items()}\n",
        "    # answer = itoa[result]\n",
        "    # print(answer)\n",
        "    \n",
        "    # Add to results dictionary\n",
        "    results[question_id] = result\n",
        "    \n",
        "    count += 1\n",
        "    \n",
        "    if (count%100==0):\n",
        "        print(count)\n",
        "    \n",
        "    # print(question_id, question, image_id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pd1NdW_4yXxC"
      },
      "source": [
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "def create_csv(results, results_dir='./'):\n",
        "\n",
        "    csv_fname = 'results_'\n",
        "    csv_fname += datetime.now().strftime('%b%d_%H-%M-%S') + '.csv'\n",
        "\n",
        "    with open(os.path.join(results_dir, csv_fname), 'w') as f:\n",
        "\n",
        "        f.write('Id,Category\\n')\n",
        "\n",
        "        for key, value in results.items():\n",
        "            f.write(key + ',' + str(value) + '\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJ8ImytbydAg"
      },
      "source": [
        "create_csv(results, results_dir='/content/drive/MyDrive/ResultsVQA')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}