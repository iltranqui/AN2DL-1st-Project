{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('tensorflow_gpuenv': conda)",
   "metadata": {
    "interpreter": {
     "hash": "b4475d159700ac7f63d83dbd0a06e80f15c08c0a62544dac6ddf2e61acd99b97"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# To Visualize and Analysze tomorrow"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "SEED = 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "c:\\Users\\enric\\Downloads\\AN2DL-1st-Project\\MaskDataset\n"
     ]
    }
   ],
   "source": [
    "# Creating the training set\n",
    "dataset_dir = os.getcwd() # Obtain \n",
    "dataset_dir = os.path.join(dataset_dir,'MaskDataset')\n",
    "print(dataset_dir)\n",
    "train_dir = os.path.join(dataset_dir, 'training')\n",
    "\n",
    "classes = [\"nomask\",\"allmask\",\"someone\"]\n",
    "\n",
    "# Create generators to read images from dataset directory\n",
    "# -------------------------------------------------------\n",
    "\n",
    "# Batch size\n",
    "bs = 8\n",
    "\n",
    "# img shape\n",
    "img_h = 256\n",
    "img_w = 256\n",
    "\n",
    "num_classes = 3\n",
    "\n",
    "# for image in os.path.listdir():  # all the images in the folder\n",
    "\n"
   ]
  },
  {
   "source": [
    "## Making the Image Generator"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# ImageDataGenerator, it is a class\n",
    "# ------------------\n",
    "# Generate batches of tensor image data with real-time data augmentation.\n",
    "# you have to prepare/create the dataset into a specific format that keras expects\n",
    "\n",
    "#The data will be looped over (in batches)\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "apply_data_augmentation = True\n",
    "\n",
    "# Create training ImageDataGenerator object\n",
    "if apply_data_augmentation:\n",
    "    train_data_gen = ImageDataGenerator(rotation_range=10,\n",
    "                                        width_shift_range=10,\n",
    "                                        height_shift_range=10,\n",
    "                                        zoom_range=0.3,\n",
    "                                        horizontal_flip=True,\n",
    "                                        vertical_flip=True,\n",
    "                                        fill_mode='constant',\n",
    "                                        cval=0,\n",
    "                                        rescale=1./255)\n",
    "else:\n",
    "    train_data_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create validation and test ImageDataGenerator objects\n",
    "valid_data_gen = ImageDataGenerator(rescale=1./255)\n",
    "test_data_gen = ImageDataGenerator(rescale=1./255)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 3,
   "outputs": []
  },
  {
   "source": [
    "## Importing the Json file and creating a dataframe"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "with open(os.path.join(dataset_dir,\"train_gt.json\")) as f:\n",
    "  dic = json.load(f)\n",
    "\n",
    "dataframe = pd.DataFrame(dic.items())  # putting all the \n",
    "dataframe.rename(columns = {0:'filename', 1:'class'}, inplace = True)\n",
    "dataframe[\"class\"] = dataframe[\"class\"].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## Creating the Training Set"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 5614 validated image filenames belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# Creating the training set for the images ! \n",
    "train_gen = []\n",
    "train_gen = train_data_gen.flow_from_dataframe(dataframe,\n",
    "                                               train_dir,\n",
    "                                               batch_size=bs,\n",
    "                                               target_size=(img_h, img_w),\n",
    "                                               class_mode='categorical',\n",
    "                                               shuffle=True,\n",
    "                                               seed=SEED) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 0 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# Test  \n",
    "test_dir = os.path.join(dataset_dir, 'test')\n",
    "test_gen = []\n",
    "test_gen = test_data_gen.flow_from_directory(test_dir,\n",
    "                                             batch_size=bs, \n",
    "                                             classes=classes,\n",
    "                                             class_mode='categorical',\n",
    "                                             shuffle=False,\n",
    "                                             seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'0': 0, '1': 1, '2': 2}"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# Check how keras assigned the labels\n",
    "train_gen.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataset objects\n",
    "# ----------------------\n",
    "\n",
    "# img shape\n",
    "img_h = 256\n",
    "img_w = 256\n",
    "\n",
    "\n",
    "# Training\n",
    "train_dataset = tf.data.Dataset.from_generator(lambda: train_gen,\n",
    "                                               output_types=(tf.float32, tf.float32),\n",
    "                                               output_shapes=([None, img_h, img_w, 3], [None, num_classes]))\n",
    "\n",
    "# Shuffle (Already done in generator..)\n",
    "# train_dataset          train_dataset.shuffle(buffer_size=len(train_gen))\n",
    "\n",
    "# Normalize images (Already done in generator..)\n",
    "# def normalize_img(x_, y_):\n",
    "#     return tf.cast(x_, tf.float32) / 255., y_\n",
    "\n",
    "# train_dataset = train_dataset.map(normalize_img)\n",
    "\n",
    "# 1-hot encoding <- for categorical cross entropy (Already done in generator..)\n",
    "# def to_categorical(x_, y_):\n",
    "#     return x_, tf.one_hot(y_, depth=10)\n",
    "\n",
    "# train_dataset = train_dataset.map(to_categorical)\n",
    "\n",
    "# Divide in batches (Already done in generator..)\n",
    "# train_dataset = train_dataset.batch(bs)\n",
    "\n",
    "# Repeat\n",
    "# Without calling the repeat function the dataset \n",
    "# will be empty after consuming all the images\n",
    "train_dataset = train_dataset.repeat()\n",
    "\n",
    "# Validation\n",
    "# ----------\n",
    "valid_dataset = tf.data.Dataset.from_generator(lambda: valid_gen, \n",
    "                                               output_types=(tf.float32, tf.float32),\n",
    "                                               output_shapes=([None, img_h, img_w, 3], [None, num_classes]))\n",
    "\n",
    "# Repeat\n",
    "valid_dataset = valid_dataset.repeat()\n",
    "\n",
    "# Test\n",
    "# ----\n",
    "test_dataset = tf.data.Dataset.from_generator(lambda: test_gen,\n",
    "                                              output_types=(tf.float32, tf.float32),\n",
    "                                              output_shapes=([None, img_h, img_w, 3], [None, num_classes]))\n",
    "\n",
    "# Repeat\n",
    "test_dataset = valid_dataset.repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Architecture: Features extraction -> Classifier\n",
    "\n",
    "start_f = 8\n",
    "depth = 5\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "# Features extraction\n",
    "for i in range(depth):\n",
    "\n",
    "    if i == 0:\n",
    "        input_shape = [img_h, img_w, 3]\n",
    "    else:\n",
    "        input_shape=[None]\n",
    "\n",
    "    # Conv block: Conv2D -> Activation -> Pooling\n",
    "    model.add(tf.keras.layers.Conv2D(filters=start_f, \n",
    "                                     kernel_size=(3, 3),\n",
    "                                     strides=(1, 1),\n",
    "                                     padding='same',\n",
    "                                     input_shape=input_shape))\n",
    "    model.add(tf.keras.layers.ReLU())\n",
    "    model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "    start_f *= 2\n",
    "    \n",
    "# Classifier\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(units=512, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(units=num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 256, 256, 8)       224       \n_________________________________________________________________\nre_lu (ReLU)                 (None, 256, 256, 8)       0         \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 128, 128, 8)       0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 128, 128, 16)      1168      \n_________________________________________________________________\nre_lu_1 (ReLU)               (None, 128, 128, 16)      0         \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 64, 64, 16)        0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 64, 64, 32)        4640      \n_________________________________________________________________\nre_lu_2 (ReLU)               (None, 64, 64, 32)        0         \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 32, 32, 32)        0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 32, 32, 64)        18496     \n_________________________________________________________________\nre_lu_3 (ReLU)               (None, 32, 32, 64)        0         \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 16, 16, 64)        0         \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 16, 16, 128)       73856     \n_________________________________________________________________\nre_lu_4 (ReLU)               (None, 16, 16, 128)       0         \n_________________________________________________________________\nmax_pooling2d_4 (MaxPooling2 (None, 8, 8, 128)         0         \n_________________________________________________________________\nflatten (Flatten)            (None, 8192)              0         \n_________________________________________________________________\ndense (Dense)                (None, 512)               4194816   \n_________________________________________________________________\ndense_1 (Dense)              (None, 3)                 1539      \n=================================================================\nTotal params: 4,294,739\nTrainable params: 4,294,739\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       [-0.00504048,  0.01446589, -0.06117932, ...,  0.09558509,\n",
       "           -0.09228083,  0.04941895],\n",
       "          [ 0.07341053, -0.0970466 ,  0.05740125, ...,  0.05505129,\n",
       "           -0.08096112,  0.03251795],\n",
       "          ...,\n",
       "          [-0.02656598,  0.02611034, -0.00756429, ..., -0.02572082,\n",
       "           -0.01187788, -0.02018443],\n",
       "          [-0.03040224,  0.10794073,  0.04180027, ..., -0.07524112,\n",
       "            0.04249012,  0.00624765],\n",
       "          [ 0.00448723, -0.04765429, -0.10389086, ..., -0.08555734,\n",
       "           -0.06856059, -0.09833778]],\n",
       " \n",
       "         [[-0.05244377,  0.10792788,  0.0439656 , ...,  0.01578363,\n",
       "           -0.10296647, -0.00462981],\n",
       "          [-0.02755921, -0.07146667,  0.01802643, ...,  0.04395459,\n",
       "            0.06026269, -0.09898575],\n",
       "          [ 0.01439688,  0.10501081, -0.10126637, ..., -0.04637729,\n",
       "            0.09417733, -0.08024074],\n",
       "          ...,\n",
       "          [ 0.00053108,  0.04549941, -0.00534728, ..., -0.10111549,\n",
       "            0.09660361,  0.02085251],\n",
       "          [-0.04417459,  0.02356706, -0.06838672, ...,  0.00637842,\n",
       "            0.10769043, -0.11459383],\n",
       "          [-0.00608533, -0.01572204,  0.07223967, ..., -0.11783326,\n",
       "           -0.05045523,  0.08107644]],\n",
       " \n",
       "         [[ 0.10639899, -0.11351293, -0.03534084, ...,  0.07671111,\n",
       "           -0.09614528,  0.05712097],\n",
       "          [-0.04962362, -0.09462007,  0.11027538, ...,  0.07618996,\n",
       "           -0.11018468, -0.02765881],\n",
       "          [ 0.05154394,  0.05767146,  0.11403549, ..., -0.10624512,\n",
       "           -0.00029879, -0.04697227],\n",
       "          ...,\n",
       "          [ 0.07870505,  0.03940261,  0.02125401, ..., -0.01294754,\n",
       "           -0.03761095, -0.10139892],\n",
       "          [ 0.07903782, -0.08421932,  0.03939994, ...,  0.08389366,\n",
       "            0.01629271,  0.02091338],\n",
       "          [ 0.05326634,  0.00902549,  0.02881383, ...,  0.07885826,\n",
       "            0.01623913, -0.03109951]]]], dtype=float32)>,\n",
       " <tf.Variable 'conv2d_2/bias:0' shape=(32,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'conv2d_3/kernel:0' shape=(3, 3, 32, 64) dtype=float32, numpy=\n",
       " array([[[[-0.0387973 ,  0.04995728, -0.01591158, ..., -0.02638227,\n",
       "            0.07963123, -0.04924534],\n",
       "          [-0.0345725 ,  0.02101137,  0.01282531, ...,  0.08029946,\n",
       "            0.05080227,  0.07782974],\n",
       "          [-0.05555838,  0.07199765,  0.06514762, ..., -0.01574252,\n",
       "           -0.01804576,  0.07987841],\n",
       "          ...,\n",
       "          [ 0.01588378,  0.03556065, -0.07732928, ..., -0.0008539 ,\n",
       "           -0.04374043,  0.00489467],\n",
       "          [ 0.01745397,  0.01734082, -0.0223063 , ..., -0.07066842,\n",
       "            0.06337593, -0.08230025],\n",
       "          [ 0.0310787 , -0.02485748, -0.02043635, ..., -0.02124932,\n",
       "            0.06027695,  0.06366903]],\n",
       " \n",
       "         [[ 0.07673075,  0.07786808,  0.01760099, ...,  0.00164584,\n",
       "           -0.08307831,  0.03222748],\n",
       "          [-0.04758567,  0.08170853,  0.06864657, ..., -0.00797373,\n",
       "           -0.01132345,  0.06575897],\n",
       "          [-0.03493836, -0.00060761,  0.00923812, ...,  0.06770471,\n",
       "            0.00786638, -0.04462081],\n",
       "          ...,\n",
       "          [-0.0179894 ,  0.02599535,  0.04879806, ..., -0.04045558,\n",
       "            0.07806238,  0.02685239],\n",
       "          [ 0.00990516,  0.01904041,  0.08217607, ...,  0.0412766 ,\n",
       "            0.02207172, -0.04547065],\n",
       "          [-0.0163875 , -0.03183446, -0.0633845 , ...,  0.07847864,\n",
       "            0.03221303, -0.06954777]],\n",
       " \n",
       "         [[ 0.03683241, -0.0502013 ,  0.03362026, ...,  0.04708997,\n",
       "            0.03859073,  0.0525629 ],\n",
       "          [-0.02798533, -0.07602537, -0.06917592, ...,  0.05977536,\n",
       "            0.04617182, -0.01996597],\n",
       "          [ 0.05376532, -0.02390832,  0.06675335, ...,  0.02074301,\n",
       "           -0.0637605 ,  0.06530347],\n",
       "          ...,\n",
       "          [-0.01438799,  0.06509849, -0.01929655, ..., -0.08094911,\n",
       "            0.07186697,  0.03059554],\n",
       "          [-0.03562443, -0.05497509, -0.08284861, ...,  0.00043527,\n",
       "            0.07712821, -0.02808688],\n",
       "          [ 0.08207641, -0.07303375, -0.04510061, ..., -0.06393137,\n",
       "           -0.07811666, -0.08102431]]],\n",
       " \n",
       " \n",
       "        [[[ 0.00432082, -0.06077763,  0.01165781, ...,  0.03225631,\n",
       "            0.00486829, -0.07899635],\n",
       "          [ 0.02054232,  0.07743547, -0.03501634, ...,  0.00049559,\n",
       "           -0.01302692, -0.05339547],\n",
       "          [-0.0125458 ,  0.05581548,  0.00069183, ..., -0.05411651,\n",
       "           -0.00825606,  0.08128216],\n",
       "          ...,\n",
       "          [ 0.05575398,  0.01465438, -0.04769143, ...,  0.06849933,\n",
       "            0.05907572,  0.07515735],\n",
       "          [ 0.06845023,  0.07838877,  0.07302172, ..., -0.08231513,\n",
       "            0.01055022, -0.08332042],\n",
       "          [-0.07074483,  0.00672332, -0.01769916, ..., -0.03440289,\n",
       "           -0.02416049,  0.08320678]],\n",
       " \n",
       "         [[-0.03653121, -0.08031701, -0.08300614, ...,  0.02475629,\n",
       "           -0.07349294, -0.04703971],\n",
       "          [-0.03031296, -0.0152516 ,  0.00661365, ..., -0.01549327,\n",
       "            0.04126149,  0.06835229],\n",
       "          [ 0.05919678, -0.08243436, -0.05860186, ...,  0.01076522,\n",
       "            0.00627637,  0.06465545],\n",
       "          ...,\n",
       "          [ 0.07836432,  0.00232508, -0.04133916, ...,  0.01414315,\n",
       "           -0.07039299, -0.00218805],\n",
       "          [-0.01993404,  0.02569542,  0.02672392, ..., -0.01852306,\n",
       "            0.03229823,  0.07240067],\n",
       "          [-0.06767385,  0.05493189, -0.00486398, ...,  0.07771442,\n",
       "            0.04568674,  0.00165252]],\n",
       " \n",
       "         [[ 0.0381007 , -0.08191123,  0.04332938, ..., -0.07692085,\n",
       "            0.03012758, -0.07312679],\n",
       "          [ 0.02988044,  0.07182046,  0.00859622, ..., -0.00946319,\n",
       "            0.05709434,  0.04742888],\n",
       "          [-0.00498084, -0.04270333, -0.07504313, ...,  0.03663025,\n",
       "            0.0790431 ,  0.08211143],\n",
       "          ...,\n",
       "          [ 0.02607324,  0.02667934, -0.00197991, ...,  0.05902887,\n",
       "           -0.01772646,  0.07334427],\n",
       "          [ 0.01072111, -0.04531366,  0.03407349, ..., -0.0259016 ,\n",
       "            0.05432878, -0.03479439],\n",
       "          [-0.03885758, -0.05650886, -0.01295292, ...,  0.07453451,\n",
       "           -0.04886806,  0.03785294]]],\n",
       " \n",
       " \n",
       "        [[[ 0.04872034,  0.06867696, -0.02278511, ...,  0.02836102,\n",
       "            0.04221649, -0.00345802],\n",
       "          [ 0.01788004, -0.00992342, -0.04328477, ...,  0.0524402 ,\n",
       "            0.02961525, -0.04277144],\n",
       "          [-0.0539885 , -0.01718476, -0.02745871, ..., -0.0133398 ,\n",
       "            0.05124567,  0.02200689],\n",
       "          ...,\n",
       "          [ 0.03428975, -0.00774429, -0.05389396, ..., -0.05145381,\n",
       "           -0.07622842,  0.03485706],\n",
       "          [ 0.07857879, -0.06819068,  0.0594394 , ...,  0.07636996,\n",
       "           -0.00435239,  0.04854686],\n",
       "          [-0.07722098, -0.07682264,  0.04917011, ...,  0.00711614,\n",
       "            0.00128379,  0.08290913]],\n",
       " \n",
       "         [[-0.01813398,  0.04710384, -0.03475706, ..., -0.02055522,\n",
       "           -0.0457589 ,  0.08093471],\n",
       "          [ 0.06575481, -0.00313282, -0.06437467, ..., -0.03774587,\n",
       "            0.07787434,  0.00807831],\n",
       "          [-0.05268534, -0.04090124,  0.06080689, ..., -0.00631031,\n",
       "           -0.05751858,  0.00675335],\n",
       "          ...,\n",
       "          [-0.0429461 ,  0.05021701, -0.03930918, ..., -0.03286701,\n",
       "            0.02402981, -0.06121417],\n",
       "          [-0.05629581, -0.00875831, -0.03901311, ...,  0.00114229,\n",
       "           -0.01384219,  0.08193924],\n",
       "          [ 0.05724091,  0.04421405, -0.07593988, ..., -0.07451006,\n",
       "           -0.06574827,  0.02739092]],\n",
       " \n",
       "         [[ 0.07490937,  0.04679567,  0.00650879, ...,  0.05204526,\n",
       "            0.03860968,  0.08331921],\n",
       "          [-0.05273583, -0.04763689,  0.06128754, ...,  0.0596    ,\n",
       "            0.05373094,  0.0821634 ],\n",
       "          [-0.05839632,  0.0449594 ,  0.07328995, ..., -0.00998465,\n",
       "           -0.0195998 , -0.02215924],\n",
       "          ...,\n",
       "          [-0.0676954 ,  0.00353596,  0.01303891, ..., -0.02033993,\n",
       "           -0.00123024, -0.01621666],\n",
       "          [ 0.03545228,  0.04781661,  0.05964866, ...,  0.01277959,\n",
       "            0.04735901,  0.04915646],\n",
       "          [-0.00379159, -0.01058733,  0.06907947, ..., -0.0723302 ,\n",
       "           -0.00627428,  0.01007406]]]], dtype=float32)>,\n",
       " <tf.Variable 'conv2d_3/bias:0' shape=(64,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'conv2d_4/kernel:0' shape=(3, 3, 64, 128) dtype=float32, numpy=\n",
       " array([[[[-4.34171557e-02,  1.26922317e-02, -2.17737779e-02, ...,\n",
       "            2.15068646e-02, -4.71622124e-02,  3.73723693e-02],\n",
       "          [-3.68751213e-03,  3.32491286e-02, -5.20242564e-02, ...,\n",
       "            3.26361321e-02,  4.30070125e-02,  3.45480777e-02],\n",
       "          [-5.52780367e-02, -5.75896353e-02,  4.13219668e-02, ...,\n",
       "            9.55000147e-03,  2.64735855e-02, -1.30869187e-02],\n",
       "          ...,\n",
       "          [ 1.59497745e-02, -3.41771543e-03, -3.51800025e-02, ...,\n",
       "           -3.21484208e-02, -4.51683402e-02, -3.26088890e-02],\n",
       "          [-2.10151784e-02,  4.05670889e-02, -5.32918237e-02, ...,\n",
       "           -1.47171319e-03, -5.63383251e-02,  1.28499828e-02],\n",
       "          [-7.10298121e-03, -1.05834231e-02, -8.76724720e-03, ...,\n",
       "           -1.84815601e-02,  5.18073253e-02, -1.39833838e-02]],\n",
       " \n",
       "         [[-1.57479458e-02,  9.19158384e-03,  2.91024111e-02, ...,\n",
       "            4.69249226e-02,  6.60265610e-03,  2.96700634e-02],\n",
       "          [-2.57899091e-02,  2.34062932e-02,  1.14062317e-02, ...,\n",
       "           -4.04241942e-02, -1.05775259e-02,  1.67505778e-02],\n",
       "          [-1.17530562e-02,  5.76237477e-02, -5.02374992e-02, ...,\n",
       "           -1.59375481e-02, -3.78475338e-02, -5.24826720e-03],\n",
       "          ...,\n",
       "          [-2.62502804e-02, -3.69199067e-02, -2.81360000e-04, ...,\n",
       "            3.81923951e-02, -3.43076326e-02,  3.61410640e-02],\n",
       "          [-5.89204095e-02, -1.53751299e-02, -2.00320184e-02, ...,\n",
       "           -1.81655288e-02, -2.28689797e-02,  5.56009375e-02],\n",
       "          [-3.25845852e-02, -9.41827893e-05, -3.29620540e-02, ...,\n",
       "           -5.45020439e-02, -2.37637684e-02, -4.96939309e-02]],\n",
       " \n",
       "         [[-1.05872601e-02, -3.57814655e-02,  2.15112604e-02, ...,\n",
       "            3.09297182e-02,  3.37157212e-02,  2.48076878e-02],\n",
       "          [-4.08635326e-02, -4.96264957e-02, -2.39659213e-02, ...,\n",
       "           -5.68277910e-02, -1.74518451e-02,  2.68674083e-02],\n",
       "          [ 2.09314562e-02, -9.70122218e-03, -3.63631919e-03, ...,\n",
       "            3.28529514e-02,  5.57214059e-02, -4.60757092e-02],\n",
       "          ...,\n",
       "          [ 2.77281888e-02, -1.11495331e-03,  2.44960599e-02, ...,\n",
       "            4.19241451e-02, -3.38141359e-02, -1.05120689e-02],\n",
       "          [ 2.58485191e-02,  2.70039104e-02, -1.87095329e-02, ...,\n",
       "            3.55618075e-03,  3.29977684e-02,  5.50972857e-02],\n",
       "          [ 5.51922433e-02, -3.77142057e-02, -5.26772514e-02, ...,\n",
       "            1.49790607e-02, -4.16539684e-02,  9.11347196e-03]]],\n",
       " \n",
       " \n",
       "        [[[-2.70240530e-02, -2.62380280e-02, -1.13806874e-02, ...,\n",
       "           -3.32365707e-02,  9.11937281e-03,  2.65838690e-02],\n",
       "          [-2.87919119e-03,  2.80254893e-02, -1.80077888e-02, ...,\n",
       "           -5.41521125e-02,  5.37223555e-02,  2.92616747e-02],\n",
       "          [ 1.88402086e-03, -4.91809770e-02,  6.54741749e-03, ...,\n",
       "           -7.70250335e-03,  3.68450172e-02,  2.08272971e-02],\n",
       "          ...,\n",
       "          [ 2.63666920e-02, -2.14238092e-03,  2.85555683e-02, ...,\n",
       "            5.09331860e-02,  1.50892995e-02, -4.93227839e-02],\n",
       "          [ 1.02587044e-04,  1.86306350e-02,  2.13175975e-02, ...,\n",
       "            4.33660559e-02,  1.49086118e-04, -5.17433509e-02],\n",
       "          [ 1.00934841e-02, -5.83821386e-02,  8.16135481e-03, ...,\n",
       "           -7.17630237e-03, -1.54307187e-02,  4.18007784e-02]],\n",
       " \n",
       "         [[-2.05882713e-02,  5.78356050e-02,  5.89044504e-02, ...,\n",
       "           -1.97669715e-02, -3.91136929e-02,  4.16025482e-02],\n",
       "          [ 5.74992336e-02, -2.78168209e-02,  1.42773427e-02, ...,\n",
       "           -3.20022143e-02,  2.84241140e-03,  3.81786563e-02],\n",
       "          [-2.14306451e-02,  4.57745418e-03, -4.93584424e-02, ...,\n",
       "           -1.23140179e-02, -5.16701527e-02, -5.40511981e-02],\n",
       "          ...,\n",
       "          [-5.36925718e-02,  2.17223428e-02, -4.38414179e-02, ...,\n",
       "            4.45684828e-02, -8.84474069e-03,  4.73741554e-02],\n",
       "          [ 9.44029167e-03,  3.94031294e-02, -3.61769311e-02, ...,\n",
       "           -5.04818112e-02,  4.98161726e-02,  4.27952074e-02],\n",
       "          [ 1.19719915e-02, -5.11487983e-02,  3.11681591e-02, ...,\n",
       "            5.76604418e-02, -2.15897523e-02, -3.22434492e-02]],\n",
       " \n",
       "         [[-4.16247621e-02,  3.91151942e-02,  1.12419166e-02, ...,\n",
       "            3.48247923e-02,  5.49148731e-02,  5.07693924e-02],\n",
       "          [ 3.07594724e-02, -5.69867976e-02, -4.27672639e-02, ...,\n",
       "           -9.41561908e-03,  1.44943185e-02, -2.12005377e-02],\n",
       "          [ 3.18949334e-02,  3.68571095e-02,  5.44952564e-02, ...,\n",
       "            4.55728509e-02, -5.82453012e-02,  4.25633825e-02],\n",
       "          ...,\n",
       "          [-6.75819069e-03,  3.65724750e-02, -4.47333306e-02, ...,\n",
       "           -5.57795689e-02, -5.81005588e-03,  1.19565390e-02],\n",
       "          [ 3.66045944e-02,  3.40342708e-02, -2.54121348e-02, ...,\n",
       "           -2.99848691e-02,  5.19175418e-02, -2.52591819e-02],\n",
       "          [-2.17351578e-02, -3.64348292e-02,  7.92262331e-03, ...,\n",
       "           -1.26849227e-02,  1.72725059e-02,  1.90200545e-02]]],\n",
       " \n",
       " \n",
       "        [[[ 4.42802943e-02, -4.79825027e-02, -3.00880037e-02, ...,\n",
       "           -4.10980359e-02, -3.70628014e-02,  5.76117747e-02],\n",
       "          [ 4.94998135e-02,  1.83847807e-02,  5.73919341e-03, ...,\n",
       "           -1.99402347e-02,  3.00264396e-02, -3.17666307e-03],\n",
       "          [-1.16259269e-02, -2.19451189e-02, -1.98319033e-02, ...,\n",
       "           -4.89340350e-02,  2.28248201e-02,  4.94610257e-02],\n",
       "          ...,\n",
       "          [-5.60204387e-02,  2.83550955e-02, -5.67913055e-04, ...,\n",
       "            2.88961865e-02, -2.93410942e-03, -9.62618738e-03],\n",
       "          [-1.83855109e-02, -5.28343618e-02, -5.40708825e-02, ...,\n",
       "           -4.97020073e-02, -2.54947394e-02, -5.24310730e-02],\n",
       "          [ 1.05702169e-02, -2.88292766e-03, -5.66135012e-02, ...,\n",
       "           -5.61893210e-02, -1.78850070e-03, -5.17386198e-03]],\n",
       " \n",
       "         [[-4.59955186e-02,  4.84740026e-02,  1.30349509e-02, ...,\n",
       "            1.55676566e-02, -2.42942311e-02,  1.38872489e-03],\n",
       "          [-2.61395723e-02, -4.97840270e-02, -3.43171582e-02, ...,\n",
       "            2.07738169e-02, -2.30138935e-02, -3.68373692e-02],\n",
       "          [ 1.28673874e-02,  5.26458956e-02, -4.35068980e-02, ...,\n",
       "           -5.74207120e-02, -5.16510196e-02, -1.76139697e-02],\n",
       "          ...,\n",
       "          [ 5.47473505e-03, -5.87352738e-03,  1.78542770e-02, ...,\n",
       "            5.72812222e-02,  3.34626175e-02,  3.17369141e-02],\n",
       "          [-4.15977463e-02,  1.81451030e-02, -5.22417054e-02, ...,\n",
       "           -2.52619907e-02,  3.50775309e-02,  3.47377248e-02],\n",
       "          [-4.23496738e-02,  2.98878588e-02,  4.78212871e-02, ...,\n",
       "           -2.35510394e-02, -6.86936080e-04,  3.43770906e-03]],\n",
       " \n",
       "         [[ 8.68615881e-03, -4.67569120e-02, -4.53163907e-02, ...,\n",
       "           -3.61822173e-03,  4.15567309e-04,  1.68499611e-02],\n",
       "          [-9.98076797e-03, -4.27543521e-02, -1.00381151e-02, ...,\n",
       "           -3.11151631e-02, -5.70692644e-02,  3.34800668e-02],\n",
       "          [-3.56788523e-02, -5.88638783e-02,  5.81610613e-02, ...,\n",
       "            3.37965451e-02,  3.05756591e-02,  1.17716677e-02],\n",
       "          ...,\n",
       "          [ 7.35864416e-03,  3.99147682e-02, -7.84255564e-04, ...,\n",
       "            1.97353475e-02,  1.99198388e-02,  4.06056643e-04],\n",
       "          [ 8.72258469e-03,  2.12491043e-02, -1.98440999e-02, ...,\n",
       "            2.24296711e-02, -1.74521096e-02, -3.45939100e-02],\n",
       "          [-1.85250565e-02,  2.06822194e-02, -1.64440013e-02, ...,\n",
       "           -1.81764476e-02, -2.91721523e-02,  1.52505599e-02]]]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'conv2d_4/bias:0' shape=(128,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'dense/kernel:0' shape=(8192, 512) dtype=float32, numpy=\n",
       " array([[ 0.0023926 ,  0.02160159,  0.01927342, ..., -0.01272   ,\n",
       "          0.01967444,  0.02377068],\n",
       "        [ 0.00816376, -0.00900372, -0.01135973, ...,  0.00752975,\n",
       "         -0.01531325,  0.00373056],\n",
       "        [-0.01523177, -0.01386897, -0.0240687 , ...,  0.01153704,\n",
       "          0.02445766,  0.01236737],\n",
       "        ...,\n",
       "        [ 0.01954455,  0.01350396, -0.00884141, ...,  0.02117115,\n",
       "          0.00758293, -0.02464376],\n",
       "        [ 0.00847681,  0.01314589,  0.01699665, ..., -0.00295581,\n",
       "         -0.01865632, -0.02321103],\n",
       "        [ 0.00599788, -0.00364108, -0.02225468, ...,  0.01732233,\n",
       "          0.00901238, -0.00120616]], dtype=float32)>,\n",
       " <tf.Variable 'dense/bias:0' shape=(512,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'dense_1/kernel:0' shape=(512, 3) dtype=float32, numpy=\n",
       " array([[ 0.07458342,  0.07841855, -0.00637466],\n",
       "        [-0.03959292,  0.04131856, -0.03903122],\n",
       "        [ 0.01499043, -0.03357964, -0.02818277],\n",
       "        ...,\n",
       "        [ 0.07067487,  0.02976812,  0.09572101],\n",
       "        [ 0.01410445,  0.06089839,  0.07076833],\n",
       "        [-0.04740392, -0.0160076 ,  0.05830126]], dtype=float32)>,\n",
       " <tf.Variable 'dense_1/bias:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>]"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "# Visualize created model as a table\n",
    "model.summary()\n",
    "\n",
    "# Visualize initialized weights\n",
    "model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization params\n",
    "# -------------------\n",
    "\n",
    "# Loss\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "# learning rate\n",
    "lr = 1e-4\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "# -------------------\n",
    "\n",
    "# Validation metrics\n",
    "# ------------------\n",
    "\n",
    "metrics = ['accuracy']\n",
    "# ------------------\n",
    "\n",
    "# Compile Model\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train for 702 steps\n",
      "Epoch 1/18\n",
      "702/702 [==============================] - 122s 173ms/step - loss: 1.1014 - accuracy: 0.3343\n",
      "Epoch 2/18\n",
      "702/702 [==============================] - 99s 141ms/step - loss: 1.0974 - accuracy: 0.3598\n",
      "Epoch 3/18\n",
      "702/702 [==============================] - 109s 156ms/step - loss: 1.0824 - accuracy: 0.4001\n",
      "Epoch 4/18\n",
      "702/702 [==============================] - 109s 155ms/step - loss: 1.0298 - accuracy: 0.4692\n",
      "Epoch 5/18\n",
      "702/702 [==============================] - 104s 147ms/step - loss: 0.9792 - accuracy: 0.5000\n",
      "Epoch 6/18\n",
      "702/702 [==============================] - 106s 151ms/step - loss: 0.9337 - accuracy: 0.5326\n",
      "Epoch 7/18\n",
      "702/702 [==============================] - 122s 174ms/step - loss: 0.8944 - accuracy: 0.5652\n",
      "Epoch 8/18\n",
      "702/702 [==============================] - 106s 151ms/step - loss: 0.8685 - accuracy: 0.5729\n",
      "Epoch 9/18\n",
      "702/702 [==============================] - 101s 144ms/step - loss: 0.8461 - accuracy: 0.5812\n",
      "Epoch 10/18\n",
      "702/702 [==============================] - 101s 143ms/step - loss: 0.8231 - accuracy: 0.6026\n",
      "Epoch 11/18\n",
      "702/702 [==============================] - 104s 149ms/step - loss: 0.8008 - accuracy: 0.6163\n",
      "Epoch 12/18\n",
      "702/702 [==============================] - 101s 144ms/step - loss: 0.7967 - accuracy: 0.6076\n",
      "Epoch 13/18\n",
      "702/702 [==============================] - 105s 150ms/step - loss: 0.7787 - accuracy: 0.6242\n",
      "Epoch 14/18\n",
      "702/702 [==============================] - 101s 144ms/step - loss: 0.7678 - accuracy: 0.6345\n",
      "Epoch 15/18\n",
      "702/702 [==============================] - 101s 144ms/step - loss: 0.7398 - accuracy: 0.6361\n",
      "Epoch 16/18\n",
      "702/702 [==============================] - 102s 145ms/step - loss: 0.7314 - accuracy: 0.6477\n",
      "Epoch 17/18\n",
      "702/702 [==============================] - 102s 145ms/step - loss: 0.7146 - accuracy: 0.6649\n",
      "Epoch 18/18\n",
      "702/702 [==============================] - 110s 157ms/step - loss: 0.7104 - accuracy: 0.6584\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14d23be46c8>"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "model.fit(x=train_dataset,\n",
    "          epochs=18,  #### set repeat in training dataset\n",
    "          steps_per_epoch=len(train_gen))\n",
    "\n",
    "# If you can get \"Failed to get convolution algorithm. This is probably because cuDNN failed to initialize\", your GPU is full ! Restart all kernels !\n",
    "\n",
    "# How to visualize Tensorboard\n",
    "\n",
    "# 1. tensorboard --logdir EXPERIMENTS_DIR --port PORT     <- from terminal\n",
    "# 2. localhost:PORT   <- in your browser"
   ]
  },
  {
   "source": [
    "## Save a Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "can't pickle _thread.RLock objects",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-33c5d1c210d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Model1\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# saving the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: can't pickle _thread.RLock objects"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(model, open(\"Model1\",'wb')) # saving the model"
   ]
  },
  {
   "source": [
    "## Visualize a Random Image"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "UnknownError",
     "evalue": "NameError: name 'valid_gen' is not defined\nTraceback (most recent call last):\n\n  File \"C:\\Users\\enric\\anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\", line 673, in get_iterator\n    return self._iterators[iterator_id]\n\nKeyError: 0\n\n\nDuring handling of the above exception, another exception occurred:\n\n\nTraceback (most recent call last):\n\n  File \"C:\\Users\\enric\\anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\tensorflow_core\\python\\ops\\script_ops.py\", line 236, in __call__\n    ret = func(*args)\n\n  File \"C:\\Users\\enric\\anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\", line 789, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"C:\\Users\\enric\\anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\", line 675, in get_iterator\n    iterator = iter(self._generator(*self._args.pop(iterator_id)))\n\n  File \"<ipython-input-8-38f1f5365434>\", line 34, in <lambda>\n    valid_dataset = tf.data.Dataset.from_generator(lambda: valid_gen,\n\nNameError: name 'valid_gen' is not defined\n\n\n\t [[{{node PyFunc}}]]",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\tensorflow_core\\python\\eager\\context.py\u001b[0m in \u001b[0;36mexecution_mode\u001b[1;34m(mode)\u001b[0m\n\u001b[0;32m   1896\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecutor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecutor_new\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1897\u001b[1;33m     \u001b[1;32myield\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1898\u001b[0m   \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    658\u001b[0m             \u001b[0moutput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 659\u001b[1;33m             output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[0;32m    660\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next_sync\u001b[1;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[0;32m   2478\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2479\u001b[1;33m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2480\u001b[0m   \u001b[1;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6605\u001b[0m   \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6606\u001b[1;33m   \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6607\u001b[0m   \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mUnknownError\u001b[0m: NameError: name 'valid_gen' is not defined\nTraceback (most recent call last):\n\n  File \"C:\\Users\\enric\\anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\", line 673, in get_iterator\n    return self._iterators[iterator_id]\n\nKeyError: 0\n\n\nDuring handling of the above exception, another exception occurred:\n\n\nTraceback (most recent call last):\n\n  File \"C:\\Users\\enric\\anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\tensorflow_core\\python\\ops\\script_ops.py\", line 236, in __call__\n    ret = func(*args)\n\n  File \"C:\\Users\\enric\\anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\", line 789, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"C:\\Users\\enric\\anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\", line 675, in get_iterator\n    iterator = iter(self._generator(*self._args.pop(iterator_id)))\n\n  File \"<ipython-input-8-38f1f5365434>\", line 34, in <lambda>\n    valid_dataset = tf.data.Dataset.from_generator(lambda: valid_gen,\n\nNameError: name 'valid_gen' is not defined\n\n\n\t [[{{node PyFunc}}]] [Op:IteratorGetNextSync]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-594eeea2aabe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Get a test image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mtest_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mtest_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_img\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    629\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# For Python 3 compatibility\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 630\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    631\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    632\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_next_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m     \u001b[1;34m\"\"\"Returns a nested structure of `Tensor`s containing the next element.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    673\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 674\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    675\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    676\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    663\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_element_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_from_compatible_tensor_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    664\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 665\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_compatible_tensor_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_element_spec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    666\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    667\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_gpuenv\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m    128\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m                 \u001b[1;31m# Suppress StopIteration *unless* it's the same exception that\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\tensorflow_core\\python\\eager\\context.py\u001b[0m in \u001b[0;36mexecution_mode\u001b[1;34m(mode)\u001b[0m\n\u001b[0;32m   1898\u001b[0m   \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1899\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecutor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecutor_old\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1900\u001b[1;33m     \u001b[0mexecutor_new\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1901\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1902\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\tensorflow_core\\python\\eager\\executor.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     65\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;34m\"\"\"Waits for ops dispatched in this executor to finish.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m     \u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTFE_ExecutorWaitForAllPendingNodes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mclear_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnknownError\u001b[0m: NameError: name 'valid_gen' is not defined\nTraceback (most recent call last):\n\n  File \"C:\\Users\\enric\\anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\", line 673, in get_iterator\n    return self._iterators[iterator_id]\n\nKeyError: 0\n\n\nDuring handling of the above exception, another exception occurred:\n\n\nTraceback (most recent call last):\n\n  File \"C:\\Users\\enric\\anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\tensorflow_core\\python\\ops\\script_ops.py\", line 236, in __call__\n    ret = func(*args)\n\n  File \"C:\\Users\\enric\\anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\", line 789, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"C:\\Users\\enric\\anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\", line 675, in get_iterator\n    iterator = iter(self._generator(*self._args.pop(iterator_id)))\n\n  File \"<ipython-input-8-38f1f5365434>\", line 34, in <lambda>\n    valid_dataset = tf.data.Dataset.from_generator(lambda: valid_gen,\n\nNameError: name 'valid_gen' is not defined\n\n\n\t [[{{node PyFunc}}]]"
     ]
    }
   ],
   "source": [
    "# Let's visualize the activations of our network\n",
    "from PIL import Image\n",
    "\n",
    "test_iter = iter(test_dataset)\n",
    "\n",
    "# Get a test image\n",
    "test_img = next(test_iter)[0]\n",
    "test_img = test_img[0]\n",
    "\n",
    "# Visualize the image\n",
    "Image.fromarray(np.uint8(np.array(test_img)*255.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'test_img' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-210323040ec9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mactivation_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlayer_outputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Finally we get the output values given the imput test image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mactivations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mactivation_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_img\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'test_img' is not defined"
     ]
    }
   ],
   "source": [
    "# Get the activations (the output of each ReLU layer)\n",
    "layer_outputs = [layer.output for layer in model.layers if isinstance(layer, tf.keras.layers.ReLU)]\n",
    "# We can do it by creating a new model (activation_model) with model.input as input \n",
    "# and all the ReLU activations as output\n",
    "activation_model = tf.keras.Model(inputs=model.input, outputs=layer_outputs)\n",
    "# Finally we get the output values given the imput test image\n",
    "activations = activation_model.predict(tf.expand_dims(test_img, 0))"
   ]
  },
  {
   "source": [
    "## Evaluation of the Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Confusion Matrix and Classification Report (Precision, Recall, and F1-score)\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "Y_prediction = model.predict_generator(test_gen, len(test_gen))\n",
    "# Convert predictions classes to one hot vectors \n",
    "Y_pred_classes = np.argmax(Y_prediction,axis = 1) \n",
    "actual_classes = 0 # no becuase we don't know the test labels\n",
    "# Convert validation observations to one hot vectors\n",
    "Y_true = test_gen.classes\n",
    "# compute the confusion matrix\n",
    "confusion_mtx = confusion_matrix(Y_true, Y_pred_classes)\n",
    "class_report = classification_report(Y_true, Y_pred_classes, \n",
    "                                     target_names=test_gen.class_indices.keys())  # target_names must be ordered depending on the class labels\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_mtx)\n",
    "print()\n",
    "print('Classification Report:')\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_csv(results, results_dir='./'):\n",
    "\n",
    "    csv_fname = 'results_'\n",
    "    csv_fname += datetime.now().strftime('%b%d_%H-%M-%S') + '.csv'\n",
    "\n",
    "    with open(os.path.join(results_dir, csv_fname), 'w') as f:\n",
    "\n",
    "        f.write('Id,Category\\n')\n",
    "\n",
    "        for key, value in results.items():\n",
    "            f.write(key + ',' + str(value) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'listdir' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-ac96d816b3c4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtest_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'test'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mimages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mimages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'filename'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'listdir' is not defined"
     ]
    }
   ],
   "source": [
    "dataset_dir = \"C:/Users/enric/Downloads/AN2DL-1st-Project/MaskDataset\"\n",
    "test_dir = os.path.join(dataset_dir, 'test')\n",
    "\n",
    "images = [f for f in listdir(test_dir)]\n",
    "images = pd.DataFrame(images)\n",
    "images.rename(columns = {0:'filename'}, inplace = True)\n",
    "images[\"class\"] = 'test'\n",
    "\n",
    "test_gen = train_data_gen.flow_from_dataframe(images,\n",
    "                                               test_dir,\n",
    "                                               batch_size=bs,\n",
    "                                               target_size=(img_h, img_w),\n",
    "                                               class_mode='categorical',\n",
    "                                               shuffle=False,\n",
    "                                               seed=SEED)\n",
    "\n",
    "\n",
    "test_gen.reset()\n",
    "\n",
    "predictions = model.predict_generator(test_gen, len(test_gen), verbose=1)\n",
    "\n",
    "results = {}\n",
    "images = test_gen.filenames\n",
    "i = 0\n",
    "\n",
    "\n",
    "\n",
    "for p in predictions:\n",
    "  prediction = np.argmax(p)\n",
    "  import ntpath\n",
    "  image_name = ntpath.basename(images[i])\n",
    "  results[image_name] = str(prediction)\n",
    "  i = i + 1"
   ]
  },
  {
   "source": [
    "## Evaluation of the model."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Confusion Matrix and Classification Report (Precision, Recall, and F1-score)\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "Y_prediction = model.predict_generator(test_gen, len(test_gen))\n",
    "# Convert predictions classes to one hot vectors \n",
    "Y_pred_classes = np.argmax(Y_prediction,axis = 1) \n",
    "# Convert validation observations to one hot vectors\n",
    "Y_true = test_gen.classes\n",
    "# compute the confusion matrix\n",
    "confusion_mtx = confusion_matrix(Y_true, Y_pred_classes)\n",
    "class_report = classification_report(Y_true, Y_pred_classes, \n",
    "                                     target_names=test_gen.class_indices.keys())  # target_names must be ordered depending on the class labels\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_mtx)\n",
    "print()\n",
    "print('Classification Report:')\n",
    "print(class_report)"
   ]
  },
  {
   "source": [
    "# Create the CSV for Kaggle"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_csv(results, results_dir='./'):\n",
    "\n",
    "    csv_fname = 'results_'\n",
    "    csv_fname += datetime.now().strftime('%b%d_%H-%M-%S') + '.csv'\n",
    "\n",
    "    with open(os.path.join(results_dir, csv_fname), 'w') as f:\n",
    "\n",
    "        f.write('Id,Category\\n')\n",
    "\n",
    "        for key, value in results.items():\n",
    "            f.write(key + ',' + str(value) + '\\n')\n",
    "\n",
    "\n",
    "test_dir = os.path.join(dataset_dir, 'test')\n",
    "\n",
    "images = [f for f in listdir(test_dir)]\n",
    "images = pd.DataFrame(images)\n",
    "images.rename(columns = {0:'filename'}, inplace = True)\n",
    "images[\"class\"] = 'test'\n",
    "\n",
    "test_gen = train_data_gen.flow_from_dataframe(images,\n",
    "                                               test_dir,\n",
    "                                               batch_size=bs,\n",
    "                                               target_size=(img_h, img_w),\n",
    "                                               class_mode='categorical',\n",
    "                                               shuffle=False,\n",
    "                                               seed=SEED)\n",
    "\n",
    "\n",
    "test_gen.reset()\n",
    "\n",
    "predictions = model.predict_generator(test_gen, len(test_gen), verbose=1)\n",
    "\n",
    "results = {}\n",
    "images = test_gen.filenames\n",
    "i = 0\n",
    "\n",
    "for p in predictions:\n",
    "  prediction = np.argmax(p)\n",
    "  import ntpath\n",
    "  image_name = ntpath.basename(images[i])\n",
    "  results[image_name] = str(prediction)\n",
    "  i = i + 1"
   ]
  }
 ]
}